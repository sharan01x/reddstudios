
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/blog/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "http://localhost:4000/blog/about",
    "title": "About the Author",
    "body": "I’m Sharan, a developer-turned-designer. I have worked on over 95 projects in my career with clients large and small. I have run a top-100 UX Design agency in the past and am the Chief Design Officer of a Web3 company today. This website is organised as a progression of ideas, which turn into experiments, that finally get implemented in projects. And the few ideas that endure the test of time, I document as principles. I use this website to reflect upon my work and hope it will prove useful to other fellow designers as well. Connect with MeUse any of the following methods to connect with me:        X    LinkedIn    Mastodon    Lens     "
    }, {
    "id": 2,
    "url": "http://localhost:4000/blog/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "http://localhost:4000/blog/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                                                           The Age of Goal Based Computing is Here                              :               Among the many things AI has enabled, it has now made possible an entirely new method of interacting with our computers. :                                                                                                                                                                       sharanx                                17 Apr 2025                                                                                                                                                                                                                                                                                                                        Review of Replit, the Figma Killer                              :               Replit has been thought of as a tool that will replace Figma. I tested it out to see if that is true. ___Introduction:                                                                                                                                                                       sharanx                                29 Jan 2025                                                                                                                                                                                                                                                                                                                              How to start designing for Web3                              :               Web3 is a burgeoning field, but you can’t just take Web2 designs and expect them to work in Web3. What should you keep in mind?. . . :                                                                                                                                                                       sharanx                                04 Dec 2024                                                                                                                                                                                                                                                                                                                              Designing Web3 Wallets for Mainstream Users                              :               There is a problem with Web3 wallets, they’re just too complex. But where’s the problem stemming from and how do we solve it?:                                                                                                                                                                       sharanx                                30 Sep 2024                                                                                                                                                                                                                                                                                              All Stories:                                                                                                     The Age of Goal Based Computing is Here              :       Among the many things AI has enabled, it has now made possible an entirely new method of interacting with our computers. :                                                                               sharanx                17 Apr 2025                                                                                                                                    Review of Replit, the Figma Killer              :       Replit has been thought of as a tool that will replace Figma. I tested it out to see if that is true. ___Introduction:                                                                               sharanx                29 Jan 2025                                                                                                                                    The New Age of the Design Generalist              :       AI tools have made coding simpler. Skills are no longer relevant. Imagination and envisioning a particular future is more necessary than ever. ___The ‘Boring’ Part:                                                                               sharanx                30 Dec 2024                                                                                                                                    How to start designing for Web3              :       Web3 is a burgeoning field, but you can’t just take Web2 designs and expect them to work in Web3. What should you keep in mind?:                                                                               sharanx                04 Dec 2024                                                                                                                                    The Ultimate Guide to Hiring the Right UX Design Agency              :       It doesn’t matter that the design agency has a high rating if they aren’t a good fit for your project. But how do you find the right one?:                                                                               sharanx                15 Nov 2024                                                                                                                                    Design Proposals that Boost Conversion Rates              :       Building proposal templates takes a lot of effort and you’re still left unsure of whether you’ve done it right. This article tries to help you fix that. :                                                                               sharanx                05 Nov 2024                                                                                                                                    Designing Web3 Wallets for Mainstream Users              :       There is a problem with Web3 wallets, they’re just too complex. But where’s the problem stemming from and how do we solve it?:                                                                               sharanx                30 Sep 2024                                                                                                                                    Five personal AI assistant devices reviewed and what they need to fix              :       The world of AI assistants has taken a sharp leap forward with new devices emerging every year. However, despite the excitement around these personal AI assistant devices, many haven’t lived. . . :                                                                               sharanx                12 Sep 2024                                                                                                                                    DIY: A Raspberry Pi based Time Capsule              :       I built an efficient Apple Time Capsule clone that will perform the task of allowing any externally connected hard drive to be used as a backup destination using the Time. . . :                                                                               sharanx                04 Aug 2024                                               &laquo; Prev       1        2        3        4      Next &raquo; "
    }, {
    "id": 4,
    "url": "http://localhost:4000/blog/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 5,
    "url": "http://localhost:4000/blog/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 6,
    "url": "http://localhost:4000/blog/page3/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 7,
    "url": "http://localhost:4000/blog/page4/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 8,
    "url": "http://localhost:4000/blog/the-age-of-goal-based-computing/",
    "title": "The Age of Goal Based Computing is Here",
    "body": "2025/04/17 - Among the many things AI has enabled, it has now made possible an entirely new method of interacting with our computers. IntroductionI have long believed that we are on the precipice of changing the fundamental way in which humans will interact with computers. We are stepping into an age where we are going to simply be able to tell our computers the goals we want to achieve and they will figure out the steps in order to achieve it and then execute it for us. But this powerful idea is founded on the notion that your computer will know what there is to know about you, including your preferences, your data and whatever else you can supply it. But that brings up many new questions regarding privacy, data ownership and data residency. But don’t worry, I’m not here just to whine, (though I will), but I also come bearing a solution and even ways for you to participate in it. BackgroundTo begin to understand the importance of what we’re currently living through, it is important for me to provide you a bit of background about three aspects of this industry. First, I want to point out the evolution of computing from the perspective of how much effort it takes to have your computer do what you need it to do, the effort has been reducing over time. We’ve gone from writing our instructions on punch cards to writing programs using almost english sounding programming languages like BASIC or Python. After that, the evolution plateaued until the birth of LLMs. Now, we can speak to them in natural language and have them do things for us.  The second progression that I want you to pay attention to is the number of things a particular program is capable of doing. You see, at first you needed to employ programmers in your office to write you custom programs because there was just no other way to having your company use the efficiency that computers could bring to your organisation. Post that phase, applications were available to people to just download, install and use. Now app developers who were competing for the user’s dollars, either built apps to serve a niche audience or started building super-apps that could do everything. The latter group quickly ran into the limitations of the Graphical User Interface (GUI) because there was only so many things you can pack into a screen and still be user-friendly. This was the case, again, until LLMs. Now you had computers that could do anything, even write programs to do specific things. Thirdly, apps have been very specific solutions to a problem. As such, they’ve been very brittle as you could only ask the app to do certain things and that’s it. Even when speech technology was applied, you still spent time learning the phrases that you could use a la, “Hey Google, turn my lights on in the living room”. If you said that phrase differently than it had been setup with, for example, if you said, “Hey, it’s too dark in the living room” – you couldn’t expect your app to understand that phrase. This hurdle again has been overcome by LLM’s because they can understand your meaning past your words. For example, you could say “I’m thirsty”, “I’m parched” or even be euphemistic like “My mouth feels like the Sahara desert right now” and it would still get the meaning you want to convey. From a UX perspective, this ability for technology to fit into the life of human beings seamless is what I find most powerful. So we are at the threshold of these three progressions having come to a head at once. This means that not only are our computers going to be super capable going forward, it’s going to be incredibly simple to use and no one has to spend any time even learning them. Can you imagine what an unlock this is for society? And this is the first time in history that the benefits of this technology is not just going to those of us who grew up with technology in our lives and we’ve found it comfortable because we spent the time learning them, it’s going to be a massive unlock for those that were so far left behind the technological divide or even the english-language.  These include people like my parents who find their smartphones challenging to use. This, is huge. Context is EverythingFor AI systems to go from just being effective on the baseline (based on what it’s learnt about humans as a whole from the internet) to doing things for you the way you prefer it be done requires understanding your context. They need to be able to study your behaviours and patterns in order to be able to emulate them. This may mean giving the AI access to not just your emails, calendars, contacts, photos but even allow it to watch your health data, medical records, your passwords, etc. That’s when they can go to a place where they can understand that you prefer to say “clutch” over “cool” or like to order from this particular Chinese restaurant and the other one is there as a backup or that you prefer your screen font size large because you have trouble reading or even to cancel all your appointments automatically if you woke up unwell one day. It can figure all this out without you ever having to tell it these things explicitly. But AI isn’t just going to be a useful assistant to have, it will soon become essential. We live in a world where information is being produced at unprecedented rates and we feel compelled to keep up. But we are reaching the limits of human capabilities and that’s just going to continue to be the case. There will be hundreds of decisions that we can delegate to AI that’s working on our behalf, the least of which is deciding which email is spam and which isn’t. If you want to participate in an accelerating world, having an AI assistant will become a necessity in the same way having a smartphone today is seen as a necessity. So, the question is, where do you get your AI assistant. Shop AroundIf there’s one thing we’ve learnt from the mistakes made by the social media decade is that if the service is free, you are the product. We’ve also seen the many ways data about users have been used against them. To most readers of this blog, I don’t need to list the kinds of things these large technology companies learn about us just through the ways in which we shop or even the intonations of our voice. We’ve seen how effective and accurate they have been, including stories about products being suggested to dads of teenagers who were pregnant, even before the dad knew about that pregnancy! I would never trust these corporations with my context data, especially when that data could reveal infinitely more information than my social media profile ever could. Let me be clear, I don’t think these corporations are necessarily evil. I find it hard to imagine anyone waking up every morning with the sole intention to destroy other people’s lives. But the incentives of corporations are definitely not aligned to serving the user. They are beholden to their shareholders and are mandated with generating profits for them. This mechanism doesn’t allow anyone to see the user as anything more than a resource to derive value from. If value can be generated by selling their data to the highest bidder, so be it. Given this equation, let’s suppose you go ask a question about a certain type of cancer to the AI assistant from one of these large corporations or submitted a scan to this assistant with the intention of getting a second opinion. What if that AI assistant saw that and realised that your insurance company may be willing to pay a huge amount for that information because they could loose a lot more if they continue to cover you if you fell ill. Do you think the assistant would be programmed to act on your behalf or to generate a profit for the corporation? The good news is that we don’t need to rely on these corporations. The open source world has realised these pitfalls and have been hard at work developing technologies that will ensure that this kind of a future doesn’t need to befall us. I also realise how important these efforts are and have been contributing my time and efforts to such projects as well. The Solution is SimpleWhile these big companies that own the frontier AI models want to portray themselves as the only option for this sort of intelligence, don’t be fooled. Know that you can have absolutely great stuff available to you without any of them in the picture. You can retain complete ownership of your data while still getting all the convenience. You can do all this locally, in the privacy of your own computer. You don’t have to learn prompting strategies either. You can install Ollama and Move 37 on your machine and you’re good to go! All of it is completely free and you can even check and audit the code if you’re so inclined. Granted it’s a little bit of work to get this installed right now, but they are all making things easier all the time. If you’d like to see a demo of this, I’d be happy to create one. If you want to find out how to install this also, I can create another video about it. But for now, here’s a very quick walkthrough. [COMING SOON] As mentioned, these two projects are available for free, from these locations. So go check them out:  Ollama Move37ConclusionIf you believe in an open future where individuals retain control over their own destinies, you can start using these technologies for yourself. But if you feel like you’d want to contribute more and be a part of these movements, there are many ways you can participate depending on your skills. If you’re technically inclined:  Move37 is looking for help in testing, verifying the code completeness and various other items listed in their roadmap.  UX designers can propose new ways to organise the frontend to make things easier and more efficient.  The installation process could use a lot of simplifying and that’s something that you can contribute to, especially on Move37. If you’re not an engineer:  Use and provide feedback and spot bugs Spread the word and get more people to realise the problem and understand that there are solutions Create videos talking about the projects Add new recipes – the steps for using various applications Suggest new ideas and features that can be built Star the projects on GitHub so that they get more visibility Just donate to the projects if you’ve got the money, they can use it. But whatever you choose, thanks for being a part of this! Until next time, ciao! "
    }, {
    "id": 9,
    "url": "http://localhost:4000/blog/whatsapp-versus-slack/",
    "title": "WhatsApp or Slack for your startup?",
    "body": "2025/03/24 - These tools are relied upon by a lot of startups. But these tools can make or break your startup. So, which do you choose?___ Introduction"
    }, {
    "id": 10,
    "url": "http://localhost:4000/blog/review-of-replit/",
    "title": "Review of Replit, the Figma Killer",
    "body": "2025/01/29 - Replit has been thought of as a tool that will replace Figma. I tested it out to see if that is true. ___ IntroductionIn my previous video, I wondered why design and coding tools had to be different and require constant translation when moving between them. Just two days later, Paul Graham tweeted that one of his well-known companies had ditched Figma in favour of Replit — validation that my curiosity was onto something big. As someone always eager to explore innovative tools, I couldn’t resist diving in myself. In this review, I’ll walk you through my experience with Replit and share whether it truly lives up to the hype. DisclaimerFirstly, I must say that this article is in no way sponsored by Replit. I paid for the account myself and used the software and these opinions are mine alone. I got myself the $25/month plan. I paid extra per month firstly because I was just testing this out, but also because I feel that committing to a single platform for a whole year makes no sense when new tools are being developed and released all the time. Using ReplitObjective: So, my objective was simple:  I wanted to prompt my way into bringing a working product to life and it needed to have the UX and UI that I wanted for it. The application that I was trying to build was one that could be used to take notes during meetings, summarise it and then share it with the user. I chose this as it’s not too complex but also not as easy as the demo apps that have been shown to work in a lot of cases. Third Attempt: After signing up, I was presented this box that asked what I wanted to build today. In my first two attempts, I said that I wanted to build an audio recording application that does such and such. For some reason this just didn’t work. It failed miserably, but we’ll talk more about it later on. So what I describe here is my third attempt where I changed tactics and tried to approach this in a very non-technical way.   I began by stating that I wanted to build an app that would take notes during meetings. I further specified that there should be a toggle button to start and stop recordings, that it should clearly indicated that it is active and also send the recordings to a server for processing where it would be transcribed and the meeting notes generated.   I didn’t specifically mention any platforms or specifications of the UI. I was hesitant to provide too much detail as I have seen AI agents breakdown because of this. Providing too little detail also doesn’t usually provide me the output that I want, so I’m never quite sure exactly how much detail I needed to provide. But there’s a helpful, “Improve Prompt” button and I’ve seen that clicking these usually provides the level of detail that is expected by the system. So I clicked it and it added details about the UI itself and chose “dark mode” for some reason. I’m not a fan, but I don’t hate it enough to want to change it for a trial app, so I just went ahead and asked it to start building. Some interesting things happened at this point. It started “Thinking…” and after a few seconds came back and reiterated what it thought I wanted it to build. Mind you, I had just asked it to improve my prompt, so from my perspective it was already aware of what it was supposed to build, so when it said something like, “So you want to build…” with added surprise like it had become aware of this message for the very first time, it felt like I was talking to a moron, not something that was going to make things any easier.   It feels like I’m splitting hairs here. I know the system needs to confirm what’s been understood, but I have seen more and more AI based interfaces use these conversational style interfaces and end up making this mistake of not keeping the user’s context in mind.   Anyway, the good thing was that it suggested additional features that I could add on to my initial request. The suggestions were great and extremely relevant, but, not something I really needed to consider at this moment. This was really mis-timed and should have been something that was suggested after the main request was completed (which it actually does). It would have made more sense to ask questions that it needed clarifications on at this point. Moreover, my experience with using AI based tools to create applications has taught me that it is better to start small and then build up the set of features that you want. So you need to do some planning yourself actually.   Anyway, I asked it to just go ahead and build out the basic application first and then it began whirring away. The chat flow moved to the left and the right side showed a section called “Progress” and lots of things started to fly by. Pieces of code, snapshots of interfaces and more pieces of code, more snapshots, a database getting created, dependencies being installed, etc. and then finally, after about 3 to 5 minutes, it stopped, a panel slid up with the application in view (this is a nice feature by the way), and then in the chat, it asked me to confirm if the interface was visible to me. It had been taking snapshots until now, so I wasn’t sure what the question was. I clicked around on the interface and saw all the required components were indeed there. I clicked the microphone button and saw that nothing really happened. So I assumed that this is what was supposed to happen and so I responded in the chat stating that exactly, that the interface looked fine but nothing functioned as yet. But it didn’t quite respond to me and instead just went ahead and started building out the functionality.   Again, I saw a whole lot of code flash by and then it finally stopped and asked me to test out the functionality. To my utter amazement the application worked and even had a nice visualisation and everything. I started recording, said a few things and when I stopped it, it saved the recording and then moved it to the server. The layout was a little messed up and I also needed to improve the algorithm behind the uploading to the server bit, because it was possible that the mobile phone that is recording the meeting isn’t always going to be able to stay connected to the server. So in such circumstances, it should save the recordings locally and then try to attempt to push the recording to the server whenever it connects again. Making Changes: After having made some edits in the previous attempts, I realised what was possible to edit and what wasn’t. So I just cut to the chase and got rid of troublesome elements and made it make some changes that I needed. I was able to add additional features quite easily, but when I tried to ask it to work on a feature to mitigate upload issues and instead, to chunk the uploads in 10 second blocks and then try to upload it to the server, it failed to do this level of a complex task. But at this time, when I tried to go back to a previous checkpoint where things were working, it completely failed that and it seemed like it’s roll-back wasn’t well done. It seems that when it comes to using AI tools for development and prototyping work, there’s no going back, only forward. Failures: There was one early attempt that I made where Replit hit an obstacle that it couldn’t surmount. It gave me 3 options to continue trying, try a different approach or to rewrite the whole thing in a completely different way. I responded in the chat stating that exactly, that the interface looked fine but nothing functioned as yet. But it didn’t quite respond to me and instead just went ahead and started building out the functionality. There was a stop button and I clicked that but by that time, I think some code was written and that was that. It was a bad build and I just couldn’t recover from that point onwards. I had to scrap the project and begin again. Using Templates: I even thought that I am making my life difficult by trying to build an app from scratch. There are a lot of templates available on Replit and I thought I’d try that out. But when I use a template, the AI Agent is no longer available to me and I can only talk to the AI Assistant that cannot write the code like the agent. I thought this was really strange and I didn’t proceed with using the templates even though they seemed really appealing to me as starting points. Lessons LearntThis was a very informative experience for me. When I used the trial version, it ran out of available credits. If you’ve watched an older video of mine, you know that I have tried using GitHub Copilot and Windsurf and I ran into some problems there that made the left the development experience wanting. So I was actually really looking forward to trying out Replit because I had heard so much about it. But here’s where I think things are at with Replit: Making multiple attempts is required: I’ve seen this with other coding agents and it’s kind of interesting that I am seeing the same pattern occur here, but your chances of creating the application that you want in one shot is next to impossible. You need to go through the process multiple times like a video game and running into different bosses and striking out and then starting making sure to avoid those pitfalls when you try to build it all over again. Start small and then add on: While Replit provides you the options to add a whole number of features all at the beginning, it’s not a good idea. I think it’s best to start with the barebones version of the application first and then once you have that bit working, add on new features. Editing the UI is hard: When I referenced elements on the screen by a certain logical name, it wasn’t always understood by the agent. But since there’s no way to point at a thing and identify them, it just wasn’t possible to edit some elements. I also didn’t see where the files were until much later, so going through the code and referring to a specific element just wasn’t easy either. So I used UI strategies where I worked around the need for these difficult elements. Checkpoints don’t work well: When I realised that the checkpoints weren’t working as expected and weren’t as reliable, I began downloading the files at the points where I felt I had things functioning just like I wanted. Additionally, there was a point where I chose the wrong checkpoint that was a much earlier version of the code where things had been working. Once it tried to restore to that point, there was no way to go forward to the next checkpoint instead. This was severely frustrating for me. Couldn’t bring it to life: Despite the three attempts, I couldn’t bring the project to life. I downloaded the code and while I tried to get it to function locally, I haven’t been able to install the database and build the structure as yet. There’s no file backup for the database elements, so I’ve got to figure this out on my own. I’m really not looking forward to this. Bottom LineNot there yet: I don’t know what Paul Graham’s acquaintance was thinking when they’ve committed to working with Replit and remove Figma. I don’t think Replit is there yet. Can they get there in the future? I sure hope so. But will I be replacing Figma, Framer and Windsurf right now? No, not at all. UX is not great: If you watch some videos of Replit from before, you’ll notice that the agent chat window has gone from being the ancillary element on the right to the primary element on the left. This signals that they thing of code and files as secondary elements to writing the code right now. But they haven’t evolved fully as yet. In order to appeal to designers or non-developers, the interface needs to be able to refer to elements and operate them in different ways. As an example, if I had a way to point at elements on the right-side preview pane, it would have made my life so very easy. Additionally, they need to provide a way to build and utilise design systems at the same time. Really not meant to create stuff you have in mind: It occurred to me that if I begin with a very specific idea in my mind and try to recreate that using Replit, it’s going to be super hard if not impossible. So this tool really isn’t about doing that, but instead to explore new ideas and interactions. Even if I gave Replit exactly the same set of commands in the same order, I don’t think it would arrive at the same output at the end. That’s a challenge for anyone that wants to have any kind of control over the outcomes. But for exploration, it’s a fine approach. I wouldn’t build anything large or serious: As mentioned before, I have to assume that I need to attempt to build the project multiple times. This limits the kinds of things I can do with Replit. I cannot imagine building a large application. Since the project that was output in the end felt like a precarious Jenga tower, I am not exactly certain that this application would perform well in production. I’m just not that confident. If it’s a blog or a static website, that’s an entirely different matter and I probably wouldn’t feel the same way about that. Deployment is a nice touch: I think Claude and OpenAI demonstrated the artefacts panel in their interfaces. I found that to be extremely important because we could avoid the environment setup and things like that. With Replit, they’ve taken that to the next level by including deployment. So not only can you test and see stuff while building it, you don’t have to deal with deployment issues that are all too common when you’re ready to push the app and make it live. Local software incompatibility: One of the biggest issues that you will face with Replit and it’s ilk is that you cannot have it interface with locally running software. In this example itself, I had the option of having this app work with Ollama installed locally because I would actually be running many tests and didn’t want to hook it up to OpenAI. But there was no way to do this that I could figure out. They’re straddling two boats and need to commit: While it’s perfectly natural for every startup to pivot when they find new product-market-fits, I think Replit is currently mid-pivot as they haven’t really committed to building tools for non-developers as yet. They began as a developer focussed tool to begin with, and they haven’t completely changed their focus and redesigned the older tools to suit the needs of designers and other non-developers. Once they commit, I think I would expect a lot more from them. ConclusionI have never hit “Cancel Subscription” on any tool faster than I did with Replit. The task they’ve undertaken is hard, but they’re not yet where they need to be to get me as a user. My experience developing an application was much better with Windsurf (in conjunction with Perplexity) and I’ll be going back to it. But if this blog has somehow made its way to the Replit team, I would happily invite them to a chat with me as I can recommend many more things that they could do to get users like me on board. Otherwise, I wish them well and hope to use their software after a few months to see if it will suit me then. Until then, I wish them luck! Accompanying videoSupplement video contrasting features with Lovable. dev: "
    }, {
    "id": 11,
    "url": "http://localhost:4000/blog/the-post-app-era-and-the-computing-powershift/",
    "title": "The app-less world and it's implications on the world of computing",
    "body": "2025/01/04 - Among the many things AI has enabled, it now has made it possible to think beyond building software applications. ___ Background      I have [[2024-09-12-5-personal-ai-assistant-devices-reviewed#^1c44a7   long believed]] that we are on the precipice of changing the fundamental way in which humans will interact with computers. Humans will soon be in a place where they can think in terms of the goals they want to achieve rather than thinking about the apps they need to string together in order to achieve the various pieces of it. The required technological pieces such as the [[2024-01-10-rabbit-r1-review#^a18b65   LAM]] and [[2024-12-30-the-new-age-of-design#^5b3b30   Just-in-Time Code]] being developed makes me believe that we are getting closer to this becoming real. There is still one big piece of the puzzle that is necessary which is the context of the user, but it’s only a matter of time and this will be achieved.    DataAs of the writing of this article, the entities that have data about us are the large corporations that have spent years amassing it from our interactions in the digital sphere. They run very large data centres to store and process all this data to understand the user’s context and preferences. Hundreds and thousands of lines of code have been written to do this. So far it’s been employed to serve us ads or sell us stuff. But we are now at a place where the hardware required for the user to be able to record this data about themselves is cheap enough that they could do this at their own homes. Open Source AI engines are also sophisticated and capable enough to replace the need for the many lines of code and instead be able to mine this data to understand the user’s preferences or to know what they said in the previous meeting whenever it is required. Digital TwinSo, in theory, we can build a “digital twin” of a user that exists entirely in a computer that’s owned and controlled by them. This digital twin will be useful in so many ways. For instance, it can be examined to understand their preferred cuisine in order to order lunch or even to identify signs of depression if it comes to that. This digital twin is also available at all hours, so can represent the human in many digital spheres while the human is asleep. AI AgentsAI agents are becoming more and more capable. They are able to search the web, make API calls, do calculations, make good decisions, write code, use computers and software applications and do it using multi-modal inputs and outputs. Very quickly, this AI agent can learn to perform any tasks that the human may perform. The user will begin to speak to their agents in terms of the goals they want to achieve and leave it to the agent to figure out the plan and break it down into tasks that will help achieve that goal. The agent will operate software applications in oder to achieve these tasks. The human will use it to interact with and execute everything certainly in the digital sphere, but maybe some things in the physical world too (taxi hailing, ordering food or products, etc. ) These agents can also filter their actions through the Digital Twin in order to make choices and decisions just as the user would. ImplicationsFirstly, the AI agent becomes the universal interface for the user. This may happen gradually at first, but there is a real possibility that this becomes indispensable soon. Secondly, if the agent is capable of writing code as required to perform a task, software as we know it will not be necessary anymore. Thirdly, if the primary user of websites and applications is the AI agent, they will cease to exist in their current form and become far more like API’s. Future app-stores will be selling specialised data bundles or algorithms that will help analyse the user’s own data in novel ways. Fourthly, with the human interacting more with the agent than with computers or phones, this may reduce their dependence on technology. We may finally settle on computing form factors such as the smart watch in the future. "
    }, {
    "id": 12,
    "url": "http://localhost:4000/blog/the-new-age-of-design/",
    "title": "The New Age of the Design Generalist",
    "body": "2024/12/30 - AI tools have made coding simpler. Skills are no longer relevant. Imagination and envisioning a particular future is more necessary than ever. ___ The ‘Boring’ PartRecently I’ve been having a lot of difficulty in staying on top of my social media game. Not being a native to social media, I approached it with a certain disdain in the beginning and completely missed the wave. But given the new course I have set upon, I intend to learn as much as I can and get better at this now. ️ But the tedious aspect of social media has got to be the manual process of posting content on each and every channel that I have become a part of. That’s the biggest hurdle and the most boring aspect of the entire process. There are some tools, and I subscribed to Typefully to be able to do this. But, alas, Typefully doesn’t support the social platforms on Web3 that I am a part of. So I looked for various solutions and none of them satisfied my needs. It occurred to me to try building an application that would do this for myself with the help of AI and I am so glad I did because, a whole new world has opened up to me now! I began down this path in the usual way that one builds software these days. I got access to ChatGPT, but I found the idea of copy-pasting between the chat interface and VS Code tedious and quite problematic as I am not a very good developer and often made mistakes with where I copied and pasted from. Github Copilot Chat was like having the same ChatGPT capability but repurposed for use within VS Code, though I still had to copy and paste between panels. But GitHub Copilot has a new feature called “Edits” which would directly make the edits to your code. This made things a whole lot more convenient. I could even describe what I wanted to do in plain english and it would make the right edits directly in my code. This was a game-changer! So, with my new setup in place, I began by describing what I intended to achieve at a high level and asked it to recommend the right technology stack. It recommended that I built with Vue. js for my intended purpose, I said “Fine” and it began whirring away setting up the environment with all the required files and started to build out my views. I didn’t know what the limitations were going to be, so I wanted to do a trial project first. I gave it some instructions for a “Hello World” program and it performed it beautifully and I got it to work as expected without much difficulty. The trouble came afterwards where I asked it to scrap the trial project and begin working on the real one. It completely couldn’t figure out how to take steps backwards. It was easier for me to delete the entire project folder and start again, so that’s what I did. But it also highlighted to me that this would be a limitation I would have to deal with using this tool. So I had to chart a course of building features one by one while I get to the final version without having to remove or modify the previously built feature. In my plan, I was going to build a social media posting utility that would allow me to post across multiple channels by supplying it with a single post. So the simplest form of that application was going to be a feature that would post a message on a single channel first, then I would add a drop-down with additional channels and then create a broadcaster that would post across every channel, then a scheduler, etc. This approach worked out rather well. I had to learn to be very specific at times and very broad at other times and that was straightforward enough. But I hit a road block when, after building out the functionality, I wanted to improve the UI and started making fixes. Now these fixes needed to be made across all the interfaces, but for some reason it had a lot of difficulty doing this across the various modules that I had built. It got to bad that I decided to use an entirely different front-end framework that would keep things standardised out of the box so that I would have to do very minimal work in order to make the UI look good. I chose to build the application with Streamlit. At the same time, I heard about Windsurf as an AI infused IDE and saw the demo video and it looked great, even better than Copilot Edits. So I downloaded it and built a simple demo application with the trial credits. It was simply an entirely different experience. I simply describe the application I wanted to build and broke it down into the steps that were going to be required to achieve that and since I had it in the “Write” mode, where it could make file edits and changes, it simply went about doing everything. If I was impressed with Copilot Edits, this blew my socks off. I had the entire application setup and ready to go with Windsurf taking some incredibly good decisions regarding the things I hadn’t mentioned. It even named all the modules and variables in the code as I would have done myself! It was simply outstanding. I was able to achieve what I could with GitHub Copilot over the 5 or 6 days in a matter of 1 day. It did help that I was doing this a second time around, so I knew what the right approach was and didn’t make as many mistakes. But Windsurf hasn’t been without it’s flaws. There were two times where I asked it to write a module “like the edits that you made to the Twitter module…” and it not only wrote the new module in the way it had done the Twitter module, but went too far and made edits to other modules. I had to learn to limit its scope by adding “Do only this and don’t make any other edits” to my instructions and that stopped the problematic edits from being performed. So, the very thing that it was great at and extremely useful at the beginning stages of an application became it’s Achilles heel later on. It was quite literally the opposite of GitHub Edits in this regard. So, the workflow that I would use for future application development is to use Windsurf in the beginning stages of the application and then switch to GitHub Copilot for specific edits and module-level enhancements. But of course, I am talking about their qualities as of today. I completely expect that the teams behind these two tools will find ways to integrate the best features of each other’s AI code companions. But this isn’t meant to be a discussion on the usage of these tools at all. Creating a video about the right ways to work with these AI tools is a fool’s errand because these tools have obviously been built by very smart people that really do understand what they’re bringing to this world and they will keep making improvements until these tools work just the right way it is meant to be by it’s users. No, it’s a discussion about the fact that I now stand in front of a very designed and well built application that does exactly what I want it to do! The implications of this has in equal parts shaken me and blown my mind, and I had to talk about that! The Interesting PartThe following are the changes that I expect to see on the horizon. There are numerous impacts of the stuff that I’ve been doing that I can see and I’ve done my best to list them in a logical order. OS: Firstly, these tools, in their current form have made a huge leap forward in the span of a year. The capabilities of frontier and open-source AI models are only going to become better over time. This will allow them to factor more parameters into their operations. In other words, you will be able to communicate with the AI engines in as many ways as you need, speaking some actions, writing out some others and even supplying your Figma designs straight into the LLM’s for them to understand and execute. But then, if you extend that idea, one may ask, why couldn’t the AI write the program at the time of need? Or even better, couldn’t the AI become the application necessary to do the tasks and instead of providing a chat interface, provide the interface that an application would provide a user. A majority of applications are simply interfaces over some data source, so while there are many qualifiers to this sentence, the short answer is yes, it truly can become that super app and replace the user-facing part of the operating system. The OS will be relegated to managing security, permissions and managing the hardware interfaces. ^5b3b30 Skills: In this world, where would UX design fit in? If an AI can understand the best ways humans interact with interfaces, they can not only produce those interfaces with scarily effective interfaces, but also tune it to the needs of a single individual, no longer serving only the needs of the majority. In such a world, what role would a human UX designer play? I fear, it will no longer be relevant. Roles: In the short-term however, the role of the UX designer will change. They will no longer be beholden to a developer and their capabilities anymore and can circumvent them and develop a great application on their own – just as a developer will no longer need a designer for the applications they will create. As AI takes over more tasks, traditional design roles are likely to shift from execution-oriented to focus on strategic direction. The job will be to instruct AI agents to perform the required tasks in the manner in which it needs to be done in order to achieve the goal. So practical imagination and planning will be the skills that will set us apart going forward. People like lead designers or lead design organisations are going to be much better equipped to jump into this role more naturally than anyone else. But this is only for the short-term and they too will need to go up the chain and up-skill themselves to think like entrepreneurs in the long term, because AI will take over the planning aspect as well soon. Tools: Our current design tools are built for specialists and therefore are designed for precision. You can edit just this pixel, move exactly this screen and change exactly this effect. However AI can handle the details and the tools of the future are going to be designed around doing things with broad strokes. So it can take inputs like, “a background of a desert dune” or “a login flow with 2FA”, instead. The broad strokes are just going to get broader over time with humans being able to specify things in a increasingly abstracted manner. If you look at Krea. ai as an example and see what they’re doing with the Edit feature and compare that with the Photoshop workflow, this aspect will become even more evident. Logically, this also means that the target audience is going to change. It’s no longer going to be appealing only to a graphic designer anymore but an entrepreneur running a company could use Krea, today, with little to no knowledge of graphic design and create some stunning artwork for themselves. Economies of Scale: The dynamics of the economy will also change within the digital space. One of the biggest challenges in the software industry has been to design features that appeal to every individual. But because it costs a lot to design, code, test and release a certain feature, the decision has always been skewed towards appealing to the majority of users and ignoring the fringe needs. But with AI in the mix, this very dynamic can change. As I was discussing before, every feature and interface can be built to appeal to the individual user. Maybe the workflow will be that the human orchestrated output will be the feature that appeals to the majority of users, but AI can use that as a starting point and fill in the gaps to make that feature work for the fringe users? This changes the entire industry. Unexpected Benefactors: One of the biggest benefactors of the economies of scale change are going to be the group of people that are currently disadvantaged by the digital world today. For example, these could be people with eyesight challenges or even the elderly that have so far been left behind by the digital world and are left more and more unsafe because of it. My own father keeps sending me fake videos of various things completely believing whatever thee video says. And since he’s at high risk in a digital world, I have had to ask him to not do any digital banking and completely prevented him from using UPI and such. My mother is unable to use these technologies as she’s a non-native-English-speaker and most interfaces are designed for English. Imagine user interfaces that will adapt to them without additional costs to the software developer. They would finally be able to cross the chasm and join the rest of the digital world. The Generalist: In this AI assisted world, there is a power-shift taking place. The users of AI are going to be able to build anything they can imagine. You no longer are constrained by needing a large team to execute on your vision. A lot of the roles of the team that one needed to build in the past can be executed by an AI agent today. It’s only going to be able to handle more roles in the future. This means that the required capital to build the companies of the future is only going to reduce. It therefore means that more and more people with the imagination and desire to do something will simply be able to. A typical entrepreneur today is a generalist that understands a little bit of all the pieces that are required to execute something and can bring all those pieces together. Broadly speaking, they identify the need in the market, develop a vision for the solution to the problem, then they bring in specialists to fill in the gaps and capitalists to provide the capital required, and create the culture required to execute on the vision. It’s this very person’s role that will be made infinitely better in the future. In the digital world, we’re ushering in the dawn of the age of the generalist. Accompanying Video"
    }, {
    "id": 13,
    "url": "http://localhost:4000/blog/how-to-design-for-web3/",
    "title": "How to start designing for Web3",
    "body": "2024/12/04 - Web3 is a burgeoning field, but you can’t just take Web2 designs and expect them to work in Web3. What should you keep in mind? How to go from designing UX in Web2 to Web3Web3 has been built by engineers, for engineers, until now. But the recent DevCon conference hosted by the Ethereum community in Bangkok had a huge focus on user experience and that’s never happened before. Given how geeky this community has been, even talking about usability is a huge step! There’s a shift from focusing on building infrastructure to building applications on top of that now that a lot of the required infrastructure is in place. There’s a clear realisation within the community to focus on usability with the intention of attracting the mainstream population. This presents an unprecedented opportunity for designers. But transitioning hasn’t been easy and this article intends to make that part simple. Firstly, Understand Web3As UX designers know, to design something effective, we need to begin by understanding as much as possible about the technology underneath. To that end, let’s begin by understanding what is different about Web3 in contrast with Web2. 1. Different Stack: In Web2, you have companies that own the entire application stack – they own the servers, the databases, the back-end software, the payment layer and the front-end UI layer. Users go to these companies and create accounts with them and their usage information is stored on the databases owned and operated by these same companies. In Web3, the network is composed of a huge number of nodes and they are the equivalents of a web server in Web2. The front-end may be built by the company and the users that want to use the software can just sign-in with their wallets and begin using it. Their data is stored on the public blockchain. The results of these differences is vast. Let’s consider the scenario where the application is a social media app and the company wants to implement a feature that some users object to. In Web2 they have no choice but to leave the platform which also means leaving behind all the data they generated and all the friends they made on the platform. In Web3, there is no such thing as locking out the user as their data is always available on the public blockchain. If one front-end provider is charging a very high price for their app, they could use another front-end provider and still have access to all their data and their relationships. 2. Composability: But Web3 is built on standards and protocols, so they’re highly composable. This means that developers can treat all data sources and all projects as if it were their own. For instance, in the example given above, you can imagine a developer creating a different front-end that not only gets the social media posts from one platform, but could choose to include background music from the user’s song library from an entirely different platform and create an audio-visual experience altogether. This is possible because of the composability of Web3. 3. Permissionlessness: If I wanted to develop this sort of an application on Web2, I need to get API Access from the provider, let’s say for example Twitter.  To get that access, I need to firstly submit a short essay on what I intend to do with my API access (to my own account) and then agree to terms and conditions set by Twitter’s lawyers. After this, my access remains conditional, and if I built something super popular but built something Twitter didn’t agree with or maybe felt like they would want to do themselves, they can pull my API access. There’s none of that on Web3. Since the data is stored on a public blockchain, it will be publicly accessible for anyone to come and write programs that can use that data without asking anyone for permission to do so and without terms and conditions. 4. Ownership of Data: The data that is typically generated by users is publicly stored, but private data is typically encrypted using the user’s public key. This means that the data can only be decrypted by the user and no one else. This puts the user’s squarely in control of their information, not any corporation. Mining this data is also impossible if it’s encrypted, so users don’t ever have to worry about being exploited. 5. Pseudonymity: It is a misnomer that people think that Web3 is anonymous. It is not. Every transaction on a blockchain is signed by a wallet. So all the data is identifiable as belonging to that wallet holder. The only piece of information that one doesn’t have is who the owner of the wallet is. But if anyone ever establishes that a certain wallet belongs to a specific person for example, they immediately stop being anonymous and their data becomes transparent on chain, otherwise known as getting doxxed. Sometimes this is a deliberate thing, for example if a user wants social recognition in a game, they can establish their ownership of several items they have collected in their wallet, by demonstrating their ownership of that wallet. But often, users want to remain unknown and do not want to be doxxed if they can help it. 6. Speed: Because of the decentralised structures, speed is often slow when compared to AWS or other such servers. This is something to keep in mind when designing systems. You have to afford for the latency as the result of actions may actually take a long time to be written to the blockchain and are not as immediate as when using equivalent systems built on Web2 standards. But all this is changing and the lines of division are being blurred. 7. Culture: Web3 has been built by idealists, but in a very pragmatic way in order to have real-world utility. You cannot miss hearing about the “original cypher punk” values that seem to be beneath all of it. Decentralisation is not a buzz word, it is the essence of the culture. Being authentic and original are virtues in this field. Having a different viewpoint is celebrated while corporate behaviour, censorship and authoritarianism are taboos. The two biggest projects in the field Bitcoin and Ethreum. Bitcoin’s founder, is unknown, and Ethereum’s founder is Vitalik Buterin, who has actively tried to build a project that doesn’t need him to be around to succeed. He is a 29 year old billionaire who wears unicorn t-shirts and lives a nomadic lifestyle travelling the world with nothing more than what he has in his backpack. I mention these things to highlight the kind of culture that permeates through this world. 8. Digital Property: A big part of the reason for the existence of Web3 has to do with property rights, specifically digital property rights. If you’re anything like me, all your work exists on the digital medium alone. How can you claim your ownership of a blog or artwork? With Web3, you can. You can mint it on a blockchain to claim ownership and lock in the date and time of publication. Key Challenges (Opportunities) Facing Web3For Web3 to become mainstream, there are some key challenges on the user-facing side. These are also opportunities for UX designers to come in and find solutions for. 1. The Wallet: If a user wants to do anything on web3 they need a wallet. While a lot of very user-friendly wallets do exist and some even go so far as to allow Google-sign-ins to create accounts within these wallets, the purpose and usage of these wallets is not very well understood by users. This is an area that needs a lot of work as there are no direct analogies in Web2. Communicating the intricacies of public-private key cryptography is a challenge. 2. Managing Security: One of the disadvantages of Web3 is that it only has one level of security. It’s the public private key pair and nothing else. It’s always the highest level of security. Unlike in Web2, where you signed in only with a login and password on an app of low importance, and with login, password and 2FA to your email service and possibly login, password, OTP and FaceID on a banking app, there are no other levels in Web3. You can see the problems that occur if users started using the same account for social apps as well as to store their money and there was only one level of security that exists for both and that got compromised, they end up loosing everything. Also, Web3 is pseudonymous, not anonymous, so if a user doxxed themselves on a social app, their social network could easily find out everything about their finances. Finally, in case a user forgets a password in Web2, they know they can go through some steps and regain access to their accounts. This is not the case in Web3 as there’s no recovery. If the user doesn’t do a good job storing their passwords, they may loose access to their account forever. These are all challenges that need design intervention to solve as an industry. 3. Liquidity Fragmentation: The Blockchain Trilemma expresses the problem of blockchains against the dimensions of decentralisation, scalability and security and states that any blockchain can have any two of the three qualities but will need to sacrifice the third.  For this reason, there are several blockchains out there that cater to different needs with some providing security, while others are tuned for scalability. Consequently different amounts of capital are spread across these blockchains creating fragmentation of liquidity and users feel the need to constantly move their capital between these chains. But I think design could solve this problem in a number of different ways. 4. Public Relations: Some regulators hate this field because they see it as a threat to their ability to control their population. Crypto has therefore long been portrayed as a scam by the mainstream media. The field has also had several grifters who perpetrated scams and those have also created very bad press. But just like the airline industry, each mishap has informed the field about how to improve. Web3 truly has reached a level of maturity today where it can serve mainstream use cases and make the lives of end-users a lot better. But we’ll have to overcome this PR hurdle. As a designer, you can help. 5. The Search for Mainstream Use Cases: While there is already a Defi use case, there are NFT’s and it is used to transfer money between people and to pay for crypto-use cases like gas fees, there are very few use cases where a mainstream user can use crypto for. There are “real world assets”, “crypto collaterals for fiat loans” and “pay with crypto” as potential ideas, but there may be many, many more. UX Designers that have worked in other fields could probably identify the application of this technology in those fields. 6. AI and Crypto: No list would be complete without the mention of AI, and that’s true here too. There are very interesting applications where AI agents have been creating crypto coins and utilising it for things determined by the AI agents. But this is just the tip of the iceberg and designers would be able to identify more opportunities as this is a very creative space for it’s application. Trends to Keep in MindThere are some trends already taking place that you should pay attention to, and change if you’d like. 1. Demand for Design: Unlike any other point in time, there is a deep desire from projects to improve their design. Vitalik Buterin, the founder of Ethereum has highlighted the importance of UX in several of his talks. He is of course talking about technological improvements that would improve the user experience on the surface layer of tech. But nonetheless there is a focus on UX like no other point in time and we;’re seeing the conversation shift towards making things more usable by regular, mainstream users. 2. Changing Demographics: While Web3 was built by engineers, for engineers, it is changing today. It is attracting far more non-technically inclined people who may be considered early-adopters. So interfaces have to cater to both audiences at the same time. While engineers may need all the details and want to exercise control over how a transaction is performed, the early adopters tend to flock towards apps that remove the complexity and offer an opinionated (fastest transaction speeds), but simple experience. Building interfaces that cater to both may be the order of the day where interfaces can reveal more complex controls on demand. 3. Changing Visual Styles: A couple of years ago, all of Web3 was specifically looking inwards and there was a strong visual identity. Colours were saturated, there were a ton of gradients, a lot of space themes, a lot of orbs, balls and atoms and felt very cutting edge. And everything was dark themed, possibly because the audience it was catering to were mainly male developers. But things have been changing. Things have grown a lot lighter now and the visual language has become a lot more accessible to the mainstream. The copy used on the websites also seem to be plain English these days and not filled with jargon and acronyms. What’s in it for you?After all that’s been said above, if you still need a reason to get into web3, here are a few: Enormous Growth in the Field: 2024 was a great year, but 2025 is looking to be an amazing year ahead for the industry. Now is the best time to to get in, learn and contribute to this field. Imagine being able to catch the next wave of technological growth at the right time. You’ll do phenomenally well. Professional Growth: If you’re tired of building ecommerce portals, come over to Web3 because you’ll be working on something brand new everyday. Decentralised Finance, NFT projects, decentralised social, decentralised science, etc. these are all fields within Web3 that are being discovered everyday. If you’re interested in learning new things and staying on the bleeding edge, you should definitely consider the shift. Set Standards: There are several aspects that haven’t been figured out as yet. If you’re anything like me, you enjoy working in the unknown and figuring out and building standards. As an example, a project called Uniswap presented a very simple interface for swapping tokens and that’s become the de-facto standard interface that is being used anywhere tokens are swapped. Or take the way Metamask did on-boarding, that’s become the standard for all wallets today. In the same way there are a ton of other aspects of Web3 that are still being figured out and you could be there contributing new ideas into the mix. Do it for the money: If nothing else, do it because the money is good. Web3 projects typically pay very well because there aren’t a lot of designers who understand it. But that’s not all. Contributors are typically also given project tokens as part of the compensation in place of ESOPS. While some ESOPS go up by 20% if you’re lucky, tokens on the other hand can sometime go up by 20X, so in case of an upside, the values could be life-changing. ConclusionJust as AI transformed from a sci-fi concept to an everyday reality, Web3 is following a similar trajectory. We’re already seeing traditional companies like MicroStrategy transform its business by simply holding Bitcoin, growing its market value from $1. 1 billion in 2020 to over $8 billion in 2021. And that’s just from using cryptocurrency as a treasury asset. You can imagine the potential when companies fully embrace Web3’s capabilities: decentralised operations, user-owned data, and transparent transactions. As a UX designer in Web3, you’re not just designing interfaces – you’re designing the future of digital interactions. The challenges are significant, but so are the opportunities. Start small, focus on user needs, and don’t be afraid to challenge conventions. Remember, every great interface began with someone asking, “Couldn’t this be simpler?” That’s your mission in Web3. The technology is ready; now it’s time to make it human. Accompanying Video"
    }, {
    "id": 14,
    "url": "http://localhost:4000/blog/how-to-hire-design-agencies/",
    "title": "The Ultimate Guide to Hiring the Right UX Design Agency",
    "body": "2024/11/15 - It doesn’t matter that the design agency has a high rating if they aren’t a good fit for your project. But how do you find the right one? The Ultimate Guide to Hiring the Right UX Design Agency for your ProjectIntroduction: When I used to run my UX design agency, we had a lot of clients that came to us after already having worked with another agency for the same project. Upon enquiring as to the reason for them to switch to us, we often were told some version of “The other team just didn’t get what we wanted”. The vain side of me would have been pleased, and I often was in the beginning, until I learnt that these situations weren’t only caused by mistakes made by the vendors, but also by the businesses that hired them.   If you’re a business that’s interested in hiring a UX design agency, read this article to avoid paying twice for the same thing and learn to hire the right agency for your project the first time! Understanding UX DesignA sure-fire way to hire the wrong agency is to not understand what UX design can do for you. Design, unlike art, is about solving problems. The job of a UX designer is to develop a solution to the business problem that you articulate. They translate the business objective that you set, into the form of an application that will help achieve that goal. They do this while balancing the needs of the customers against the business interests while working within limitations posed by technology and also by your company’s brand. It isn’t a simple task but I hope you can see that it takes a special blend of someone that is business oriented, technically adept, artistically inclined, detail-oriented as well as sensitive to culture to do this job right. A good design agency will be a partner in helping you achieve your goals, not someone who will spit out something pretty to slap onto your website and call it a day. You on the other hand, should be figuring out the right way to engage with such a person or a team and demanding the right kind of output from it. So, typically people hire UX designers to do one of the following:   You have an idea for solving a certain business problem with software and you want to develop a prototype in order to further refine that idea and bring it into a form that is more real than just an idea.   You want to reduce the overall costs of software production by working out all the kinks and details on paper as it were, before handing it off to a developer to build out — the “measure twice and cut once” approach.  You need to bring all the disparate ideas of a bunch of stakeholders from across your organisation and put it into a cohesive form of a software application.  You want to build a prototype and build consensus across all the major stakeholders within your organisation before allocating budgets and building it out.  You want to get the product designed in order to plan out the efforts and expenses required in order to get this product built. It will also help you decide what the budget allocations need to be.   Preparing a Brief As highlighted above, it is imperative to the success of the project that you take the time to define your business objectives clearly. Try being as specific as possible, by describing things like, “We have had most of our customers purchasing items from within a single vertical, but in an ideal world, every user landing on the website would generate a cart value of $2,000 with products from across three different product verticals”, or, “Our customer service division has some of the highest churn rates and this makes it difficult to impart the brand values of our company onto new hires so that they can interact with customers in line with the way we do things here”, etc. Unless it is critical for some reason, do not make the mistake of specifying how this should be done too early on. For example, don’t say, you need a website, an iOS app, etc. to do these things. It’s the design team’s job is to figure out the “how” of it all. Even if they will eventually land at the point of developing a website, etc. they sometimes may surprise you by solving the problem in another way that you may not have anticipated. One of the interactions that I remember fondly was with this client who was patiently listening to my team’s pitch as to the right solution to the problem he had stated previously. When one of his employees started to correct me about the mental model that I had used for designing the application, the boss, knowing fully well why he had hired us, politely interjected and asked the employee to allow me to finish. In the end, they were pleasantly surprised that we had removed an unnecessary layer while still achieving their objective. This wouldn’t have been possible if they had been hyper prescriptive about the solution they needed. Finding Potential AgenciesWhile the best method of finding a UX design agency is through a referral of someone that has worked with the agency because you’d also understand the fit, searching online and finding them on lists such as Clutch may be inevitable.   a. Rankings: One thing to keep in mind is that the rankings are not always completely objective. Their methods of evaluation aren’t so granular that you can reliably pass a judgement that someone ranked 20 is definitely better than someone ranked 30. While we were ranked among the top 20 within India and 100 in the global ranking, I really would pay more attention to whether the agency is a good fit for you, which is the most important thing. Still, these lists are undeniably a great resource to rely upon while looking for design partners. b. Local vs. Remote: Design agencies can work remotely, but, I’d give the one that can come into your office a few times a greater preference score than an agency that absolutely cannot. There are specific stages, like discovery discussions, brainstorming, user testing, pitching ideas that could benefit from being done in person. So if the agency you are looking for can come into your office for these meetings specifically, it would be great, but if that’s not at all possible, it’s should not be a deal-breaker in any way. c. Industry Experience: If your project has to do with improving an existing system of some kind, then industry expertise may help as you’d probably spend less time in explaining some fundamental ideas to the designers. But if you’re breaking new ground, I’d give less importance to the designers having the industry experience because most designers will learn the intricacies of the industry anyway, but also because designers that are new to a field may evaluate it with fresh eyes and see things in a different way which may be exactly what the doctor ordered.   d. Alignment of Values: There is a subjective aspect to design and that’s to do with taste. Some design agencies are drawn to flash while others are drawn to quiet efficiency. Some designers may take short-cuts to solving problems quickly while others take the long but reliable paths. In all these areas, taste matters. Don’t make the mistake of hiring a designer that clearly shows you one quality in all their work and expect that they will deliver on another quality that you want. You are never going to be able to demand every little be made a certain way. Engaging an agency inherently means that you are relying on them to make several micro-decisions on your behalf. So engage wit the agency that resonates with you so that you are going to be comfortable with these choices that they will make on your behalf.   Important Side Note: Do not evaluate design portfolio’s solely based on visual design expertise, unless that’s the requirement. FiltrationOkay, so you’ve succeeded in short-listing a few design agencies that you want to work with. Now you’ve got to figure out which one of these is the right fit for you. The filtration process should help you find someone that is technically proficient, someone that has not portrayed themselves as something more than they are, someone who fits your culture and finally fits your budget.   To do this, you could begin by requesting a proposal from each of the agencies. You can call these agencies up and have a brief discussion with them on the phone. They may request a brief from you which you can send out to them. How long they take to send out a proposal to you would itself indicate whether they have their internal processes figured out or not. Once you get the proposal, that itself becomes a good device to evaluate the capability of the agency. You see, if they are good UX designers, they would make this process easy for you right from the get go. Their proposal will clearly spell out what is involved in the process, give you firm estimates of time and costs and also detail out the payment schedules. It would have been designed to answer all the questions in your mind about engaging the agency. If it does not, this is a sign of immaturity and likely a strike against the agency.   Post this, typically the agency may request a time slot to walk through the proposal with you. You could also request the same if they don’t offer one. In this call, make sure to cover the following questions:    How do you evaluate the success of your design? Design is a solution to a problem, and UX design is usually employed to solve business problems. The work that UX designers do there are not subjective but instead very clear solutions to business problems. If the design isn’t helping achieve that business goal, then the design isn’t successful.     Have you done any work in my field? If not, what would your approach be in the design of our application? If they have worked in the same field, you’d be able to evaluate things on an apples-to-apples basis, but if they haven’t, you’ll understand how they’d approach learning about the field first and then solving the problem.     What has been the effect of your application design? Is there data to substantiate the success? While the external design agency may not always have access to the data and analytics that emanated from their design work, this question will still let you assess whether the designer understand that their work is always based on a hypothesis and always an experiment that needs to be evaluated.     What has been the biggest reasons for delays in your past projects? This question evaluates whether they’ve seen delays in past projects. There definitely will be a few where delays have occurred, and this is quite natural in endeavours that have a lot of interdependencies between clients and vendor teams. So the point is to probe whether they’ve understood what causes a lot of delays in projects and what steps they’ve taken to improve the process.     Have you determined issues with your design and fixed them after the initial design was delivered? This goes back to the point about what designers think about their work. No matter how much research is done ahead of time, every project is based on several assumptions from the clients and from the designers, they are all based on a hypothetical understanding. The truth can only be learnt by putting the design in the hands of users and evaluated at that time. There will be things learnt that will reinforce our assumptions, but there will also be things that we will learn that could be improved. There is never a situation where everything is perfect. In reality, the designer may never have information on how things performed because the client may never share such information with external vendors. But the question is meant to probe whether designers understand the temporal nature of their work and what they do to improve their understanding and provide better solutions.  Red FlagsAn architect friend once mentioned this idea of inspection points. They said that if you want to examine the quality of construction of a building, you don’t need to go floor by floor and examine the beams, you can just go to the basement and look at the pillars there. If there’s any major faults in construction, the first place the weaknesses will show up will be on these pillars. In that same spirit, the following are some things that will indicate the quality of the agency that you’re working with. 1. Acronym Overdose: Acronyms are useful to express some ideas a little more efficiently. But it’s overuse stems from ineptitude or from a desire to hide behind them to hide a lack of knowledge. In any case, the job of a UX designer is to be understood, not to obfuscate. So if they’re not demonstrating an ability to speak to you, their potential clients, in a way that you can understand, they definitely will not be able to help you communicate any better with your end-users.   2. Disinterest: For a designer to really help you succeed, it is imperative that they understand your true motivation behind working on this project. A good designer will definitely probe to find out this answer. If any of these designers haven’t bothered to do this, they will definitely not be delivering anything great for you. 3. Absolute Certainty: Regardless of how much experience an agency has, all design work is based on a hypothetical understanding of what the problem is and the design itself is a best-guess estimate of the solution. This is because the number of variables change from project to project including end-users. So be vary of the agency that states with absolute certainty that they have the right solution. They are more likely to make mistakes than those that approach the project with humility. 4. Financial Discipline: If a designer doesn’t convey their payment schedules in their proposal, they are inexperienced and don’t have enough of an understanding of the impact of finances on the execution of a project. There have been agencies that have had to stop working on their client projects midway. This is clearly a result of the agency not understanding their processes well enough and knowing how much money they will burn while working on your project. Budget ConsiderationsEven if you’ve not previously estimated how much you should spend for UX design, you would now have a great idea of how much it would cost based on the proposals that you would have received from the agencies that you reached out to.   But I understand that a lot of businesses are perplexed by the idea of paying too much for something and they want to know what the “fair market value” is. I find the idea absurd as this is not a commodity where you can substitute one designer’s output with another’s. If you find a designer whose output you like, then the “fair market value” is whatever they want to charge you then, isn’t it? But then this argument may fall on deaf ears and sound less “rational” to some, so in an effort to provide a rational answer, you could do the following exercise. First, find out how much it would cost to employ a UX designer with about 2 years of experience on a full-time basis in your area. Divide that by 12 to get their monthly salary. Then, multiply that by 5 as a project typically requires the efforts of 4 people with varying levels of experience on a non-100% utilisation basis. That number is what you should expect to pay on a minimum (not maximum) for each month of engagement with any agency. There is no maximum that you can pay as the sky’s the limit. There are premiums you could add onto this for star designers on the teams or if the agency can bring additional skills to table, like motion design, film production, over an above the base level UX design. If your company is cost conscious and wants to find a way to reduce the costs, you could try to work across geographies. Vietnam, India and Ukraine have some great English speaking UX design agencies that can provide you a lot of value for up to 40% less than what it would cost you in the US or Western Europe. Important Side Note: The idea that you could hire four designers only for a few months and have them pull off a great output is absurd. A few of my clients at my agency have been those that have tried to do this and failed and then decided to hire an agency after all. They typically spent 1. 5 to 2 times what it should have cost them in the first place, so keep that in mind.   Reviewing Agreements and ContractsQuite often large companies have standard boiler-plate engagement contracts for service providers, but in case you don’t you could request the engagement contract from your agency. Very often, if the proposal is detailed enough, that itself could be used to sign and formalise the engagement with the agency as it would contain all the usual terms that are covered in legal contracts.   While there are very few “gotcha’s” to look out for, here are some key clauses that you want to examine before you sign the agreement.   1. Scope: Please make sure that all that you intend to cover in this project is covered in the scope section. Despite any conversations that you may have had, the engagement will only be decided based on what’s covered in the scope section.   2. Delivery Formats: For UX design, the output is typically required by development teams, so make sure that they are receiving the following to make sure that your  3. Fixed Costs: Please make sure that you are working with the agency on a fixed-cost basis. They may ask you to pay on an hourly-basis for additional work, but whatever is covered within the scope should be delivered within the costs specified. 4. Ownership of Intellectual Property: While most agencies will be on a “work-for-hire” contract basis, be sure to clarify that all intellectual property developed through this project will belong to your company. This will help you use the output of the project to your benefit and further development in the future. 5. Non-Disclosure Agreement : There will be several things that you discuss about your business in order for the agency to design their application. Make sure that the agency cannot disclose this information about your organisation without your permission. Having this agreement in place will also allow your team members to speak openly and freely with the designers allowing them to develop applications that more accurately serve your needs. 6. Support: Every design agency will need to provide support post the delivery of their work. Documentation will only go so far and some live support will be required once in a while to explain some intricacies of the design. Make sure that the contract includes a support period post delivery and also a method to seek support well after that as that is required sometimes. Get this for remote support as well as for in-person support if that’s an option. Freelancers vs. AgenciesI must speak a little about hiring freelancers as that’s often an alternative that’s considered by businesses often. As I’ve been a freelancer before building an agency, I think I am in a good position to answer this and also argue for one over the other.   It is my considered opinion that businesses should only hire freelancers in very specific situations:  The project is very cost sensitive The project is a one-off and does not have long term impact You already have done enough research to guide the designer You are okay with delays You are comfortable with the skills that are being providedFor all other situations, there is absolutely no reason to hire freelancers, because with a freelancer, you get the wisdom of just one person. Design requires a lot of debate, and that’s hard to achieve as an individual, not impossible, but hard. Their learnings may also be limited as they typically are employed only on small and short term projects. I’ve seen cases where the freelancers don’t show up to meetings, they have ended projects without notice, or have behaved in unprofessional ways. Clients have thereafter had to find ways to scramble and recover from these setbacks. So for these reasons, I suggest working with teams where these problems are usually not prevalent. ConclusionA friend of mine sells bicycles and I went to him when I wanted to get into the sport. When I asked him to recommend a bike, he showed me something that was well over the amount that I had anticipated paying for a bike. So I said that since I was just getting into riding bikes, I wanted to get one that wasn’t so expensive and then if I like the sport, I would buy something more expensive.   What he said in response remains with me till today because it is extremely relevant to my field. He said that if I was serious about getting into the field, I should be getting the best bike I can afford, because buying the wrong bike will actually make me hate the sport.   I relate this story because it’s a great metaphor for choosing the right agency. If you make the wrong choice of agency and develop the wrong app based on their work, you may end up attributing the failure of the app to the weakness of the idea behind it. You may even end up making the wrong business decision whereas you may have come to a very different conclusion if you had just made a better decision while choosing the right agency. Having said that, I hope this article is useful to you in making the right choice. But if you need any help, do reach out to me once you’ve shortlisted your agencies, and I’d be happy to help you make the final choice! Accompanying Video"
    }, {
    "id": 15,
    "url": "http://localhost:4000/blog/creating-proposals-that-convert/",
    "title": "Design Proposals that Boost Conversion Rates",
    "body": "2024/11/05 - Building proposal templates takes a lot of effort and you’re still left unsure of whether you’ve done it right. This article tries to help you fix that. Creating a Winning UX Design Proposal: A Comprehensive GuideCrafting a UX design proposal can be challenging, but it is also an invaluable tool in securing new projects and demonstrating professionalism. A well-structured proposal not only showcases your understanding of the client’s needs but also reflects your agency’s strengths and your ability to foresee potential project challenges. Based on my years running a UX design agency, here’s a guide to creating a compelling proposal that can boost your conversion rates and help you stand out. 1. Understanding the Purpose of a Proposal: A proposal is essentially the answer to the client’s questions before they commit to hiring you. They want to know if you understand their project, if you’re aligned on goals, and if your capabilities and deliverables match their expectations. Answering these questions clearly within your proposal gives clients the confidence they need to move forward with you. 2. Key Components of a UX Proposal: To make your proposal thorough and professional, include these eight essential components: Project Summary: The summary should ensure everyone is on the same page. Here, outline the specific project objectives, emphasising the agreed-upon approach. If your agency has unique strengths, such as a technical or development background, this is the place to highlight them. This section serves as a commitment to the client, defining exactly what you’ll focus on. Feature List: One of the most time-intensive sections, the feature list outlines the project at a high level, covering major elements without getting overly technical. For instance, if the project includes user authentication, mention this as a feature but avoid specific technical details like whether it will include OTP verification. This list demonstrates thorough planning, showing that you’re not just sending a generic proposal. Scope of Work: Outline all the deliverables you’ll provide. This section can also serve as a showcase for your agency’s full capabilities, even if some services aren’t part of this specific project. For example, list everything from wireframing to prototyping, and clarify which tools and formats you’ll use. Ensuring clarity on deliverables avoids confusion later on and establishes a sense of professionalism. Team Structure: Explain who will be working on the project, their roles, and their experience levels. This can include a project manager, UX/UI designers, and other support roles like content creators or icon designers. Detailing your team structure justifies your pricing, showing the client that the work involves skilled professionals rather than being handled solely by a generalist. Engagement Guidelines: Set out expectations on both sides. Define a single point of contact (Spock) on your team and request the same on the client’s end to streamline communication. Specify a regular meeting cadence, like weekly check-ins, to keep the project on track. This section also covers managing scope changes and clarifies your availability to avoid client requests at odd hours. Support: Support goes beyond project completion, as clients may need assistance once the design phase is over. Typically, offer 30 days of support post-handover to handle clarifications and minor adjustments, but make it clear that extensive support beyond this window will incur additional charges. This also includes defining the method of support, whether remote or on-site, with associated travel costs if needed. Cost and Packages: Costing can be a make-or-break aspect of your proposal. Offering tiered packages—bare minimum, standard, and premium—can appeal to different budgets and give clients flexibility. Using a worksheet to customise package features and pricing quickly allows you to respond to client requests efficiently, showing professionalism and organisational readiness. Payment Schedule and Protection Clauses: Establishing a payment schedule is essential for cash flow and client commitment. A common approach is 50% upfront, 25% midway, and the remaining 25% upon completion. Clearly state conditions for payment delays, such as the right to halt or terminate the project if payments are not made on time. Including protection clauses safeguards your interests, and clients typically view them as standard business practice. Additional Annexures: Finally, append any extra information that can strengthen your proposal, such as:  Company Overview: Highlight your agency’s expertise and how you stand out. Large clients, especially, may appreciate a quick reference on your background without needing to research separately.  Client Portfolio: Showcasing similar past projects builds credibility. If your client seeks an e-commerce solution, for example, list other e-commerce projects you’ve completed to demonstrate your experience.  Team Bios (Optional): If certain team members have notable expertise, add brief bios. This personal touch can reinforce the unique value you bring to the project. 3. Recognising Common Proposal Traps: Not all proposal requests are genuine. Some clients may seek proposals simply to benchmark costs, fulfil internal bidding quotas, or collect ideas without intending to hire. Though you can’t always avoid such situations, by treating ideas as renewable and presenting your unique perspective, you position yourself as a resourceful, innovative partner for potential clients. 4. Automating for Efficiency (to an Extent): Automating repetitive proposal elements, like feature lists or pricing structures, can streamline your process. However, automation shouldn’t replace human interaction altogether. Proposals play a vital role in assessing potential clients and understanding their unique needs, so a fully automated system risks undermining this relationship-building opportunity. I chose to keep personal contact integral to my process, which allowed me to enjoy a diverse range of projects with clients I valued. ConclusionA well-crafted UX design proposal is more than a sales document; it’s an opportunity to build trust and set clear expectations with clients. By including comprehensive components, adapting to different client needs, and presenting a strong sense of your agency’s capabilities, your proposal can serve as a valuable tool for both winning projects and ensuring smooth collaboration throughout. With this framework, I hope you’ll find the proposal process smoother, more efficient, and ultimately more successful. Accompanying VideoUseful Items Mentioned General Purpose Proposal Template for UX Projects General Purpose Proposal Worksheet"
    }, {
    "id": 16,
    "url": "http://localhost:4000/blog/web3-wallets-for-mainstream-users/",
    "title": "Designing Web3 Wallets for Mainstream Users",
    "body": "2024/09/30 - There is a problem with Web3 wallets, they’re just too complex. But where’s the problem stemming from and how do we solve it? Web3 Wallets for Mainstream UsersWeb3, the next phase of the internet powered by blockchain technology, promises to revolutionise industries, but its complexity continues to alienate mainstream users. At the heart of this challenge is the Web3 wallet—a fundamental tool required for engaging with decentralised applications (dApps), managing cryptocurrencies, and accessing blockchain networks. While Web3 enthusiasts have embraced the wallet system, its cryptographic foundations and technical jargon have left everyday users overwhelmed and frustrated. To drive mainstream adoption of Web3, we need to focus on fixing the wallet experience, making it intuitive and accessible. In this blog, we’ll explore why the wallet is the crux of Web3 usability challenges and how a thoughtful redesign grounded in familiar concepts, like banking, can unlock its full potential. The Wallet Conundrum: Complexity Meets Confusion: The primary function of a Web3 wallet is to store a user’s private and public keys. These cryptographic keys are used to authorise transactions and prove the user’s identity within the blockchain ecosystem. But this process, while secure and revolutionary, is incredibly foreign to non-technical users. Terms like “private key,” “public key,” and “signing messages” can cause even the most tech-savvy Web2 users to shy away. The need for simplification is apparent. In Web2, users can easily send and receive money through banks or payment apps without ever having to understand the mechanics behind these systems. Web3, by contrast, demands users grasp cryptographic principles or risk losing access to their digital assets. The complexity isn’t just a barrier; it’s a deterrent. Many existing wallets, such as Zerion or Rabby, have attempted to ease the user experience by iterating on older designs. And while they have indeed made Web3 more user-friendly, they still fall short of the mainstream appeal necessary for broad adoption. These wallets are excellent by Web3 standards, but they remain inscrutable for the average Web2 user, leaving us to ask: Why can’t a Web3 wallet be as intuitive as the apps we’re already accustomed to? Terminology Matters: The Language of Web3: A significant part of the problem lies in the terminology itself. In Web3, terms like “wallet” are used inaccurately. In traditional banking, a wallet implies a place where you store something—cash, cards, and other financial instruments. However, in Web3, a wallet doesn’t “store” money in the traditional sense. Instead, it acts more like an access card to funds stored on the blockchain. Misleading terminology adds to the confusion, making it harder for users to understand how to manage their digital assets. Open-source development, which is central to the Web3 ecosystem, has contributed to this confusion. Over time, various developers have used different terms to describe the same concepts, leading to inconsistent vocabulary across platforms. For instance, “public key,” “wallet address,” and “externally owned account” all refer to the same thing, but new users won’t know that. This inconsistency hinders their ability to trust and navigate the system confidently. Language is powerful, and when users encounter familiar terms, they can better grasp unfamiliar concepts. Web2 sites like e-commerce platforms utilise relatable language (“add to cart,” “checkout”) that immediately makes sense to users. The same approach needs to be applied to Web3 wallets if we want to make them accessible to the average person. Building Familiarity: Banking as a Metaphor: To solve the wallet problem, we need to rethink the entire framework. Instead of framing wallets with cryptographic jargon, we should use a metaphor that resonates with mainstream users. And what’s more familiar than banking? Banking is a 2,000-year-old institution, and most people are already acquainted with its core concepts. By reimagining the Web3 wallet as a piece of “banking software,” we can translate complex blockchain concepts into terms users already understand. For instance, the wallet itself could be referred to as “banking software,” the wallet address as an “account number,” the private key as a “signature,” blockchain networks as “networks,” and the various fees associated with a transaction such as “tip”, “gas” and such could be simplified into “transaction fees,” just as people are used to paying on traditional payment platforms. This banking analogy would not only make Web3 wallets more relatable but also help ease users into the system without overwhelming them with technical details. A Three-Account Structure: Enhancing Security and Usability: In addition to simplifying the terminology, a redesigned Web3 wallet should also mimic the structure of traditional banking. A banking app typically offers various types of accounts—checking, savings, and investment—and the same can be applied to Web3.    Checking Account: This would be where users conduct everyday transactions with known entities or individuals, similar to a checking account in traditional banking.     Savings Account: This would serve as a secure place to store assets, where users could stake cryptocurrencies or simply keep them safe. It would allow users to generate interest on their holdings without needing to interact with external applications.     Investment Account: For users seeking higher risk and reward opportunities, this account would enable interaction with decentralised applications (dApps) for staking, lending, or other investment activities.  This compartmentalisation not only makes the system more intuitive but also enhances security. By limiting the interactions of the checking and savings accounts with external applications, users can reduce their exposure to potential security risks. Only the investment account, which is meant for higher-risk activities, would be open to external dApps. The Road Ahead: Evolving Web3 for the Mainstream: In conclusion, the wallet is the linchpin of Web3 adoption. If we can make the wallet experience seamless and intuitive, we can unlock Web3’s immense potential for a wider audience. The key lies in rethinking both the terminology and structure, using familiar banking concepts to demystify the process. By addressing these foundational issues, we can bridge the gap between Web2 and Web3, paving the way for mass adoption. For designers and developers working on Web3 applications, this means prioritising usability over technical prowess. It means considering what mainstream users already know and building upon that knowledge, rather than introducing new, foreign concepts. The future of Web3 is bright, but only if we can make it accessible to everyone. Video with screens"
    }, {
    "id": 17,
    "url": "http://localhost:4000/blog/5-personal-ai-assistant-devices-reviewed/",
    "title": "Five personal AI assistant devices reviewed and what they need to fix",
    "body": "2024/09/12 - The world of AI assistants has taken a sharp leap forward with new devices emerging every year. However, despite the excitement around these personal AI assistant devices, many haven’t lived up to their full potential. Having headed a UX design agency ranked among the top 100 globally, I’ve seen firsthand the challenges and nuances of designing new tech. Today, I want to share with you seven critical mistakes these products are making—and how I believe we can fix them. Why Aren’t Personal AI Assistants Taking Off?: Before diving into the nitty-gritty, let’s get one thing clear. The personal AI assistants I’m referring to aren’t like Siri or Google Assistant on your phone. We’re talking about devices that can break down complex tasks and execute them for you—whether it’s running apps, searching the web, or even coding in some cases. These devices are mostly aimed at early adopters right now, but the goal is to create something for everyone. If you picture the product adoption lifecycle, we’re still in the early adopter phase. Right now, companies are testing their products in different niches, trying to figure out what sticks. It’s a chaotic phase, and we’re seeing an explosion of ideas—some good, some not so much. A lot of these ideas won’t make it to the mainstream, but that’s what makes this phase so exciting. Now, let’s dig into the seven mistakes these AI assistant products are making and how I think they can course-correct. 1. Not Using the Right Metaphor: The first mistake is starting with the wrong metaphor. Products need to fit into a framework that users already understand. People don’t like adopting something completely alien. I always say evolution trumps revolution, especially in mass-market products. Finding a metaphor that connects the new with the familiar is crucial. AI assistants should be positioned as an evolution of tools people already know, not a radical shift that alienates potential users. 2. Limited Accessibility and Reachability: For an AI assistant to succeed, it needs to be extremely accessible. Think about the evolution of computing—from desktops to laptops, tablets, smartphones, and now wearables. The goal is to bring tech closer to the user. Personal AI devices need to occupy that space between a smartphone and the user—something wearable that’s always available at a moment’s notice. Users are going to need to learn a new behaviour—one where they think in terms of goals, not apps. The easier we make it for them to access the assistant, the quicker they’ll adapt. ^1c44a7 3. Lack of Multimodal Inputs and Outputs: Let’s be honest—audio alone isn’t enough. Yes, voice commands are intuitive and efficient for certain tasks, but information needs to be delivered in various ways. Visual feedback, like images and text, allows users to process information faster. Devices that rely only on voice, like some AI pins or pendants, miss out on the efficiency that visual data provides. The solution is to design devices with both visual and auditory outputs. 4. Poor Data Privacy Protections: With AI, the question of privacy becomes even more critical. These devices will have access to mountains of personal data, and without strong privacy protections, they could easily become surveillance tools. The safest way to ensure privacy? Keep the data on the device itself. I think open-source projects like Open Interpreter, which runs locally on the user’s device, are on the right track. This model protects privacy and offers immediate feedback—something that cloud-based models struggle with. 5. Lag in Response Time: For AI assistants to feel natural, they need to respond quickly. Research shows that interactions that take longer than 400 milliseconds feel slow and clunky. Devices relying on cloud-based AI models are always going to have some lag, no matter how fast the server is. To hit that magical threshold of 400 milliseconds, AI models need to run locally on the device. Otherwise, users will experience delays that break the flow of interaction. 6. Lack of Interoperability: We’re transitioning to a new kind of computing—one where AI agents handle tasks for us. These agents need to be able to interact seamlessly with existing systems and applications. If a user wants their AI assistant to book an Uber or play a song on Spotify, the interaction needs to be flawless. Devices that struggle with this will quickly fall out of favour. The future belongs to AI assistants that can bridge both the current and future computing models. 7. Failure to Create Universal Interfaces: The final mistake I see is the lack of universal, adaptable interfaces. Every request a user makes might require a different interface—one that adapts in real-time. If I ask my AI assistant to book an Uber, the interface might display a map. If I want to pick between two songs, I’ll need a list. These interfaces need to be generated on the fly, based on the user’s specific request. A rigid interface simply won’t cut it. The Future of AI Assistants: In my opinion, the best form factor for personal AI assistants is a wearable device—specifically a smartwatch. It’s close to the user, easy to access, and can incorporate the necessary screen for visual feedback. While today’s smartwatches may not have the power to run advanced AI models, the tech is catching up. With chip technology becoming more efficient and AI models getting smaller, we’re not far from a future where AI-powered smartwatches will be the norm. Ultimately, while none of the current products on the market have quite nailed it yet, some are closer than others. But in the end, it’s the big players—Google, Microsoft, and Meta—that are best positioned to dominate the personal AI assistant space. They have the data, and in AI, data is king. As much as I root for the underdog, I wouldn’t bet my money on any of the current startups trying to break into this space. The race will be won by those with the resources to gather and process the vast amounts of data required to create truly effective AI assistants. Watch the Video"
    }, {
    "id": 18,
    "url": "http://localhost:4000/blog/feature-requests-made-better/",
    "title": "Designing a better feature request system",
    "body": "2024/08/06 - If we get feedback and feature requests from users regarding products we’ve built, we get valuable insights into understanding what the users want. This is a great place to involve LLMs to handle the issues involved in this process. OverviewThis feedback system will do the following:  It will allow users to submit their feature requests To handle the problem of faster horses, it will produce a page where users can vote on things they didn’t think of before It will show a priority list to product teams that will allow them to understand what to develop next The same idea can be ported to handling bugs, but it needs to be a separate system altogether"
    }, {
    "id": 19,
    "url": "http://localhost:4000/blog/raspberry-pi-timecapsule/",
    "title": "DIY: A Raspberry Pi based Time Capsule",
    "body": "2024/08/04 - I built an efficient Apple Time Capsule clone that will perform the task of allowing any externally connected hard drive to be used as a backup destination using the Time Machine setup on your Mac. What this is: If you want to build your own Apple Time Capsule clone using the Raspberry Pi and an external hard drive, this is the slimmest and most efficient solution that you could build in under an hour, without the bonus 3D printing bit in the end of course! You may also be successful if you just follow the steps below, but there’s a step where you need to find your Raspberry Pi on your network and reserve a specific IP address in your router which I won’t be going into that may require some prior knowledge. What’s unique about this solution: This solution has the following characteristics that make it different from other solutions that you may have seen:  You don’t need any other software such as Open Media Vault, which is great if you want to do a whole bunch of other things, but is too much of an overhead if all you want to do is build a network backup solution This could be setup on very low horse-powered boards like the Raspberry Pi 3A+ as it runs with the services built into the OS This solution works with more than one Mac on your network It can do this for guest logins on a network and doesn’t require an account to be setup on the Pi, so this makes it easy to use for a home environmentRequirements: You need the following as a minimum:  Raspberry Pi 3 Model A+ with compatible power supply Micro SD Card with 4GB or more External hard drive of any capacity that is compatible with the Raspberry Pi’s USB port The drive will work with most laptops using different OS’s in case that’s needed at any time Raspberry Pi Imager softwareSoftware Setup: Step 1: Create the SD card image: For this, simply do the following: 1. 1 Download the Raspberry Pi Imager software and open the file and follow the instructions to install the software on your Mac as you would any other software  1. 2 Plug in the Micro SD card into your Mac. It doesn’t matter if it isn’t already formatted. 1. 3 Choose the Raspberry Pi OS Lite (64-bit) image to write to the Micro SD card  1. 4 Choose the Micro SD card that you just inserted into your Mac as the storage destination and click ‘Next’  1. 5 In the next step of OS customisation, make sure to Edit Settings and in the first tab  1. 5. 1 Setup the host name – this is the name of your Pi on the network. I’ve called mine “pinstripes”, but you could just call it “timecapsule” or anything else you’d like  1. 5. 2 User name and password for the machine. I suggest you set it to the default username and password for now which are ‘pi’ and ‘raspberry’. You can change this later if you’d like. 1. 5. 3 Provide the SSID and password to enable it to connect to your Wifi network. You don’t need this if you’re using a different Raspberry Pi that connects using a LAN cable. 1. 5. 4 On the second tab called “Services”, make sure that you enable SSH and use the password authentication mechanism. This will allow you to remotely log into your Pi with the user name and password that you setup in the previous step.   1. 5. 5 Hit “Save” and in the next screen click “Yes” and then “Next” to begin the imaging step. You may need to type in your login and password for your computer to tell your computer that you authorise this action. In about 15 minutes your Micro SD card is going to be ready. Just eject your card if not already done before pulling it out of your computer. Step 2: Initialise your Pi and set it up on your network: 2. 1 Setup the host name – this is the name of your Pi on the network, so you could just call it “timecapsule” for simplicity or name it anything else you’d likePlug in your Micro SD card into your Pi and then plug in the power cable to the Pi. After about 5 minutes, the Pi would have booted up and then connected to your network over Wifi (or LAN in case that’s how you’d connected). You don’t need to plug in your external hard drive to the Pi as yet. 2. 2 Open up a Terminal window on a laptop on the network and type in ping timecapsule. local. Replace “timecapsule” with whatever you named your Pi in Step 1. 5. 1. This should return the IP address of your Pi on the network.   2. 3 Now type in arp -a and get the MAC addresses of all the devices connected to your network. Look for the Pi’s MAC address that corresponds to its IP address you found in the previous step. 2. 4 Now log into your router which assigns the IP addresses on your network and setup a fixed IP address for your Raspberry Pi’s MAC address. This whole thing may work without this address reservation, but I’ve never tested it. So if you absolutely cannot perform this step, just go through the rest and let me know if it works for you. 2. 5 If you’ve reserved a specific IP address for your Pi and it is different from the one it is currently assigned, you will need to reboot your Pi by turning off the power. 2. 6 Once your Pi comes back on your network, go back to your Terminal window and type in the following to log into your Pi through SSH - ssh pi@192. 168. 0. 10 where ‘pi’ is the user name and the IP address is the one that you reserved for your Pi in step 2. 4. If everything is setup properly, your Pi will ask you for a password and you could just type in ‘raspberry’ or whatever else you set up in Step 1. 5. 2. Step 3: Prepare your external hard drive: 3. 1 Get your external drive. Be sure you’re using a hard drive that doesn’t have any data that you want to retain as it will be lost forever once you’re done with this step. Connect the hard drive to your Mac. 3. 2 Use “Disk Utility” to Erase and initialise your external drive. Name the drive anything you’d like such as “TimeCapsule” but make sure to use “Exfat” and if asked, the “GUID” options for maximum compatibility of the drive across different OS’s.  3. 3 Once the process is complete, eject your drive from your laptop. It is ready for plugging into your Pi in the next step. Step 4: Get the software setup: 4. 1 While connected to your Pi through a Terminal window, do the following to update your Pi’s OS: 123451. `sudo apt update`2. `sudo apt upgrade`3. `sudo apt install exfat-fuse -y`4. `sudo apt install samba -y5. `sudo apt install avahi-daemon -y`4. 2 Once the above packages are installed, let’s mount the external drive. 4. 2. 1 Plug in your external drive into the Pi 4. 2. 2 Type in sudo df -Th which will list all the drives connected to the Pi. Find the identifier for your drive which should most likely be “sda2” but could be different too. 4. 2. 3 Create a mount point by typing in the following commands sudo mkdir /mnt/timecapsule and sudo mount -t exfat /dev/sda2 /mnt/timecapsule. Just substitute “sda2” with whatever the drive’s identifier actually is. 4. 2. 4 Type in the following to find the UUID of your drive lsblk -f and all the drives connected to your Pi will show up (including the Micro SD card). Look for the UUID of the drive with the label ‘TimeCapsule’ if that’s what you named the drive in Step 3. 2. Cross verify against the size of the drive to be sure. Copy the UUID into the clipboard. 4. 2. 5 To make the mount point persist across reboots of the Pi, you will need to add the following code to the file named “fstab”. You can do that by: sudo nano /etc/fstab 4. 2. 6 Paste the following in the end of the file UUID=your-uuid /mnt/timecapsule exfat defaults,uid=1000,gid=1000,umask=000 0 0 but replace the UUID with the one you copied to the clipboard in the previous step. 4. 2. 7 Press Ctrl-X to save the file, Yes to write the buffer to file and enter to rewrite the file. 4. 3 Now write the configuration file to Samba, which is the file networking service that shows the drive on a network in a form that is compatible with Macs and Windows. To do this, you need to write the following code into the smb. conf file by typing in sudo nano /etc/samba/smb. conf which should bring up the existing configurations in the file. Press the page down key on your keyboard to get to the end of the page and paste this and make sure the mount points are correct: 4. 4 Save the file as the other files in step 2. 5. 3 and then restart the service with the new configurations by typing in the command into your command prompt in the Terminal sudo systemctl restart smbd 4. 5 We’ve got to do the same for the avahi service configuration. To edit the file, sudo nano /etc/avahi/services/samba. service and paste the following code. There are no changes needed to be made. 4. 6 Save the file as in step 2. 5. 3 and then restart the service by typing in the following command sudo systemctl restart avahi-daemon I suggest restarting the device itself to make sure that it works even if it ends up restarting on it’s own in the future. To do this, type in sudo reboot now into your Terminal command prompt. This will disconnect your session and restart the Raspberry Pi. That’s it, you’re ready to go and setup the Time Machine backup from your Mac as always! Troubleshooting: If for any reason you don’t see the newly setup drive when you are setting up Time Machine on your Mac, try to connect to the drive first on the network by going to the Finder &gt; Go &gt; Connect to Server and then typing in smb://192. 168. 0. 25 replacing this with the IP address of your newly setup Time Capsule. You should be able to connect to the Raspberry Pi drive. Post that the Time Machine should automatically find the drive on the network. If for any reason this still doesn’t work, there’s probably some step above that you’ve missed. So give that a shot again.  Bonus Step: Make a case for the Raspberry Pi and the hard drive to be situated together. I’m designing something for this purpose and should have a 3D printable file posted here soon. Check back in a bit. But if you’d like to print something else, look at the plethora of stuff that’s available to you on Printables. "
    }, {
    "id": 20,
    "url": "http://localhost:4000/blog/where-the-puck-is-going-to-be/",
    "title": "Where the puck is going to be",
    "body": "2024/07/24 - Product design requires you to imagine the future version of a product, but how do you do it reliably? Ice Hockey may offer some insights. Ice Hockey and Product DesignAccording to the Wayne Gretsky quote that goes, “I skate to where the puck is going to be, not where it is”, the way to win is to accurately anticipate the future outcomes as accurately as possible. The principle could be applied to product design too. The way to design a successful product is to know what the next version of the product is going to be. But the challenge of knowing what that is as challenging as judging where the hockey puck is going to be on the ice rink. But while no one can be absolutely certain where exactly the puck is going to be on the rink at any given point in time, one thing everyone can be absolutely certain about is that the puck is headed towards the other team’s goal. In a similar way the product’s end goal is to suit the needs of the consumer perfectly. The consumer is human. The form the product must then take is to suit the form of a human body. If the product is meant to be held, it must fit the hand perfectly. If it is meant to be worn on the ear, then it must fit various ear types. If it is meant to be used over a period of time, then it must use materials that will not strain the user during that period. In terms of the function it performs, it must serve the needs of the human as accurately while also needing as little effort as possible. The final version of the product therefore is possible to define, at least in the abstract. If it’s not a physical product, the final form is one that serves the needs of the user perfectly and is extremely simple to use. Let me illustrate the idea with some examples. Consider the evolution of the USB cable. Type A USB cables required the user guess which way should be facing up before plugging it into a socket. Many users struggled with this and the act of plugging in the USB A cable into a socket was a hit or a miss every time. Making the cable pluggable into a socket in either orientation therefore was obvious. Therefore that’s what happened in the future iteration of the USB C cable. Another issue with the cable was that the sockets it plugged into on the other side was variable. There were the USB A plug, USB B plug, a mini USB plug and even a micro USB plug. You therefore had to have at least one cable of each type in order to be able to connect with various device types that one bought over time, not to mention the proprietary cables that were required by some devices like smart watches. Intuitively one can see that these were too many cables to basically perform the same task. Again, no wonder the USB C cable’s invention. As of the time of writing this article, the USB C cable too has various types, the ones that supply current and the ones that also transfer data. How long do you think that’s going to stay that way? The same principle can be applied to Generative AI tools – do you think specialised prompts are going to be required much longer; computer keyboards – are they more convenient than speech; or even subscription services – will Adobe get away with charging cancellation charges for their subscription service for much longer? Or even consider the iPad. What was it’s evolution? I’d postulate that it came about because someone thought that the computers of the time were too “unnatural” for a human to use. Having a user type using a keyboard to communicate something or using a mouse or a track pad to point at something is a hard challenge for people who aren’t familiar with computers. Humans communicate by speaking, they point to things with their fingers. The iPad is a step in that direction. What would the future of this device be? Well, a computer that let’s a user express themselves with all the tools they have at their disposal – from communicating with their voice, pointing with their fingers or even setting the context of what they’re talking about by facing in a particular direction or looking at something with their eyes. The display of the iPad is an intermediate expression of the limitations of current technology. The computer of the future will not be something that is picked up and stared at with your head bent down. If you think the Apple Vision Pro headset is a step in that direction, I would agree that it is. But it’s not the end point.  The end point is something that will be even more seamless. It will be an assistant that the user can just converse with, something that can understand the full range of expressions that humans can emote with their faces, eyes, hand gestures, body positions and language and it will be seamless and something that is worn and always available. It will enable the user to do and perform everything they need in the real world but also to understand and appreciate everything much more. For this to happen, we need a voice assistant with infinite knowledge and ability to learn about the human, wireless technologies that will seamlessly stay connected at all times, face tracking, body tracking, motion tracking, gesture tracking and even battery technology that will not only power something like this, but be in a form that is far more shaped like the person who will wear it. These intermediate states therefore are not dictated not by the human being it is meant to serve, but by other constraints such as materials available, the tools, technologies, the people available to build that next version, legal and environmental constraints, the organisational politics, available marketing budgets or even the designer’s inability to understand who the user is. But knowing that these are necessary stages of evolution will allow the designers to keep their eye on the eventual goal. The task of the product designer or even the entrepreneur building this product is to negotiate the most efficient course between the current state of the product through to the final destination it is meant to be. "
    }, {
    "id": 21,
    "url": "http://localhost:4000/blog/experiments-with-3d-printing/",
    "title": "My experiments with 3D printing",
    "body": "2024/01/24 - My foray into the world of 3D printing and my learnings and insights so far. This is work in progress and will continue to be edited. 3D Printing: A Journey into a Promising, Yet Challenging FieldBack in around 2015, I stumbled upon 3D printers during their nascent stage. The potential was clear, but the technology wasn’t quite there yet, and it was relegated to a niche space for tech enthusiasts. As a UX designer, my curiosity was piqued, especially considering the initial buzz surrounding its potential impact on ecommerce and logistics. However, being based in India at the time, affordability, availability of replacement parts, and local support were significant barriers to entry. Fast forward to 2023, I was blown away by an amazing YouTube video showcasing a user designing and printing all the shelves he needed for his desk, as well as custom SD card holders. This experience resonated with me, reminding me of the excitement I get when visiting a hardware store or a craft shop, imagining the possibilities of creating useful things. I was eager to explore this technology further and get my hands on a 3D printer to discover what I could create. The Right Printer for Me: Balancing Usability and Performance: As the 3D printing industry evolved, so did its focus on user experience. Although there are numerous resources available online for fine-tuning printers, many models offer excellent results straight out of the box. In terms of the printing technologies, I narrowed down my choices to Fused Deposition Modelling (FDM) and Vat Polymerisation (VP) printers due to their popularity in the consumer space. VP printing introduced some unique challenges like the need for ventilation and dealing with smells arising from resin. Given that I wanted the printer to remain in my study, I opted for FDM. After thorough research, I selected a printer that offered ease of assembly, maintenance, and accessibility to support. The Bambu Labs X1 and Elegoo Neptune 4 Plus stood out, but ultimately, I went with the Neptune 4 due to its lower cost and absence of proprietary parts. Unboxing and Setting Up: Overcoming Challenges Together: The delivery took around a month due to pre-ordering, arriving during Christmas holidays, offering ample time for me to delve into learning about 3D printing. The setup was straightforward, but there were some complications like ensuring the correct cables were connected and checking voltage settings on the printer bed. Although these tasks weren’t particularly challenging for a technologically inclined user, they required careful attention and a bit of research to ensure a seamless experience. Despite the occasional hurdles, the experience was rewarding, as I was able to build my 3D printer from scratch with all necessary tools supplied. The desktop software that came with the Neptune 4 pleasantly surprised me with pre-installed printable files of a tool stand for the printer! Designing: The Gap in the UX of 3D Modelling: The design process in 3D modelling is complex and requires a good understanding of visualising 2D cross-sectional shapes to create 3D objects. Sculpting tools like Blender are suitable for creating aesthetically pleasing, non-functional designs, while functional 3D design tools like OnShape offer the best capabilities for product designers. OnShape, a cloud-based platform, boasts responsive and great tools that keep users updated with the latest features. However, the pricing could use improvement to cater to hobbyists and make entry into this space more accessible. Simplifying design tools by incorporating user-friendly features specific to 3D printing would further enhance the overall UX. Design Marketplaces: Tools and Toys for Everyone: Websites like Printables and Thingiverse offer a wealth of user-generated designs, allowing anyone to download and print objects using their 3D printers. This sense of power to create and own is truly exhilarating, enabling users to go from ideation to tangible results in a matter of hours! However, there are challenges like inconsistent quality checks and potential issues with new designers’ designs not being fully optimised for mass consumption. Improving the user experience could involve implementing better quality control measures or allowing experienced designers to review and approve new designs before they are released to the public. Additionally, providing more comprehensive information about dimensions, filament requirements, and print time would significantly improve the overall experience. Printing: Turning Ideas into Reality: Printing in 3D isn’t without its challenges – files need to be converted from design formats (usually STL) to Gcode using slicing software like Cura before being printed. This step involves setting various parameters that determine the quality, strength, and speed of the final print. Although these steps are essential, they can be complex for new users. It is also not apparent to users that they may affect the final look of the object with the changes made to some of these settings. Streamlining this process by incorporating it into authoring tools would greatly improve the user experience. Until then, there are numerous resources available online to help users learn the intricacies of 3D printing, allowing them to enjoy the satisfaction of turning their ideas into tangible objects. Conclusion: A Promising FutureThe potential of 3D printing is immense, and I’m confident that significant improvements will be made to address the unique challenges in this space while keeping user experience at the forefront. Like with all the challenges solved in the 2D printing world, I envision 3D printers becoming an integral part of every household or as more likely, in the neighbourhood print shop. The key to realising this lies in simplifying the design authoring tools and making them accessible to everyone. Hurdles and Insights The plugging in of the cables for the gantry motors still requires some amount of understanding of connectors. This could be further simplified in future versions.  The printer plate travels outside the frame of the printer itself which allows a user to make the mistake of placing it too close to a wall and having to learn during printing that it needs to be moved. This could be explained as well.  Going from 2D to 3D is incredibly difficult and staying in the 3D space from the start would be ideal, but the tools we have today are limited in their ability to express these ideas.  Marketplaces are currently aimed at those that own 3D printers, whereas they should be aimed at the end-users of the products that are available on the sites.  There are two outcomes to the world of 3D printers, they will either become a part of every household of the future as 2D printers today are, or they will become a part of every neighbourhood print shop. "
    }, {
    "id": 22,
    "url": "http://localhost:4000/blog/rabbit-r1-review/",
    "title": "Review of the Rabbit R1",
    "body": "2024/01/10 - A detailed review of the newly launched Rabbit R1, exploring its hardware and software design, its strategic position in the market and its potential challenges The Launch of Something NewTo say that the Rabbit team mimicked Steve Jobs’ keynote would be an understatement! The only thing missing was the Vera Wang turtleneck—it was a black t-shirt instead. Otherwise, the presentation featured the same slide style from Apple Keynote with the gradient, the same format, the hand gestures, and even the “One more thing…” announcement at the end. But OnePlus did this before too, turtleneck included. While it was considered cringe-worthy at the time, the product compensated for the lack of originality in the presentation. So, let’s not dwell on style and focus on the substance instead. BackgroundThe tech world has been in pursuit of two things over the past couple of years. The first is an answer to what will replace the smartphone. Depending on whom you ask, the smartphone has remained relatively unchanged since its debut in 2007. It has been upgraded in small ways with better screens, cameras, and sensors, but otherwise, the form factor has stayed largely the same since the beginning, despite some major flaws in the structure. But it’s been more than 16 years, Steve Jobs isn’t around, and everyone is looking for the smartphone killer. Secondly, the success of OpenAI’s ChatGPT has demonstrated to everyone how powerful AI assistants can be. The open-source space has also made giant leaps with Llama 2 and Mistral AI models, and you can achieve the same capabilities as ChatGPT, and even the interface, running on your local computer with relative ease using tools like Ollama. With the addition of vision, audio, and speech capabilities into AI models, they are now ready to move beyond the browser and integrate into people’s lives, understanding instructions within their own contexts. For this, they may need to leave desktop browser windows and move onto mobile phones instead. But mobile phones are still a reach-into-your-pockets-or-handbag away, and that’s not good enough either. People need something even more readily available. Enter Meta Ray-Ban, Humane’s AI Pin, etc. Thirdly, these models have so far been hamstrung by their inability to perform actions on behalf of the user. They cannot yet click buttons on screens and other interfaces, and the OS architecture and security do not allow an app to interact with the interfaces of other apps as yet, and rightly so. But this also means that we have to duplicate actions and information across apps in order to achieve certain goals. With this backdrop, I think we can evaluate what Rabbit R1 is doing much more accurately.  Hardware DesignIt seems they hired Teenage Engineering (nice name), which appears to have a penchant for creating retro-futuristic tech products, reminiscent of Dieter Rams’ Braun designs. The design features a very cool, Lego-inspired shell that houses a great-looking touchscreen, a camera on a swivel, a scroll wheel, microphones, a slot for USB and SIM cards, and a push-button on the right side of the product. The touchscreen is a great addition, making interactions with apps, information delivery, and answering questions much faster than the audio-based delivery chosen by the AI Pin by Humane. The camera on a swivel seems like a good idea, as the R1 can potentially scan the environment to find what a user may be referring to in their instructions. However, the plastic above the camera prevents the device from being held at an angle less than about 45 degrees, meaning the user must position the device almost vertically, like a smartphone, for the camera to see. This is odd, and I’m not sure why this choice was made. Why not just position the camera on the very edge without the top plastic part causing an obstruction? I’m also struggling to understand the purpose of the analogue scroll wheel. Is it meant to help make selections within the touchscreen interface? That doesn’t seem likely, as it would potentially be faster to use your finger to scroll on the touchscreen itself. Is it intended for manually positioning the camera? If so, positioning it to the right of the camera would have been more logical. Is the idea to enable one-handed scrolling on the touchscreen? If I were holding the device in my left hand, using my index finger to scroll might be easier than using my thumb on the screen, but I would still need to make button selections, and for that, I might be hitting the push-button. This seems like a learned behaviour, but it’s the only explanation I can come up with given my limited understanding. However, if you hold this device in your right hand, the positioning of the scroll wheel becomes even more perplexing! You can’t scroll with the thumb that’s holding the side of the device, and you can’t use your left hand to operate the scroll wheel without blocking your view of the screen. So, why is it designed this way? Finally, I didn’t notice any way for the product to be attached to a jacket or shirt, and the placement of the screen and push-button suggests that the R1 is intended to be carried in a pocket and pulled out when needed. This raises a significant concern for me. An AI companion needs to be readily accessible within the user’s physical space to understand instructions better (and to keep the instructions simpler). If it needs to be pulled out of a pocket—or more likely from a bag, since the smartphone will probably be in the pocket—it won’t be as easily accessible. The AI Pin addressed this better by being always accessible from the t-shirt or jacket where it is clipped. The Meta Ray-Ban was another good attempt, but since they are sunglasses, wearing them all the time is nearly impossible. Software DesignJesse Lyu, the founder and CEO, begins his keynote by recognising one of the most fundamental issues with the way smartphones are designed. This is an extremely deep insight, and I’m so glad someone on such a large stage was able to express it. During the early days of the smartphone, Apple proudly used the line, “There’s an app for that,” in their marketing to highlight how many apps there were in the App Store. You see, in their view, there was an app that could achieve any task that you wanted to do. But the mental model of a person who wants to perform a specific task requires them to choose the app that would enable them to do it, then open that app and make the right choices in the interface in order to achieve the task. If you’ve got more than one app that could help you do that task, there’s some time spent in your mind deciding between them. And if you have a task that needs more than one app to be achieved, you’ve just made the choices even more complex. Given that most people have about 90 different apps on their phones on average, this isn’t a small matter. You also need to have downloaded these apps ahead of time in anticipation of needing them in the future. But that’s another story altogether. This is also third-generation thinking, where you have to consider the objective you need to achieve and then break it down into the steps required for the computer to help you achieve it. Contrast that with fourth-generation thinking, which simply requires the user to clearly express the goal, and the computer then breaks down the tasks into atomic bits, figures out the best tools to use to solve the problem, and solves it. This was science fiction before the advent of AI. This is reality today. There’s also the duplication of data and instructions between the apps to contend with. For example, travelling somewhere on a vacation requires an app for flight bookings, an app for hotel bookings, an app to book a ride, and another to research the highlights of the destination. Each of them will ask you for your name, dates, times, locations, your companions, your preferences, over and over again. And that’s not even considering the fact that you need to register with each app too! This is a problem today, and Jesse and his company used this idea as the foundation to build their solution to combat this problem. Kudos to them for being able to figure out a way around it with their Rabbit Hole interface, even though it doesn’t yet completely solve all the problems. There’s much more to say about the software, the interfaces, and the UI design, which are all brilliant but table stakes for a game this big. The fact that they understood the above point and also broke through the 500ms (while not yet hitting the Doherty Threshold) makes the device feel really responsive, which is just amazing. ^a18b65 Business DesignThe fact that the product was launched at $199 is simply a masterstroke. A device that purports to be an AI Companion is really only that useful today, and the price point is perfect. But how could they not have a recurring monthly fee? They must have servers running in the background to serve the needs of the users. How do they expect to fund this? To me, this is where the rabbit hole comes in. I think the apps need to pay to be listed there. Maybe not initially, but eventually. They also may have a local model running on the device that handles the majority of the daily queries and only passes along the complex ones to the server, à la Mixtral of Experts. This would keep their costs low too. There is a possibility that they will benefit from a model that understands the physical world of the user better. This is greenfield at the moment, and they are going to be one of the first to occupy this space. But this is me just conjecturing, and the answer may be far simpler; the operational costs may just be borne through VC funding until they hit some kind of threshold. Or maybe it has to do with advertising, a. k. a. “recommendations” that the agent provides. ConclusionThe R1 is intriguing and addresses some key concerns of mobile computing. However, several challenges persist. While the Rabbit R1 excels in software, the hardware design falls short of being an effective AI companion. A smartwatch with a camera still remains the form factor to beat. Given these shortcomings, I predict limited usage and abandonment by most users within a few months unless these improvements are implemented by the time they start shipping in March. With regard to competition, this concept could easily be replicated by smartphone manufacturers. If they cannot produce it independently, an acquisition could be on the cards, which may be the anticipated endgame anyway. For any AI companion, the major obstacle remains payments. The demo didn’t quite show how the many payments that were alluded to actually took place, and I’m curious to see how this aspect works. While I don’t personally wish to purchase this product due to the aforementioned issues and deficiencies, I still regard it as a ‘directional innovation’ that pushes the industry in the right direction. There will be numerous iterations before the ideal form factor for the product is realised, as well as the perfect business models for the companies backing them. Consequently, I intend to keep a close eye on Jesse and his team to see if they adapt and iterate as I anticipate they will. "
    }, {
    "id": 23,
    "url": "http://localhost:4000/blog/review-of-humane-ai-pin/",
    "title": "Design review of the AI Pin by Humane",
    "body": "2023/11/28 - As a product designer, I analysed Humane’s first product, the AI Pin, and identified several critical challenges that need to be addressed. While the product’s primary purpose of replacing mobile phones is laudable, it faces significant obstacles. Firstly, the device needs to offer a 10X better value proposition than the mobile phone to convince users to switch. However, this proved difficult as the AI Pin struggled to deliver on this promise, particularly in terms of call and message functionality, social media, calendar management, navigation, photography, entertainment, running apps, and more. Furthermore, the voice-based input/output and low-resolution screen limit the device’s usefulness compared to a high-resolution touchscreen display. Additionally, the need for a tap activation can be slow and cumbersome, hindering the AI assistant’s utility. Demonstrations showed that the AI assistant takes time to retrieve information and respond, leading to frustration in daily usage.  To improve the product, I would ask the following questions:  Why create a phone replacement as the first version of the product? It would have been more effective to demonstrate the usefulness of an always-available AI assistant, as Meta RayBan did.  Why use tap as a wake gesture when hot keywords or head turns towards the device could be faster and more hands-free? What were the reasons for not pursuing a smartwatch with video capabilities? A watch offers familiar activation gestures like raising to wake, and provides a screen for information delivery and private touch inputs. While many have criticised this project, upon closer examination, it appears that the product was rushed to market rather than be the example of the company’s vision. However, there is still hope for Humane as they continue to innovate. A truly effective always-available AI assistant has the potential to improve various aspects of life, and I await their future developments with interest. It’s hard to go into uncharted waters, and one must admire them for trying. "
    }, {
    "id": 24,
    "url": "http://localhost:4000/blog/is-there-room-for-another-dating-app/",
    "title": "Is there room for another dating app?",
    "body": "2023/07/18 - Examining whether there’s an actual need missing or a packaging problem The NeedMeeting the person that is now my wife had been quite a challenge. I probably have been helped by friends, family and work colleagues and when that didn’t work, I even joined a singles group, signed up online on matrimonial sites and even dating apps. I finally met my wife on a dating app called OkCupid. To say that this field of allowing people to find each other is dear to me would be an understatement. I’ve been happily married for a while now. I have several single friends my age and while a few of them want to find someone and get married eventually, some are choosing to stay single and are quite content doing so. However they would still like companionship and would like to meet people that are similarly inclined. In a recent conversation with four twenty-something user experience designers, I asked about dating apps and whether they are serving the needs of people their age group. But surprisingly the complaints were the same as for those that belong to the older group I spoke of above. All of them said they had issues meeting people and that no dating app was serving them well. On a broader societal level India has always been thought of as a nation with very traditional values and therefore the population had a majority of married people. But this trend is changing. People are getting married later in life if at all and many are also choosing to stay single, not seeing getting married and having kids as the final goal. Divorce laws in India are also complicated to say the least and this may be a contributing factor to people choosing to stay single.  The ProblemsIn my research, I’ve funnily had absolutely no trouble getting people to tell me about the issues they’ve faced while using dating apps. It usually ends up becoming an hour-long conversation and everyone wants to explain their individual journeys and issues that they’ve run into. In a lot of ways they want to vent their frustration and when someone like me comes along and asks what the issues are, it’s like opening the flood gates to a dam. But I feel their pain as I’ve been there myself. To whit, the issues they presented for dating were as follows:  Men find it harder to meet women as the percentage of men on dating platforms is much higher. This may be because it’s traditionally been uncommon for women to put their profiles online.  It is not easy to convert an online encounter into a physical meeting due to concerns regarding security. They typically want to be very sure of the person before they meet.  People prefer to meet others in real life rather than online as that is a more authentic way to find someone.  Creating a good profile is key and people request others who have found success to create their profiles. But this inadvertently also adds to the catfishing concern as the profiles may not be authentic at all.  People don’t always know that the person they are meeting online are verified in any way and this adds to security concerns.  Dating apps that require women to initiate the connection may be adding a hurdle to introverted women. They may prefer to be approached instead. But this an an all-or-nothing kind of offering on such platforms.  Ghosting is a big concern as people may be spending inordinate amounts of time trying to build a relationship with someone they met online whereas the other person may be not be interested at all but doesn’t know how to end this.  The online medium is skewed towards good-looking people. The fact is that most platforms offer huge databases of people and it’s practically impossible to sift through all without being extremely quick to judge either based on photos or based on scanning of profiles very quickly.  There are several scams that have occurred based on people meeting each other online in India. Scams involve extortion, confidence scams, honey traps and lots of other such issues that make this kind of meeting very dubious. There are some things that could be solved through better employment of technology. But there are a lot of things that can be solved in the real-world realm.  Room for AnotherWith the passage of time, it’s a good idea to evaluate old decisions over again. While I had previously thought that this market is overcrowded and that there is dating-app-fatigue that has set in, I think the advent of AI has made it possible to evaluate this once again. Yes, I am very aware that platforms like e-harmony and OKCupid, and lots of others, have indeed marketed based on this idea. However, I don’t think they had the tools we have today to make that claim in earnest. Besides, the one flaw in their thinking was that they were only able to go so far as making a recommendation of who they would match with; they were never able to evaluate whether they had made the right prediction because they had no mechanism to receive such feedback. If they didn’t get any feedback, it definitely didn’t help make future recommendations any better either. If one were to venture into this field, this is a key aspect that I would evaluate: did they have good recommendation engines that not only had recommendations but also had feedback loops to make future recommendations better? The Business CaseIn my quick study of this field I’ve come to the conclusion that the demand is off-the-charts. No platform has solved this problem as yet, so there’s definitely room for another entrant. There is no dearth of money as people are willing to pay out of money in order to meet the right person. So it can definitely be a profitable venture. But the solution has to be packaged correctly and the right promises need to be made. The Goal: First and foremost it is important to set the right goals for a platform. Is it meant to result in a date, is it meant to result in a relationship, is it meant to result in a marriage or is it simply to develop companionship in this changing world. I think apps and platforms that promise finding the person to get married to are obviously overselling what they are capable of. I’d go so far as to say that even if they promise a great date. It takes a lot more to make a date memorable than the matching of characteristics in databases. I’d love to see an app that promises that the user would meet good people and that’s it, because that’s a promise that can be kept. Target Audience: While some people may be looking at getting married, some may simply be looking for companionship or even to meet other singles because the conversations with their married friends maybe something they can’t relate with anymore. I think it would be prudent to simply focus on the people looking to make friends. If something more were to develop from this, that’s just the cherry on top and not the baseline expectation. This may also therefore not be an age or gender-related qualification. Packaging: In my mind, the following are the core areas to keep in mind when designing a solution: 1. Security: As mentioned above, we need to make security the main focus area. We need to find ways to make sure that people feel confident when participating on a platform. Vetted profiles, membership through recommendations, attracting people through the right channels, etc. are some of the things that we can do to make sure of this. 2. Authenticity: While making an effort to make all the profiles on the platform look good, the authenticity of the profile must not be lost. There is a fine balance here that must be found. Maybe the profile is written by those trained in it, but there could also be a video that the user records of themselves saying things that should be added with it. 3. Matching: At the fundamental level this is a matching problem. There is a lot of noise to sift through to find good information and characteristics to match people against. People often lie about themselves in order to appear a certain way and no questionnaire can overcome this hurdle. Or, they may not express what they want for fear of being judged for it. Yet again, they may simply not know what they want. All of this makes the matching problem more difficult for any system, but not for machine learning systems. Building a good matching engine that powers all of this is therefore the most important task. And for this, we need as many signals and feedback as possible. 4. Efficiency: This is one of the most ignored metrics within this field. People spend inordinate amounts of time trying to find the right person that they would like to be with. This increases the fatigue that they face and makes a lot of people give up in the middle of the process. Any new system that is built should definitely consider making this entire process more efficient. The system should try to match a person with a group of people that they share common ground with. The individual they meet within that group that they connect with is almost unnecessary to focus on. Pricing: Pricing will obviously play a key role here. Pricing can be used to create an elite group that keeps the non-serious participants out, but too high a price and it will become elitist and exclusionary. People should also not be paying for individual participation, but rather for a few different events together so that they interact repeatedly as that is key to the success of this program.  ConclusionThe world is yearning for deeper connections. With the power of technology at our fingertips, it’s time to harness it and create platforms that truly bring people together. We must seize this opportunity to build communities, foster companionship, and combat the growing loneliness in our society. It’s time to reimagine dating platforms as platforms that serve this need, where the focus is on meeting good people and forming meaningful connections. Let’s embrace the advancements in AI and recommendation engines to make this vision a reality. We have the tools, the potential, and the responsibility to improve the human connection. It’s time to take action and create a platform that truly changes lives. It must be attempted because it is important to achieve. "
    }, {
    "id": 25,
    "url": "http://localhost:4000/blog/generative-ai-art-experiments/",
    "title": "Generative AI Art Experiments",
    "body": "2023/07/13 - Artificial Intelligence (AI) based design tools have captivated our collective imagination in the field of design. Here are my experiments. IntroductionArtificial Intelligence (AI) based design tools have captivated our collective imagination in the field of design. Being able to imagine something and bring it to life in the form of an image or video is a tempting prospect. While one part of the design world lamented the fact that these tools may replace our roles, I belong to the small minority that looks at these new technologies with the hope that it would lead to better design. I could after all never call myself a designer if I had never run into Photoshop all those years ago. So I dove in head-first into figuring out what this new frontier holds for us. This is an on-going experiment and I am just documenting my learnings as I go along.  If not for Photoshop, I may have never become a designer What did I expect?While I started exploring this simply out of curiosity, it later was also a business decision as I anticipated that it would help my small team do more. After all we were about to launch a second product at work and I had to find ways to  sustain all of it with the current team size. Therefore, I started by trying to find answers to the following:  What are the tools that are available? What’s the learning curve to use these technologies? How much control do I have over the output? How much post-processing is required? Can they produce consistent quality and style over a period of time? Are the technologies mature enough for everyday use?October 2022: AI based art NFTsI had heard of AI generated art and was amazed by what I saw in some videos but I had no idea how this was done or how. I happened to run into NFT’s on Rarible at that time and saw this collection of AI based images that someone had made. I was just so amazed with its accuracy that I ended up buying a few of them simply in the hope that I was supporting someone who was working on this and possibly getting flack for not being a true artist. Learnings from this phase::  AI art is dividing the world into the group that thinks this is art and the group that thinks it isn’t No one expected AI would set its sights on the creative fields first. February 2023: MidJourneyI ran into MidJourney back in late 2022 through a colleague who was using it to create some artwork that I was quite impressed with. I thought to try it out but the version that existed at the time was just not that great with the simple “prompts” I was able to provide it. It took too many tries and much too long to generate something just remotely close to what I wanted. I saw others developing images that looked a lot better and saw what they had prompted MJ in order to produce it. I copied one of them that had produced a very cool image of a cat to produce an image of a dog. My dog image had three eyes! My attempts at producing human portraits didn’t fare much better. All of them had messed up hands or too many fingers for some reason. I was producing Dali-esque images without intending to. I walked away from a two hour session kind of impressed, but feeling that the tech wasn’t there yet. Learnings from this phase::  The learning curve was too great as I would never be able to understand all the words and prompts and styles and exclusions if I had to type all of this out The interface (Discord) was absolutely not the one that I could imagine using to produce images. It was a terrible fit and since I was in a public channel typing out my requests, I felt like I was being watched while I fumbled around trying to produce the output I wanted. The tech wasn’t there yet, but I saw potential. March 2023: MidJourney V5MJ V5 launched this month and I got really interested. This was a big update and they got a whole lot of changes in. They got the hands right, they got faces right, the quality of images was just amazing and the initially released with the Zoom Out feature that essentially imagined the parts of the frame that wasn’t there before and gave images this depth and drama that didn’t exist before. The pace of smaller updates thereon has just been incredible and it was time for my team to start experimenting with it. As we had been working on building an NFT collection for use with the main product as rewards, this ability to generate a lot of graphics in a short period of time was important. The challenge was being able to get MJ5 to output the kinds of images that we had been producing until now with Blender. The alternative was to produce a new style that worked with MJ5 but that also meant updating all the graphical properties that the company had, including the website, marketing collateral, transactional content and other assets such as NFTs. So the team started to work with this and try and achieve our existing styles of artwork with the new tools. However this yielded pretty bad results. There was still a lot of manual effort required to bring the artwork to the same style. So we abandoned this approach and started pursuing the second strategy and came up with a new direction altogether. Learnings from this phase::  The tooling was still not good enough for a designer. It seemed like you can only do a full-image edit and not something specific within it. For that you’d still need tools like Photoshop. Photoshop’s generative fill provides much more control.  Knowing that we can produce the required graphics with such ease suddenly allowed us think about doing sweeping changes that we would never think about doing before. We’re now able to think about updating a website in preparation for a launch event.  I feel that we’re still at a stage where you can still tell when artwork has been produced by AI. It’s just “too polished” and accurate. Not sure what this means as yet, but I’m trying to understand it more.  Stable Diffusion came onto my radar as a platform that provides us more control within the AI generative tools space. So I started exploring that next. ‘SCRIBE’ CHARACTERS CREATED WITH BLENDER: ‘SCRIBE’ CHARACTERS CREATED WITH MIDJOURNEY 5. 0: "
    }, {
    "id": 26,
    "url": "http://localhost:4000/blog/better-tools-should-be-better-employed/",
    "title": "Better tools should be better employed",
    "body": "2023/06/29 - When you have access to tools that provide you unlimited capability, how should these tools be used. IntroductionIn the age of AI, the only limitation to creating things is our ability to imagine them. While AI tools allow for new possibilities, there is a real growing concern that our ability to imagine itself may be eviscerated. But uniquely to our time, there are dire consequences to using and not using the technologies. The only way forward is to pay attention to where we employ these tools and where we don’t. Design is about changing and managing perceptions and ideas about the world we live in. It’s powerful because when employed well, it works wonders as a way of wielding influence. This influence can broaden our horizons, make us aware of our hidden biases and even train good behaviour. Or, on the other hand, it can block progress and foster addictive and unhealthy behaviours such as providing positive reinforcement when we buy stuff we don’t need.  Two StoriesI recently watched this wonderful video by Dami Lee where she analysed the fantastic amount of detail that the people at Studio Ghibli went into while creating some of the award-winning animated movies that they are known for. Since Dami Lee is an architect, she analysed the movies from that perspective and highlighted how thoughtfully the buildings were detailed, including the details of lobbies, the rooms themselves, and even what the long passageways mean in terms of the Japanese culture they represent. She’s fascinated that the studio is able to be this observant and dives in to find out what about their design process makes this possible. And this, to me, in my current role as the head of a design team, was what I found most interesting. In the video, there are clips of interviews with one of the founders Hayao Miyazaki where he states that they force everyone to animate things in the traditional way “by hand” even though this is far more painstaking and tedious. He says that this, in fact, is the reason the studio has been able to be as observant as they have been. He insists that this is the case and goes on to berate anyone that wants to use technology or find a faster way to do things. He famously has said, “Anyone that eats instant ramen three times a day cannot be an animator,” further emphasising the idea.  “Anyone that eats instant Ramen three times a day cannot be an animator”– Hayao Miyazaki, Co-Founder, Studio Ghibli In a completely different part of the world, a friend of mine had developed an appreciation for calligraphy and had begun dabbling with it. He showed me the various pages where he had written the same letter over and over again. Being extremely observant he had observed how he had to move his hand in order to achieve the right shape of the stroke and paid attention to how the ink flowed on the paper. He had even crafted the right kind of pens and nibs to be able to do this easily. But his biggest learning was that the effort involved in the art actually made him think many times about what it is that he wanted to convey. It had to be something important as the very act of embellishing the letters took a lot of time and effort. He went on to remark at the virtues of the art of letter writing of the ages past that our grandparents were very familiar with. He saw that there was something beautiful in the effort one put not only into the writing of the letters, but also the pasting, stamping, walking the letter over to the nearby postbox that somehow conveyed to the recipient and made them so happy or at least important for being the beneficiary of such effort. It seems there was something to the deliberation involved and the lack of speed, that made for greater appreciation. And this got me thinking about the design process I use in my daily work as a user experience designer.  A Better UX Design ProcessUser Experience Design as a field gained foothold with the advent of computers and the invention of the Graphical User Interface. It’s been a digital pursuit since it’s inception and as such technology has been used to improve every aspect of the process, right from research, wire-framing, visual design, implementation and testing. For those unfamiliar with this field, the main job of a UX designer is to visualise how an application would look and feel like before it has been developed by programmers, much like an architect would render drawings of a building on paper before the building gets built. The task therefore is of communication to all the stakeholders. The hope is that any fixes that are required are done at the design stage when it is cheaper rather than at the development stage when it is definitely much more expensive. But even a considerably simple application requires more than fifty screens to be designed if every scenario anticipated while using it needs to be thought through. For example, how does a user login, how do they set their preferences, how do they communicate with support personnel, how do they bring their friends onto the app, and so on. When you factor in the additional operating systems and the various devices and screen sizes that the application should work on, you can easily understand how many screens need to be developed. Imagine if something that appears on all the screens needs to be changed (which happens more frequently than one thinks), a designer will have to manually locate the said element in each of the screens and replace them. Using Photoshop, Illustrator or Fireworks, which were tools we used to use to design these screens, this took hours or even days of mind-numbing effort and designers hated doing this. They would do anything to avoid rework, including pushing back on any change requests, pushing the task to the developers to handle at the time of development or even just changing the process to seek inputs and feedback on just key screens before all the associated screens in the process are completely developed which is not really the best way to do this as the stakeholders are evaluating based on insufficient information. Today, we have much better tools like Figma which make these changes across hundreds of screens in a matter of seconds. This one ability has allowed us to create much better designs, seek feedback after a lot of screens covering a lot of scenarios are actually developed improving the quality of the output immensely. From my vantage point, it’s clearly evident that this kind of technology has been great for the industry. But in this mad rush to achieve outputs faster, the same tools also offers the ability for designers to use templates to speed up the work even further. There are AI design tools that are being created that would create entire workflows and in some cases even apps with a single prompt. Like painters of canvasses, UX designers have also got to pay attention to every pixel that they place on the screen. Everything is deliberated upon and nothing happens by accident which is why the outputs are meaningful. This part of the process should remain slow for a reason. If technology is used to reduce the deliberation in an effort to ease this part of the process, the outputs of such processes will undoubtedly be mediocre. ___ Counter ArgumentsIn some cases, “mediocre” may be a desirable step up. For example, A business owner for instance may simply want to test out an idea for an app without the kinds of expenses involved in the design and development of a custom-built application. But there’s a risk here. A friend of mine advised me about which bicycle to buy this way, “Don’t get a basic bike if you intend to get into this sport. You won’t like the bike and you’ll end up rejecting the sport instead. ” I think there’s a lot of truth in that statement and I’d like to provide the same warning to the business owner who may be tempted to use this route. Testing out a good idea using mediocre ways to get you to the output is actually not testing out the idea at all. A UX designer also may be tempted to use these tools to define a baseline for the app that they want to develop. These tools may still serve a purpose, but fixing a bad output is probably harder than creating the right output from scratch. There’s also the possibility that not every aspect of the output is examined as well as when creating the output in the first place. Would you want your app to go out to developers with these flaws still in it?  “Don’t get a basic bike if you intend to get into this sport. You won’t like the bike and you’ll end up rejecting the sport instead. ”– Rohan Kini, Bums on the Saddle ConclusionI think technology is a tool like any other and can be beneficial or detrimental depending on how we use it. It will always lure us with its promise of speed, scale, spread, smarts and asynchrony. While it can improve our lives, indiscriminate employment of it will only result in poor outputs. We must be vigilant about what we employ these tools for. Reduction of effort is a great reason to use technology, but if it can impede our thoughtfulness, it is probably a bad use of it. "
    }, {
    "id": 27,
    "url": "http://localhost:4000/blog/the-eight-rules-of-ethics-for-ux-designers/",
    "title": "Eight Essential Rules for Mastering Ethical UX Design",
    "body": "2023/04/21 - Reflecting on the work of many others and my own work within the field, I have distilled the following rules to act as a guide IntroductionWhile UX design is a relatively young field, its importance in a product’s success cannot be overstated. Its impact on the world today is clear, but sadly its ability to effect positive change is coupled with its ability to inflict harm. As with anything that has such powerful duality, a code of ethics is necessary to act as a lodestone to guide those venturing into this field in the future. Reflecting on the work of many others and my own work within the field, I have distilled the following rules that should act as a guide: Rule #1: Your foremost duty is to help your client succeedI started my design career at Adobe Systems and then went on to build my own UX design agency. My ideas regarding this subject have evolved from “The designer’s job is to advocate for the user within a company” to “The designer is the servant of two masters and needs to figure out how to balance the two”, and finally to understanding that a company simply cannot have interests in opposition to those of its customers for any reasonable length of time, as customers are not naive people waiting to be tricked and will just switch to the nearest substitute. So, it’s enough to simply take the interest of your client — their true long-term interest — and design for that. Rule #2: Your task is to help a user simply navigate a complex worldSoftware is usually employed by a user for the completion of reasonably complicated tasks. Depending on the user, they may be unfamiliar with how to use the software, use the hardware, understand how technology functions, or even have physical limitations such as not being able to see small fonts clearly. Our job as designers is to help them navigate the technology in such a way that it is very simple for them to achieve their tasks. We may need to help them understand the decisions they need to make better, they may need settings that make interfaces more visible, they may rely on the software to make certain choices for them, etc. The better we understand our users, the better we can serve them. Rule #3: Don’t treat the user like a commodityThe anonymity one has on the internet is a double-edged sword. While it encourages free speech and discourse, it allows people to behave worse online than they would in real life. In the commercial world, this extends to thinking of users of a product in the abstract, reducing them to single dimensions as pockets that need to be picked, resources meant to be exploited, rats to be subjected to dopamine experiments, or as commodities meant to be traded. This is not good for the company in the long run (a la rule #1), but people attempt to do it anyway. Designers can play a big role in breaking these mindsets and making product managers or companies look at the long-term welfare of their users and, consequently, their own companies. Rule #4: Your counsel is as important as your labourFar too often, we measure our work by the effort we put in or the number of screens and experiences we produce. But I’ve always felt that they hire you for your skills in the early part of your career, and when you’ve gained more experience, they hire you for your opinions . When we’re designing something, we’re deeply considering a specific point, making decisions based on them and learning from their outcomes. It is this distillation of experience that is more important to a client than our labour. They shouldn’t have to spend new money to learn old lessons. Rule #5: A designer must respect cultures, genders, physical abilities, political leanings and privacy preferences and must design to enhance all of themMuch too often we think only through the lens of our biases and it’s all too easy to exclude certain people or groups from our thinking. I am myself guilty of not accommodating people with poor eyesight and early on in my life as a designer, I’d design applications with small fonts because they made the interfaces so cool. But this meant I’d ostracise a large group of people that found it hard to read the small fonts. An even more subtle example is the frustration that one feels while using tools like Google Docs or Microsoft Word or many other software, where they have to change the locale setting every time they create a new document as it usually defaults to ‘US English’ even if you’ve previously gone and set this to ‘Indian English’, ‘UK English’ or ‘Australian English’, or any of the many other dialects. I’ve seen people delivering food in India wearing t-shirts that say “Hunger Savior” instead of “Hunger Saviour” because someone forgot to change the locale setting while writing the copy for that t-shirt ! But there are even worse examples I have seen websites that use “Father’s Name” as a label for a field where “Parent’s Name” would have been more appropriate. Should someone really pick the option that says “childless”, even if they chose not to have children and wouldn’t choosing “0” against children not be a more neutral choice! But here’s something that probably affects a lot more people — the methods of proving that you’re a human by typing in the English text displayed in a box. The majority of the world doesn’t speak English natively! While it may be challenging to cater to every user’s unique preferences, being aware of these potential biases is the first step in creating more inclusive designs. By being open to feedback from users and making an effort to understand their perspectives, designers can work towards creating applications and products that are welcoming and accommodating for everyone. Rule #6: Protect the privacy of your usersIn the digital age, privacy has become a vital concern for users as their personal information is often at risk of being exploited by powerful entities. Although many people understand the importance of privacy, not everyone is aware of its implications on their own lives or how to select platforms that prioritize this aspect. As a result, it falls upon product designers to make critical decisions on behalf of their users, ensuring that privacy is protected throughout their designs. By being conscious of potential privacy risks and implementing robust security measures, designers can help safeguard users’ personal information and maintain their trust in the products and platforms they use. Anne Cavoukian, the Information and Privacy officer of Ontario, proposed a set of seven foundational principles to protect the users of most information systems called “Privacy by Design” (PbD). The core idea is to address privacy concerns from the beginning, instead of adding privacy measures as an afterthought. PbD comprises seven foundational principles:  Proactive not Reactive; Preventative not Remedial: Privacy by Design emphasises anticipating and preventing privacy invasions before they happen, rather than waiting for breaches to occur and then taking remedial action.  Privacy as the Default Setting: Privacy should be built into systems and services by default, so users don’t have to take any action to protect their privacy. This means that personal data should be automatically protected without requiring any user intervention.  Privacy Embedded into Design: Privacy should be an integral part of the design and architecture of IT systems and business practices. This ensures that privacy is not treated as an add-on but is a core component of the system or service.  Full Functionality — Positive-Sum, not Zero-Sum: PbD advocates for a “win-win” approach where both privacy and functionality are achieved, without compromising either. It rejects the idea that privacy must be sacrificed for security or other objectives.  End-to-End Security — Lifecycle Protection: Privacy by Design emphasises the need for strong security measures throughout the entire data lifecycle — from collection to use, storage, and eventual disposal. This involves implementing robust access controls, encryption, and other security techniques.  Visibility and Transparency: PbD emphasises being open and transparent about privacy practices, allowing users and other stakeholders to verify that privacy measures are in place and functioning as intended. This fosters trust and confidence in the system or service.  Respect for User Privacy: Privacy by Design puts users at the centre, giving them control over their personal data and making it easy for them to exercise their privacy rights. This includes mechanisms for obtaining consent, providing access to personal information, and allowing users to correct or delete their data. To make applications respect users’ privacy, follow these steps:  Conduct a privacy impact assessment at the beginning of the project to identify potential privacy risks and develop strategies to address them.  Design the application with privacy in mind, incorporating the Privacy by Design principles from the start.  Collect only the minimum necessary personal data and anonymise or pseudonymise data where possible.  Implement strong access controls and encryption to protect personal data in transit and at rest.  Establish clear and transparent privacy policies, making them easily accessible to users.  Offer users options to manage their privacy settings, giving them control over their personal data.  Regularly review and update privacy practices, staying informed of changes in regulations and industry best practices. Rule #7: Find every opportunity to reduce the carbon footprintWhen e-commerce companies first launched in India, every step from the moment a user completed payment on a website to the final delivery of the product to the user’s home was new and untested. One such process was the packaging method. It appears that packaging and shipping standards from another country were adopted, with every product arriving in bubble wrap and oversized boxes, regardless of the contents. However, it is well-known that India is averse to waste, be it food on a plate or in business, nothing is allowed to go to waste. When oversized boxes started appearing at people’s doorsteps for items as small as lipstick, deodorant, or a bar of soap, people began to complain! This led to someone in the logistics department reevaluating the situation and adapting the Standard Operating Procedures (SOPs) to suit waste-intolerant Indian conditions. Packaging underwent a rapid transformation across all e-commerce players: boxes were replaced by envelopes when possible, clothes were wrapped in brown paper, the number of shipments decreased, and items were grouped. Other changes included shipping items to a neighbourhood store for customer pick-up and making numerous other adjustments in a short time. Encouraging a company to adopt environmentally-friendly practices is challenging, but e-commerce companies embraced these strategies because they aligned with their interests. This prompted me to think about design interventions that could benefit the company, customer, and environment. A few ideas immediately came to mind that e-commerce companies could implement:  Allow users to specify their preferred packaging for the products they order.  Let users indicate if they need their items urgently or are willing to wait for grouped deliveries with others in the area, enabling the packaging department to avoid always defaulting to the “safest” option.  Food delivery companies can improve the value-per-mile metric for their delivery personnel by allowing them to collect used plastic containers from customers, streamlining recycling efforts.  Offer subscription options for frequently ordered products, optimising delivery routes and making them more predictable.  Allow users to inform product manufacturers of their preference for eco-friendly alternatives, which could encourage manufacturers to develop such options if there is sufficient demand. These are five ideas with me spending a few hours thinking about the problem. Imagine the possibilities if designers everywhere also focussed on this problem. And that’s the main call to action in this rule. Rule #8: Design for delight, not for addictionDesign is an incredibly powerful tool that can help achieve any goal. There have been numerous shows and documentaries highlighting how design can make applications addictive. It is possible to devise countless ways to captivate users, keeping them glued to your application. The primary benefits of this approach are pushing more ads to users or spying on them to build a profile for sale to the highest bidder. However, these are shortsighted goals and tactics. Awareness is growing among people, who now understand that if the product is free, they themselves are the product. Moreover, there is a trend towards paying for software nowadays, as demonstrated by the growth of SaaS products, consumers’ willingness to pay for digital content on platforms like Netflix, Apple+, and others, and the increased use of cloud-only products such as the popular design tool Figma. Such services depend less on ad revenue and more on providing quality products and delightful experiences. Users of these services have demonstrated that they are not only willing to pay for quality products and services but will also remain loyal to the company long-term. This contrasts with the software of the past, which would be uninstalled as soon as users had finished their intended tasks. In an era when the cost of acquiring customers is skyrocketing, wouldn’t you prefer to be the one retaining customers for the long haul? ConclusionEthics encompass the principles and values that guide human behaviour and decision-making, with a focus on concepts such as fairness, justice, and moral obligation. Ethics inspire individuals and organisations to contemplate the wider implications of their actions on others and the environment. By embracing these values, we can forge the kind of societies in which we yearn to live. As UX designers, we now hold immense power and the capacity to shape the digital worlds we increasingly inhabit. It is time for us to take responsibility for our actions, learn from the best practices, and strive to create a positive impact that fosters long-term well-being. Let us seize this opportunity, embrace our ethical obligations, and design a brighter future for all. "
    }, {
    "id": 28,
    "url": "http://localhost:4000/blog/censoring-censorship/",
    "title": "Fixing Censorship with Web3",
    "body": "2023/02/28 - It’s important to keep striving for better models of censorship that can benefit society without infringing on individual rights and freedoms. IntroductionCensorship has been around as long as information has been recorded and shared. Different groups, including religious authorities, governments, and corporations, have used censorship as a way to control what people can see and hear, sometimes for legitimate reasons but often to influence public opinion in their favour. It’s important to keep striving for better models of censorship that can benefit society without infringing on individual rights and freedoms. The emergence of both Web3 and AI presents an opportunity to find new solutions to this problem. These two fields intersect and could potentially lead to innovative approaches that balance the need for censorship with respect for individual liberties. The following is such an idea. The Need for a RedesignThe shortcomings of the current censorship system have led to a demand for a new approach. To illustrate this, consider a tech company that creates a massive social media platform with over a billion users across several countries like Twitter or Facebook. On this platform, let’s take one example of a video that was actually posted by a user that depicted the burning of an American flag. This is very likely to offend some users who may hail from the country that the flag represents. The offended users have a few options at their disposal. They may respond to the initial post and ask the user to take down the post because they’re offended, or, they may report the post to the platform for being offensive. The platform then decides whether the post is required to be taken down. Then some form of the following decision tree ensues within the department of the social media platform in charge of handling such user reports:  Is the post in line with the published set of standards related to posting content on the platform? Was the first user right to post the content? Was the second user right to be offended by the content? Is the offensiveness “sufficient” to warrant the removal of the post? How much of a political or economic backlash will the platform face if it chooses to leave the post online or take it down?Consider another example that occurred more recently. The artist Lindsay Mills shared a photo of her baby on various social media platforms. The photo showed the mother and baby, with only the baby’s butt visible. While some platforms allowed the photo to remain, one platform not only removed the post but also banned Mills’ account. This decision was made by an algorithm without human involvement, and appeals to restore the account were unsuccessful. The incident gained attention because Mills is married to Edward Snowden. These examples demonstrate the gray areas surrounding censorship, as society was divided on the appropriate course of action in each case. They highlight the problems with the mechanisms behind censorship, as corporations hold significant influence over society but are not elected to make these decisions. : Furthermore, the following questions arise:  Will the platform make a decision based on standards that have been clearly published? What was considered during the setting of these standards? Who was involved in setting these standards? Were the people that weighed in on the standards representative of the population of users that will eventually use it or was it more representative of the standards of the corporation and where it was founded? Should the standards be the same across geographies and cultures? Is it a lowest-common-denominator approach that is safe for all or were other factors taken into account for setting these standards? What is the basis for judging whether the content that clearly lies in the grey areas should be taken down or not? Is it simply how large a body of people it offends? How is the voice expressing the minority opinion protected? Do these standards change based on who the audience is, by age, by gender, by their own level of maturity? Can a user have control over what they want to be able to see or not? Can I make up my own mind after exposure to the said content? Does it evolve as a society’s views on issues change over time? What doesn’t change? How does the platform handle pressure from external entities such as influential people, large groups or even governments of countries? What are the concessions it will make in this regard?The platform cannot avoid adopting a specific political viewpoint because there’s no way around it. But if it holds any political leaning too strongly, it may loose users to rival platforms that do the same thing but only differ in their political ideologies. This is exactly what happened when Twitter decided to de-platform Trump. The problem with this then is it creates echo chambers where users are surrounded only by people that agree with them and view anyone with an alternative viewpoint as the other. We loose the public town squares where ideas are debated which is essential to building stable societies with moderate political leanings instead of societies that may erupt into civil wars at any moment. Furthermore, we are entrusting the responsibility of making decisions beneficial for society as a whole to a corporation whose sole purpose is generating profits for its shareholders. The mechanism does not allow for the consideration of societal well-being, as corporations must prioritise profits and their ability to sustain losses in a confrontation with political figures or governments pressuring them to make specific decisions. A single misstep can lead to lawsuits that could bankrupt the company. When did it become a tech company’s responsibility to determine censorship implementation on a platform? Why do we accept this as the only approach when tech companies have consistently demonstrated their inadequacy in handling the responsibility of building good societies? A Decentralised SolutionA more effective approach would be to begin with the recognition that free speech is a fundamental right for all individuals. From this foundation, the solution should not focus on prohibiting certain forms of expression, but rather on preventing individuals from encountering offensive content. Although the distinction may appear subtle, the solutions for each approach differ significantly. By focusing on the latter, several benefits arise, as outlined below:  The fundamental right to freedom of speech is maintained with no one being de-platformed The user can control what they want to be exposed to or not be exposed to on an individual level and it can change over time on an individual basis No other individual or entity dictates the standards for determining what someone should or should not be exposed to This system cannot be corrupted by external forces putting pressure on any single bodyWhile researching how a solution for this could work, the movie industry stood out as having a model that we could build upon. The film industry rates movies with suitability ratings like “PG-13,” indicating whether it’s appropriate for viewers aged 13 or older, and streaming services like Netflix provide additional information such as “Contains adult themes” or “Has crude humor” to help audiences make informed decisions. Even if two audiences are demographically identical, they may choose differently based on their preferences. This model has been effective in movies, so what if it was applied to content on the internet with the necessary modifications? One potential approach is to assign tags to all posts on a fictional social media platform that describe the content. Viewers could then apply filters based on these tags to allow or prevent the content from appearing in their timeline. This central idea serves as the starting point for outlining how such a system could operate. Step 1: Tagging the content: While AI models had to be trained to properly identify content in the beginning, the models have become pretty good at this task today. Now the model can be tested against the content to produce the right tags in the content. This is true for text, audio or video based content and across languages. So in the first pass, any new content that’s posted on a platform can be processed through AI models first to create a tag cloud for the content. Tags can be improved upon by groups of people post the initial stage to provide an additional layer of meaning through the lens of different individuals. This should happen over time as well so as to not allow the meaning of the content to stagnate in time as the same content could change its relevance at a different point in time. Step 2: Setting up filters: On the receiving end of the content pipeline, the users need to mark content that they find offensive. But this process could be explicitly done with the user flagging some content as offensive, but also could be done through observing the viewing patterns such as the user scrolling past the content faster than they do on other content or hitting the ‘skip’ or ‘stop’ buttons on videos. One may argue that platforms like YouTube are already doing some version of this, but there are two big differences. Firstly, the data is maintained in a silo on the YouTube servers and not by the users themselves. Secondly, the goal of these platforms is self-serving and to increase viewership on the platform, not to do what the user wants. While the above process gets better over time, users could also adopt filter sets from other pre-built filters created by people they trust, as starting points for their own filters to achieve immediate relief. This set then gets modified with the users own interactions with various platforms over time using on-device AI engines that are becoming more and more prevalent. Step 3: Viewing content: This is probably the simplest part. There can be timelines titled “For You” which is a view that applies the preference filters on the content being viewed and a second timeline titled, “Unfiltered” which shows all the content on the timeline if the user so wishes. This again is not even a new mechanism as most content platforms already use such devices. A Solution for the Age of AI and Web3While thinking through the solutions here, it was clear that the solution to the problem of censorship is not based on the imagining of technologies that don’t yet exist but the repurposing of those that already do. So why hasn’t it been done yet? I believe there are two reasons. Firstly, as anyone in software can tell you, the higher the amount of input you require from a user, the lower it’s adoption rate is going to be. So a self-learning system like AI or ML was necessary to exist for this to work otherwise it would have been humanly impossible to build a system that works. Secondly, the filters and learnings that a company like YouTube would develop about it’s user’s preferences were guarded as intellectual property of the company and not shared with even the user. So a decentralised system like Web3 needed to exist for such a system to work across the web. We’re living in some really interesting times when these kinds of ideas will suddenly come to life because of the fertile ground created by AI and decentralisation that have culminated to put the user at the centre of the technological universe. ConclusionThere are obviously a lot more steps and nuances to consider when building this system, for example, how would such a system work for children and those that are not as tech savvy or even handle content that is clearly illegal across all nations. But I’m sure there are smarter people that could propose better ideas based on the foundation that has been proposed here. I just didn’t want to write an article pointing out all the problems without at least proposing a potentially better solution. If you are interested in discussing any of the ideas proposed here a little further, please do reach out. "
    }, {
    "id": 29,
    "url": "http://localhost:4000/blog/seven-structural-elements-to-keep-in-mind-for-web3-ux-design/",
    "title": "Seven Structural Elements to Keep in Mind for Web3 UX Design",
    "body": "2023/02/12 - The structure of web3 influences the design of the applications IntroductionWeb3 is a decentralised internet powered by cryptography and blockchain technology that allows for transacting with any entity in the world without the need for trusted middle men. It has specific uses in fields where having a trusted third-party middleman may prove to be corruptible, inefficient or expensive. But far too often UX designers are starting from equivalents in Web2 creating poor user experiences. Unique ElementsThere are several effects that the difference between these two structures affect the UX of applications built on top and the following are some main differences that UX designers must account for while designing Web3 applications: 1.  DECENTRALISATION IS SLOW AND EXPENSIVE: Since nodes in Web3 are distributed and are of different technical capabilities, data transmission across the network takes a lot of time compared to centralised systems. These processes can cause delays on the application layer, making them slow and expensive. In order to combat this, transactions are bunched up together before being written to the blockchain as a single write operation if far less expensive than several transactions writing the same amount of data. It’s therefore essential for a UX designer designing applications to decide which data needs to be written to the blockchain and also when in a user’s sessions that needs to happen. For instance, in building a decentralised version of Instagram, would you record every “like” of the user as they occur, or collect all of them and commit them only at the end of the user’s session? Many applications also adopt a Web2. 5 design approach, where less critical interactions such as “likes” are stored on a centralised server for faster processing, while more critical data, such as who posted which picture, is written to the blockchain. But there may other approaches that suit your applications and the right solution would entirely depend on the specifics. 2. THE BLOCKCHAIN HAS THE DATA: One of the most surprising ideas to me was that in the Web2 world, an application typically includes both a front-end and a back-end/storage layer delivered as an app. However, with data and storage openly available on a blockchain, the user interface and user experience is the application. This means that someone else could write a new UX layer for the same data, and the user could choose which application interface they prefer, losing nothing when switching between apps. So, what’s the knock-on effect of this? It makes the UX layer super competitive, and the quality of experiences will only improve going forward. The app no longer stands for how well it manages to hoard and guard user data, but rather how good the experience is. 3. IT’S COMMUNITY OWNED: Unlike products and services in Web2 that are owned by corporations driven by the interests of investors and shareholders, Web3 has “projects” and “protocols” that are owned by communities, not individuals, due to the philosophy of decentralisation. While there are participants attempting to amass wealth rather than distribute it to the community, more and more projects are evaluated on their decentralisation and ownership distribution. This impacts how things are designed because in traditional Web2 UX design, a good designer tries to balance the user’s needs against the needs of the company. However, in Web3, the success of the project is aligned with its users, as they hold the tokens and assign them their value. With data no longer locked into an app residing in a database, it brings honesty to the equation. Apps that prioritise user interests will win in the future. App that use dark UX patterns to deceive users will not be successful in Web3. 4. NO COMMUNICATION CHANNELS EXIST, YET: In Web3, there is a lack of email or chat communication tools for peer-to-peer communication, and there is no de-facto protocol that can be assumed to be universally subscribed to such as email in Web2. Although tools like Push protocol and EthMail exist, they are not yet widely used and cannot be relied on for communication. This means that if someone buys something from your Web3 marketplace, there is currently no way to follow up with them to update them on the status of their purchase or to fix any issues, and they must come back and check with you. Asking for their email address is not always an option, as it could compromise their pseudonymity, allowing you to connect their email address to their wallet and potentially uncover all their blockchain activities. Therefore, it is important to design around this depending on the context. What I did on one project where a certain process would take upwards of a few days to complete was to allow the user to download a calendar appointment that stated when they needed to come back and check on the status of this process. You just need to be innovative about how to solve these kinds of problems. 5. THE WALLET IS EVERYTHING: In Web3, everything is based on cryptography using the concept of a pair of public and private keys. This provides users with pseudonymity, but not anonymity, in an otherwise transparent and open world. These keys are essential not only for authorising payments but also for verifying wallet ownership, interacting with smart contracts and linking all purchases to the wallet. Essentially, everything is connected to the wallet. However, this user-facing aspect of Web3 is largely unfamiliar to most people. Although it is vitally important to understand, most people do not know what these keys are. Losing or exposing the private key can result in the loss of all assets tied to it. Therefore, this area requires considerable design intervention to help people understand the significance of the keys, the right way to generate key pairs and the proper ways to store and protect them. Then comes the usage of the wallet itself. It is used to sign messages from applications to authenticate yourself and also authorise transactions being made on your behalf. But these messages keep popping up with messages asking you permission for something reminding me of the early days of Windows 10 where the user kept getting asked to authorise even the most banal tasks. A lot more polish is required to only seek the user’s attention when you absolutely need it. The technology is still so new that sometimes the messages from the underlying stack are exposed to the user, and they are presented with only hexadecimal code, asking them to sign the transactions. Wallet developers have a lot of work to do to make this a lot more user-friendly. 6. SMART CONTRACTS RULE: This is another concept in Web3 that has no equivalent in Web2. Smart Contracts are computer essentially programs that run on a network that was created to enforce an agreement between two parties. This means that two parties can rely on a transaction completing as agreed without the need for third-party guarantors and any associated expenses or delays, making transactions more efficient. However, since Smart Contracts are written in code and they can be difficult for people to understand. Although the code behind these contracts can be viewed on blockchain explorers, more work needs to be done to make them accessible to the mainstream. When this happens, it will revolutionise everything! 7. CENSORSHIP IS DONE DIFFERENTLY: In Web2, platforms that are owned by individuals or a small group have another problem in that they are also held responsible for implementing the censorship on them. In theory this sounds okay and the obvious thing to do, but if you explore this question more closely, there are many problems with this supposition:  They may very well be ill-suited to doing the job and may end up censoring things that shouldn’t have been censored excluding ideas that shouldn’t be excluded.  They have no option but to impose their world views on their systems and if they have a very large world-wide user-base, they will essentially be imposing their views on all of them superseding what’s culturally right.  Because they’re a central authority that can make these changes, they may be pressured by external individuals or groups to impose censorship that they themselves may not agree with.  There is always the question of “But what about the children?” that sneaks into every conversation about censorship and since there’s no argument against that, the lowest common denominator is set as the bar. The political leanings of a platform have been the reason for new ones to be setup creating silos and echo chambers that only confirm your already held beliefs without public discourse or the meeting of minds in the middle. This technology has the potential to fracture societies instead of bringing them together. Web3 has a different architecture that does not have central authorities that can censor others, making it a haven for free speech absolutists. Adults who believe they should be exposed to all kinds of ideas to progress in life can do so without censorship. For individuals who want a certain level of censorship, they can choose to use a filter and block certain types of content. This step allows individuals to make their own choices without resorting to drastic measures of stifling someone’s voice or de-platforming them. Although it is not a whole solution, it is a step in the right direction. A lot of work has to be done in this field in terms of making this UX better. ConclusionA decentralised internet can solve a lot of the issues that plague the world right now and give rise to new ways of interacting with others around the world. For this to become a reality, it needs mass adoption and the only thing stopping it is the complexity. User Experience designers can make a huge difference to adoption by making things much simpler for the everyday user. So if you’re a designer on this journey, kudos to you, you’re making a huge difference to the world. However, things need to be evaluated from the ground up based on the underlying decentralised architecture in order to deliver superlative experiences that are either at par or even better than the Web2 versions as this is indeed possible. "
    }, {
    "id": 30,
    "url": "http://localhost:4000/blog/basics-of-crypto/",
    "title": "A Curated List of Videos to Understand Crypto",
    "body": "2022/10/11 - This list of videos will help you understand crypto and Web3 better. The Basics of CryptoThe following is a collection of great videos to watch to understand the field of crypto and Web3. I hope to keep this updated with new things I learn. Economics Concepts (Yes, start here):  What is money? Short version, medium version and the long version.  How is money created? https://youtu. be/mzoX7zEZ6h4Blockchain Concepts:  What is a blockchain? The concept and the visual example and a demo What is a Bitcoin? https://youtu. be/bBC-nXj3Ng4 Consensus mechanisms: Proof of Stake vs. Proof of Work and other mechanisms What are smart contracts? Visual explanation What are NFT’s? Basic and more detailedAdditional Information:  The evolution of the web: With Marc Andreesen and Chris Dixon Mental models to understand Web3: By Chris Dixon A good overview of the crypto industry: By Chris Dixon Future of Applications: By Balaji SrinivasanGlossary of Terms to Understand      Wallets   The software that allows you to interact with a blockchain and stores your private key to encrypt messages and public keys to decrypt them         Hardware Wallets   Software wallets that are running on independent devices and are considered more secure as they cannot be hacked remotely       Private and Public Keys   A long set of hexadecimal numbers that can be used to cryptographically sign transactions. The Private Key is used to encode a message (or transaction) and the public key can be used to decrypt that message.        Coins   A unit of account on a blockchain that is usually used to pay for conducting operations on that chain. For example Bitcoin, Ethereum and Atom.        Tokens   It is a unit of account created for specific use that is based on the code of a different coin and therefore doesn’t have a blockchain of its own. For example Matic, DAI, UNI, etc.        Alt Coins   Anything that’s not Bitcoin       Shit Coins   Any coin that doesn’t have good fundamentals and instead probably built to simply pump its value and dump it on the market. Doge coin is a prime example.        Metamask   A software wallet that is used as a browser plug-in       HODL   Means Hold On for Dear Life. It is an investment strategy where people buy a coin and hold on to it for many years instead of selling it.        WAGMI   “We Are Going to Make It” or “We All Gonna Make It”. A positive affirmation.        BTFD   Buy The F*&amp;king Dip. An indication to buy a token or coin when the prices are low.        BUIDL   Build, spelt differently to indicate building in Web3       Bear Market   When sentiments in the market are low       Bull Market   When sentiments in the markets are high and when new all-time-high’s are usually being hit       Layer 1 Chains   Blockchains that are the final settlement layers and provide their own security       Layer 2 Chains   Blockchains built on top of L1 chains that usually do not perform their own security or finality and are instead built to handle fast and cheap transactions       App Chains   Application specific blockchains as opposed to general purpose blockchains       DEX   Decentralised Exchanges. They are typically exchanges where one coin or token can be changed for another coin or token. They usually do not have any KYC requirements. For example UniSwap, SushiSwap, DYDX.        CEX   Centralised Exchanges where the same operations as DEX’s can take place. They usually have KYC requirements and make it simpler for new users.        Stable Coins   Any coin whose value is pegged to a US dollar or any other Fiat currency. They have properties of tokens so that they can be used in crypto transactions (as Fiat currencies can’t be used in this way). But their value is based on the real-world value of the Fiat currency it represents.        DeFi   Decentralised Finance. It represents an industry within crypto that is trying to build equivalent infrastructures that are present in traditional finance institutions like banks. They enable people to deposit their currencies and earn interest, lend their money to others, borrow money from others, etc.        Cefi, TradFi   The slang for centralised finance or traditional finance       Staking   The act of securing a Proof of Stake network by depositing coins into staking pools       Delegation   If the amount of a coin or token you have is low and you can’t meet the minimum requirements of staking, you can delegate your tokens to someone else and they will then stake your tokens once they have the required number of tokens.        Liquidity Pools           Automatic Market Makers           The Merge   This is the point where the Ethereum blockchain switched its consensus mechanism from Proof of Work to Proof of Stake. It was a major milestone and therefore got a name.        ERC20   A coding standard for tokens that are built on the Ethereum blockchain. Examples of this include ETH, OP, ARB and others.        ERC 721   A coding standard for NFT’s that are built on the Ethereum blockchain. This is usually used when you have only one copy of an NFT, called “1 of 1”. Usually used to represent ownership of expensive objects.        ERC 1155   A coding standard for NFT’s that are built on the Ethereum blockchain. It is usually used when multiple copies of an NFT are produced by the creator.    "
    }, {
    "id": 31,
    "url": "http://localhost:4000/blog/six-ways-to-supercharge-web3-wallets/",
    "title": "Six Ways to Supercharge the UX of Web3 Wallets",
    "body": "2022/06/22 - Wallets are the entry point to web3 and they shoulder a huge responsibility Let’s Set the ContextThe debate surrounding ideal ways to organise societies is nearly as old as there have been people on this planet. We’ve gone from small bands of people living as hunter-gatherers whose primary concern was survival, to settlements centred around agriculture, which then formed countries whose primary concern became security. Because of the labour surplus created by each successive organisational structure of society, individuals gained more time to focus and specialise since they were able to depend on other members for the things necessary for their survival instead of having to produce it themselves. For example, the hunter-gatherers had to do the hunting, sheltering, protecting, entertaining, sewing, medicating and child-rearing all by themselves, leaving them little time in the day to focus on figuring out the science behind space travel; whereas today, I can write this article without worrying about hunting a boar to feed myself later. Interestingly, this specialisation of individuals has allowed the group to flourish and grow and this has spurred people on to develop even more focussed skillsets. On a side note, one of my favourite quotes is that of Robert Heinlein’s where he’s defining the “competent man” as I do feel a fuller perspective is useful. But it’s also special to me because it highlights how rapidly society has changed in the 50 years since it was coined!  “A human being should be able to change a diaper, plan an invasion, butcher a hog, conn a ship, design a building, write a sonnet, balance accounts, build a wall, set a bone, comfort the dying, take orders, give orders, cooperate, act alone, solve equations, analyse a new problem, pitch manure, program a computer, cook a tasty meal, fight efficiently, die gallantly. Specialization is for insects. ”  — Robert Heinlein, Author But while constructing societies around specialisation has obviously been beneficial, it hasn’t been without its flaws. There are still gross inefficiencies, inequities and injustices in any sizeable society. One may be tempted to blame it on corruption, but I think of it as a symptom and not the cause because it’s extremely hard to align any large group of people along a common goal — ask anyone who’s tried to arrange a dinner for a group! You try to select the restaurant that the majority prefer, or the most neutral place, or simply the boss’s favourite eatery — but none of these are going to satisfy the desires of the whole group and is bound to leave someone dissatisfied. While these strategies may be okay to apply in the case of planning dinners, they are problematic if used for anything more important; but these are also the models for the distribution of wealth, voting rights, laws to guide society, etc. The problems with organising societies based on majoritarian or authoritarian models are not new. They usually leave minorities without a voice and positive evolution takes a much longer time to take effect. Moreover, they enable a few of those in power to not just unduly enrich themselves, but to also change laws and processes that benefit them greatly. And far too often, there is discord between factions of people (domestically or internationally) so those in power are portrayed as necessary to maintain the peace. We allow these paradigms for societies to exist because we believe there isn’t a better way. But that’s an assumption based on the technologies of the past. However, technology has evolved and it’s time to reconsider our long-held beliefs. To develop a better model for societies, you need three things — the first is a way to organise groups around a common goal to achieve the things that can’t be done as individuals; second, a method to transact with other individuals in a trustworthy way so we don’t have to use violence as a method of resolving disagreements; and third, a foolproof system of owning property that allows us to benefit from the fruits of our labour. It wasn’t possible to provide these privileges without relying on central power structures to enforce them. Those in charge of these power structures (either through divine decree or as elected officials) used a varied set of tools like organised religion, currencies, laws, public relations and censorship to keep societies compliant and under control. When they weren’t able to do so with some individuals, they resorted to their usurped monopoly on violence to impose that control.  I once heard the line in a movie: “Geography is destiny, my friend”, and it struck me as the fundamental definition of life for a lot of us. It’s purely the luck of the draw and far too few have opportunities to change them. The world of cryptography, blockchains and cryptocurrencies is one where trustless architectures are laying the foundations that will enable the reorganisation of societies in any number of ways that we may wish. These technologies allow for individuals to hold custody over their currencies on their own; organise themselves into groups, vote to perform a certain action and immediately disband thereafter; recognise efforts put in by people who participate in developing “public goods” that benefit society and many others. And if the crypto world can achieve what it has set out to, societies may never be organised around geographies again and instead be driven by ideas and philosophies. One could even belong to more than one society at a time if they chose to. How amazing would that world be? Now, the Design StuffIf you’ve navigated through the sociology nerd forest above and are still reading this, you may be wondering what all that has to do with Web3 wallets. Well, I’ve always believed that any good UX designer has to understand the context they’re designing within as well as possible.  “Always design a thing by considering it in its next larger context — a chair in a room, a room in a house, a house in an environment, an environment in a city plan. ”  — Eliel Saarinen, Architect Web3 wallets are the first things anyone who is interested in becoming a part of the decentralised world will be exposed to. So it’s important to understand what its role is in the bigger picture before designing it otherwise your work will always be incremental. Having been first exposed to cryptocurrencies back in 2016, I’ve made mistakes, understood and overcome many of the technical limitations placed on me by the tech involved. I am now in a position to list improvements that will have the greatest impact on improving the user experience of these wallets and I’ve boiled it down to the following six areas:  Education and awareness Security Daily usage Motivation for usage Taxation management Preferences managementLet’s get into each of these in detail below.  Photo by Kelly Sikkema on Unsplash Focus Area #1: Education and Awareness: In my crypto-related conversations with people over the years, I’ve found that there are specific questions that most seem to have before they feel comfortable enough to dive in and learn the concepts themselves. The following are topics we need to cover whether through simple FAQs, orientation videos and/or interactive experiences. How can cryptocurrency be better than fiat? Incremental benefits will not captivate anyone. We need to find a way to explain why cryptocurrencies and decentralised apps are 10X better than the fiat equivalents. We need to:    Explain why decentralised money is better than allowing a select few to decide what’s good for everyone else.     Show how no one will be able to confiscate them for reasons as trivial as “the home address on record hasn’t been updated in a while”.     Talk about the layers of people that are involved in traditional banking and how their salaries translate to the fees they apply on allowing us to perform even the most basic of transactions with our own money.     Highlight the convenience of being able to transact with anyone instantaneously, without restrictions, and for a very small fee.     Illustrate the benefits of being able to carry our capital anywhere in the world without any kind of constraints.  What are the benefits of using Web3? No one will use something if they don’t understand the reasons for doing so. Once the benefits of decentralised currencies are understood by our users, we need to explain the advantages of Web3 dApps. Here, we can highlight the obvious privacy benefits, the ability to carry our social network with us across platforms, the capacity to earn from anywhere, new job opportunities (including the ones for non-techies, which is usually a surprise to most) in the space and new business models that can help launch entirely new services and products that have not yet been built. What exactly are these Web3 concepts? We need to create a glossary of terms and concepts that explains all the ideas that one needs to understand in order to use a Web3 wallet. Are there security measures in place? One of the biggest fears is about security and the potential of losing money. We should build interfaces that take users step-by-step through the security measures that they need to take in order to secure themselves on the decentralised web. This section can also be updated on an ongoing basis if new threat vectors are found. There’s no substitute for real sandboxes, is there? Let’s face it, there’s no substitute to actually using the wallets and sending and receiving our first transactions for us to get the hang of using it. We must create sandboxes in which people can send and receive test tokens to simulate the real environment that they are working with. This should be as real as possible, including the ability to send and receive test tokens from friends. Conversation, anyone? This has been one of the best ways to learn about crypto for me. I can ask the questions that aren’t covered by videos, discussion threads, FAQs or the like to figure out exactly what we need to do. Wallets should have interfaces where such conversations can take place because asking someone to jump on Discord isn’t really a good alternative.  Photo by Philipp Katzenberger on Unsplash Focus Area #2: Security: One of the biggest hurdles to adoption are the fears about security — security of key generation and management, recovery methods, volatility of currencies and, of course, scams. Seed Phrases While seed phrases have come a long way in simplifying the generation of private and public keys, it could be further eased by allowing users to specify their own words. They could then try to form sentences that will help with better recall if it ever becomes necessary. Key Management There’s a common phrase in the crypto world that goes: “Not your keys, not your crypto”, that encourages people to get off centralised exchanges and store their crypto on their own in cold wallets. But counterintuitively, it’s even more frightening to the everyday user because most of them don’t feel qualified enough to manage their own keys. This is a crucial area that needs to be addressed and solutions like those being developed by the likes of Arcana could help alleviate this problem. Recovery Methods Forgetting to store your keys is an all-too familiar problem as evidenced by the number of support calls on Coinbase about retrieving access to wallets because the users no longer remembered where their keys were. Good UX is forgiving and allows for people to recover from mistakes. So developing good and secure ways to regain wallet access is a necessity. There are several proposals for doing this, each trying to solve the problem for a certain type of user because there really isn’t a one-size-fits-all solution. Assistance Users that are unfamiliar with crypto wallets should be able to seek assistance from their family or friends. They could also appoint them as “guardians” who jump in to verify transactions in case the payment is an unexpectedly high amount or is being performed on an unsafe website or dApp. Scams Unfortunately there are rug pulls and cons all the time on the web — something about the anonymity seems to bring out the worst in some people. However, the wallet can take on the role of notifying users that they are operating on a website, a dApp or a wallet that’s been reported for scams by others. There are lots of details to wade through here to make this successful, but this is the higher-order bit.  Photo by rupixen. com on Unsplash Focus Area #3: Daily Usage**: The greatest impact will lie in UX refinements in the parts of the wallet that are used frequently. This includes making payment for purchases made, receiving of funds, buying things, etc. Payments This is the primary use of most wallets, but it’s too complex primarily because of wallet addresses. We will need to focus on ways to make it as easy as sending payments on Venmo or Google Pay where the transfer of money takes place using people’s names or phone numbers. Receipts Receiving money is usually a four-step process where we have to first determine the currency to be used, share the appropriate wallet address next, then specify the amount that needs to be transferred and finally verify if the right amount was received. Simplification? Yes, please! Ethereum Name Service has taken a good vital first step, but wallets could go further in making this even easier. Conversions In the future, people may hold coins/tokens of various projects that they would like to support. But these coins and tokens will be superfluous when transacting with each other. The receiver will specify which coin/token they want to receive the payment in and the bridging between chains and tokens will need to be taken care of without the user’s intervention or awareness. Volatility People are also apprehensive of the volatility in the crypto world. In everyday usage, this is mainly caused by the denominator (typically USD) that is used to display the balance in wallets. However, our bank balances are not constantly showing us what the value is in another currency so why do we do this with our crypto wallets? Transaction Fees Sometimes, a big deterrent to performing transactions is the sky-high fees charged when the network is busy. There are lots of transactions that aren’t time-sensitive, such as moving funds between the user’s many wallets, settling bills between friends, and others that can actually wait to be done at a less expensive time. But there aren’t simple solutions to allow these to happen. The solution currently is to either try the same transaction at another time when the network isn’t as busy and expensive, or to try and fiddle with the settings to set a lower gas fee. These are not ideal as firstly, the fees a user may be willing to pay may occur several days later on the network and may require multiple attempts. Secondly, most people aren’t savvy enough to understand what the right settings for gas fees need to be and trial and error is sometimes more expensive than actually paying the fee amount that was being charged earlier. In addition to the features available today, users should also be able to simply set the price they are willing to pay and allow the transaction to occur whenever the network fees drop to that point. The wallet could let the user know if the fees set are so low as to be impractical and never occur.  Photo by Mika Baumeister on Unsplash Focus Area #4: Motivation for Usage: Just holding the coins or tokens isn’t going to be enough to build mass adoption. We need to encourage users to utilise their tokens too. The following are some ways to help them to do so. Shopping While it may not be the case in the future, the need of the hour is for people to understand where they can spend this money that they are accumulating. Knowing that they can purchase domains, pay for utilities or even spend it on pizza will help them to understand that cryptocurrencies aren’t just meant to be held but used. Investing Easily Undoubtedly, if the currencies held in a wallet can earn you money while they just sit there, it’s a big draw. Investments in DeFi should be made simple through an integration with the wallets.  Photo by Kelly Sikkema on Unsplash Focus Area #5: Taxes: Once regulation is more solidified, the role of the wallet in enabling tax filing and management starts to become important. Simplifying Taxes The wallets will need to handle more complex things like whether a transaction is taxable or not; for example, what if the user gets a virtual sword instead of tokens when trading, or what if I swap one NFT for two others? These and other questions will need to be managed by wallets. Tax Guide The wallets can also start to inform users of transactions that will incur high taxes compared to others that are tax beneficial. No tax consultant today can do this stuff and has therefore got to be handled by the wallets based on the regulations.  Photo by Sten Ritterfeld on Unsplash Focus Area #6: Preferences: The settings features of wallets today extend only to how the wallet is set up and used — like default currency denominators, themes, languages, etc. But this is the decentralised world after all and the user’s preferences for the entire web and all the dApps are going to be eventually stored in the wallets. ZK Proofs Some dApps will require the user’s preference for light or dark modes so the dApp can adapt to it. But others will need to verify if the user is above a certain age and the wallet will have to share the relevant ZK proof for these kinds of interactions on their behalf. Censorship Options This is going to be another big area of focus. As detailed in another article I’ve written before, users can define their preferences for censorship and subscribe to different filters of the web as well. I. C. D. While the industry is pretty young, having started in earnest around 2010, and the individuals in it relatively youthful, the demographics of the users will also be changing. Concerns regarding what needs to happen in case of death or permanent incapacitation of the primary wallet holder are springing up now. If the keys or access is not granted to their legal heir, the crypto stored by them are lost forever. Wallets can play a critical role here and enable the funds to be released (all at once or in specified instalments) to the next of kin in such cases.  Photo by Luke Stackpoole on Unsplash ConclusionA long time ago, Personal Digital Assistants existed alongside mobile phones and the question of which device will take over the functionality of the other was being asked then. This is similar to the question that’s in front of us today. Will the wallet replace the functionality of the browser or will the browser take over the wallet? I don’t think the answer is any clearer today, but this is why we come to work everyday, isn’t it? We are going through the biggest paradigm shift in the technology space since Web 1. 0 and the role the wallet is going to play in terms of providing access, protecting users and a whole lot more cannot be overstated. The dream of Web 1. 0, to help create a decentralised world had one fatal flaw — it didn’t allow commerce on it then. But we’re able to put the final piece of the puzzle together today through cryptocurrencies and DeFi. While the tech is here, the role of user experience design will be extremely important in helping to remove all the complexity and making it ready for mainstream adoption. There’s a very long road ahead, but it’s also filled with opportunities. I hope this article will help to generate ideas and hopefully inspire you to start working in the field of wallets or even something in Web3. "
    }, {
    "id": 32,
    "url": "http://localhost:4000/blog/auditone/",
    "title": "The Audit.One Project",
    "body": "2022/06/01 - ClientIndustryYearDeliverablesAudit. OneCryptocurrency ValidatorsStaking Services2022Website designCommunication designDESCRIPTIONAudit. one is a significant revenue generator for the Persistence group and their existing website needed to be revamped to be able to cater to their audience better. We had to research and understand the very technical and complex nature of the industry they’re in, in order to redesign the website.  "
    }, {
    "id": 33,
    "url": "http://localhost:4000/blog/muvin/",
    "title": "Muvin",
    "body": "2021/06/01 - ClientIndustryYearDeliverablesFinone Financial Tech SolutionsFinance2021BrandingAppWebsiteCredit CardsMascotCommunicationsDESCRIPTIONThis project included the design of the brand, website and app for a neobank. The product differentiates itself by simplifying financial learning for young people and also enables them to operate their own faux bank account with the help of their parents. It reimagines banking with features that young adults care about, including being able to transfer money between friends, split bills, set goals and save for them all while getting rewarded for doing so.  "
    }, {
    "id": 34,
    "url": "http://localhost:4000/blog/designing-for-the-next-billion-users/",
    "title": "Designing for the Next Billion Users",
    "body": "2019/10/17 - These next big wave of users is coming not from the west but from the young, educated youth of India with access to cheap data plans and speaking many different languages. IntroductionThese next big wave of users is coming not from the west but from the young, educated youth of India with access to cheap data plans and speaking many different languages. This article talks about the design patterns to keep in mind when designing for the next billion internet users. Of late, we’ve been working with a few clients that have customer bases in tier-3 and tier-4 cities in India. This trend is an important one to note as it represents a huge population that has so far been untouched by technology. This group is significant for yet another reason because it also represents the migrant populations that travel to bigger cities for work. So we began working on a framework that aims to help design applications for the next billion users. To begin with, let’s understand who we are designing for a little better. All the descriptions can be debated but the objective is to describe the majority of users:  The user may be young or old but not very tech savvy.  Smartphones are the first computing platforms they’ve handled.  They use Android phones.  Their income levels could vary quite greatly as this is not a group defined by economics.  They seek technical help from other friends and family members.  They best understand new ideas through metaphorical comparison with real-world concepts. There are a number of dos and don’ts to keep in mind and if we went through all of them, it would simply make for a very long day. So let’s discuss the most important things here: #1 — USING PERMANENT POSITIONS FOR OBJECTS: In the real world, different objects occupy different spaces. This is starkly different in the digital world where the same area of the screen is occupied by different “objects” at different times. This is a huge hurdle to overcome for a new user. One way to design for this kind of user is to allocate spaces within the screens for certain types of actions. For example, you can allocate the bottom right of the application for confirmatory actions such as Save, Submit, Okay or Approve. The other corner of the screen can be allocated for the negative actions such as Cancel, Disapprove, Reject, etc. Having a permanent place on the screen for certain types of functions helps build a relationship between the position and the action. In the long run, it also helps build muscle memory for the required kinds of actions. The users, then, can also guess where to tap on a screen that they may have never encountered yet.  #2 — AVOID SCROLLING: The second thing to do is to avoid scrolling. Scrolling by itself isn’t something that this group of users will find intuitive. If possible, present all the information on multiple screens instead, with a progress button that takes them through each of them. But if you must use scrolling, provide the user with some kind of hint which will allow them to understand that more of the screen is available below. Make sure that the information on a screen doesn’t “cut” exactly where the physical screen ends and instead lay out the screen such that there’s a portion of what’s below peeking above the bottom of the screen. Another hint that can be provided is to show an illustration of a finger tapping and dragging the screen.  #3 — USE TRANSITIONS WHEN GOING BETWEEN SCREENS: The third thing to keep in mind is to use transitions when going between screens. When the same real estate is being used by different sets of information, it helps a user to understand that the same space is being used by a new lot of information if you use some kind of transition animation between the screens. If you slide a screen left, the user will know that the first set of screens has moved to the left to make space for the new screen. In addition, the user will also know that if they “go left”, they will be able to see the old screen. What doesn’t work is a quick switch from one screen to another because that doesn’t allow a user to switch contexts seamlessly. This is one of those principles that actually makes sense to use for all users and not just this group, but it is essential for this particular group. #4 — USE SKEUOMORPHISM: It is also recommended that you use skeuomorphism. If you’ve never heard the term before, it’s a fancy way of saying that the interface should use depictions of real-world objects. For example, if there’s a need to indicate a delete function, the functionality should be depicted using an icon that resembles an eraser or a trash can as opposed to an “X” which would make sense to someone familiar with technology but not to the others.  #5 — BUILD USER CONFIDENCE: As interface designers, we must also work hard to build the confidence of digital novices. These kinds of users will be worried about making mistakes, especially when it comes to using applications related to money. It would be good to let them know what they need to have available in order to perform the task and to also let them know the steps involved to complete the task. Additionally, messaging on the screen can let the user know that they are doing a good job with each step. This will encourage them to go from step to step in a simple manner. A summary step that indicates all their inputs and decisions before performing the task will be required in order to allay any fears that the user may have. For tasks that require the users to make multiple decisions, try and keep it to one decision per screen so the user can focus on performing that one action as accurately as possible. A mini celebration after the task is performed correctly will also reinforce the user’s confidence in being able to perform it the next time.  #6 — USE VOICE INTERFACES WHEN POSSIBLE: The most important tool in the basket is the use of voice interfaces. If there is a possibility to use them within the application, the return on investment is extremely high. We frequently underestimate the amount of learning we have gone through in getting used to GUI or touch-based interfaces. While tech-savvy users get through each of these steps quickly and seamlessly, it is a huge hurdle to learn even basic actions like scrolling, copy/paste functions, navigating within screens, etc. , for those who haven’t grown up with technology. But voice interfaces bridge these gaps seamlessly. Everyone knows what they want to achieve and most people can put it into words easily. As designers, we could use technologies like Slang or Dialogflow which allow you to infuse voice interfaces within GUI, creating dual-modal interfaces. In this way, voice can become assistive and allow users to handle applications even if they aren’t very well-versed in GUI-based ones.  ConclusionSo these are just some of the many things one needs to think about when designing for the next billion users from India. This is by no means meant to be an exhaustive list but something to get you started in thinking about how design can help bridge the technological gap that’s forming in our society. "
    }, {
    "id": 35,
    "url": "http://localhost:4000/blog/voice-interfaces/",
    "title": "Co-existence of Voice Interfaces in Apps",
    "body": "2019/08/23 - While every sci-fi show depicts Voice Interfaces as the future as it seemingly makes for very simple interactions with devices. I examine this idea. IntroductionWhile every sci-fi show depicts Voice Interfaces as the future as it seemingly makes for very simple interactions with devices, the promise seems to always have been right over the horizon. But recent developments have shown promise. And no, I’m not talking about the clunky UX offered by the Siri’s or Alexas which attempt to offer a single interface  experience, but other technologies that integrate within apps to offer a multi-modal interface and there lies something that has the potential to be useful. BACKGROUND: Let us begin by understanding the role of voice interfaces. Voice interfaces are great:  They are simple to use.  Almost everyone can use them.  They have the potential to combine multiple steps that a typical GUI interface needs to have.  And with localisation, they have the power to reach many more millions of users who find the existing touch-based GUI interfaces difficult to understand and use. But many kinds of interfaces have been built for machines in the past. You have everything right from switches and buttons to mice, pens and screen-based touch interfaces like those on your smartphones. Every time some new interface was created by someone, there has been a tendency to portray it as the killer interface that will replace all interfaces. But the fact is that switches, handles, knobs and pens all exist today. The reason for this is simple — each interface offers some specific advantage over another. For example, a light switch is cheap, it is always physically available to users, it is very simple to operate and is perfect for the electrical wiring system that it is a part of. Whereas it’s a far more efficient use of space to include a touch-based screen than to include a screen and a physical keyboard. Until brain-machine interfaces like the one that Neuralink is working on become mainstream, all other interfaces including voice-based ones can be only a part of a collection of interfaces that will be used by humans. They will therefore need to be integrated into existing user interfaces and not thought of as replacements for anything. So the principle of design needs to be that of coexistence, not of replacement.  DESIGN FOR CO-EXISTENCE, NOT REPLACEMENT  Secondly, we are talking about integrating voice-based interfaces into existing applications here using technologies like DialogFlow or Slang and this is not the same as creating a skill for Google or Alexa that could potentially be linked to a website or an app.  INTERFACE DESIGN CONSIDERATIONS: While designing interfaces for Voice UI, the following need to be considered:  Indicate that the interface is voice-enabled — Since it’s best to use examples when discussing complex topics like this, we will use the interface of one of our clients, Lenskart. Lenskart, is an e-commerce store that sells prescription and non-prescription glasses through their website and their apps. For this video, we’ll focus on the mobile app. So as you’ll see from the interface, we’ve included an activation button that’s been styled to indicate that you can tap this to say something.  Indicate to the user what is voice-enabled and the kinds of commands that can be issued — There are also similar-looking icons placed on other elements in the interface that indicate that these other elements too are voice-enabled.  Let the user know that their privacy is protected — When one taps the activation button, it gets “enabled” and starts listening for instructions from the user. We chose not to go with activation keywords here because there’s a learning curve involved with that. You’ll also notice that there’s a line around the button that keeps reducing and when it goes down completely, the button gets disabled. This mechanism does two things — one, it allows the user to give continuous commands without activating the voice interface each time. Two, it tells the user that this interface isn’t always going to be listening and respects the user’s privacy. Finally, tapping the activation button again immediately stops the system from listening further.  Provide confirmation and feedback for actions performed — Now when the user issues a command, something like “Show me sunglasses”, the application has been designed so it goes straight to the screen that shows the sunglasses.  Provide ways to recover from a mistaken action — If the voice-processing engine isn’t very sure about the guess it’s made about having heard “Sunglasses”, we can indicate the same to the user and get clarity on the next screen if the user really meant to do that or not. This allows a user to recover from the error by simply clicking the “Undo” button or saying, “No, I meant sunglasses”.  Provide a way for power users to understand how to harness the power of voice — Users may intuitively begin using the voice features in the app but in the initial period when people may not really know how this works, providing them with the ability to understand what’s possible may be required. What we did to enable this is to have an information icon placed to the right of the activation button. Tapping this will bring up a sheet with all the available types of commands that can be issued on the application. This sheet could also be presented when the user says things like “What can I say?” or “What can you do?” which are equivalent commands on Google Assistant or Siri.  Design for voice-only workflows — Voice-only workflows are powerful new user journeys that come up when working with voice. You don’t need to work through screens sequentially anymore and in most cases, multiple steps can be combined. In this example, the user can ask to check out and the cart page will show up after which the user can choose the method of payment and the delivery address. However, with voice, these two steps can be combined using a simple command like, “Checkout using card number ending with 0399 and deliver it to my home”. Upon this command being issued, a user is brought to a confirmation page that shows the card chosen and the address chosen and all the user needs to do is hit “Proceed”.  THIS IS AN EXTREMELY POWERFUL NEW CAPABILITY THAT IS OFFERED THROUGH VOICE INTERFACES AND REQUIRES UX DESIGNERS TO THINK DIFFERENTLY WHEN DESIGNING.    Eliel SaarinenArchitect ADDITIONAL THOUGHTS: So that’s a quick look at how to design for voice-based interfaces. One just needs to keep in mind to not take an all-or-nothing approach, but rather design for a mixed interface. Getting started is surprisingly simple, but employing voice interfaces and exploiting their full power are going to require quite a bit of thought. "
    }, {
    "id": 36,
    "url": "http://localhost:4000/blog/ux-problem-with-the-voting-system/",
    "title": "The UX Problem with the Voting System in India",
    "body": "2019/05/30 - Something as important as voting is fraught with UX problems and the intention of the voter is not well expressed within the systems that exist in places such as India IntroductionA vote is defined as a right to express a wish, choice or opinion. In the context of a democracy, it is the right to express one’s opinion on how s/he would like to be governed. If that’s the primary objective of a vote, is the mechanism we are using to capture the user’s opinions serving our nation well? And from my own corner of the world armed with my own tool kit, I wonder if thoughtful UX design could make it better. So what’s the problem that we need to fix this? In the “plurality voting system” that is followed in India, which we use to vote representatives to the lower house of the Parliament, a citizen is allowed one vote and to only cast it in the affirmative. This is an extremely limited form of expressing one’s opinion. Everything is hunky-dory if there’s a candidate that represents your views, you just cast your vote for them. But what do you do in the case where there are no candidates that represent your convictions? The only choices you’re left with are to express your support for the least objectionable of the candidates, abstain from voting, cast your vote for “None Of The Above” or use your vote tactically to mitigate your losses. Are any of these options clearly communicating the opinions of the citizen? Is a vote for an opponent the same as a vote for a candidate? Is a vote for the least objectionable candidate the same as support for their mandate? It’s no wonder that one of the most common refrains during voting season is: “It’s like choosing between the devil and the deep sea. ” All of these choices leave people disenfranchised and hopeless about being able to affect change through their votes. In fact, these plurality voting systems face much more criticism than that. In a long enough timeline, these systems result in fewer political parties, reduced incentives for new players to participate, increased gerrymandering, the use of “spoiler” candidates with the sole objective of detracting from the front runners and finally, the increased use and influence (and therefore the privatisation) of mass media on political outcomes. None of these are the desired results for a nation or even the conspiracy of any political party or candidate. Not even the most jaded among us can agree with the idea that a political party wants to lead a citizenry in a direction that it doesn’t want to go. The parties just want to win the game. These are just the definite outcomes produced by a system whose rules are defined in a certain way. We find that this happens very often in UX as well. Whatever we set as the goals, key performance indicators or criteria for progress, we see the users of the system strive for this. Set new goals or new criteria, the users of the system start to strive for that new goal. So, what can we do to improve our voting system? We can change the rules that govern them. We can design voting methods that keep the process efficient and also more expressive. While there are no perfect systems out there, all we can adopt is the spirit of building “a more perfect union. ” We have to keep trying to find better solutions and keep fixing the new problems we find. In other words, we need to evolve. There are many different solutions one could think of, but for the age of our democracy, I find two models that would work better for India: MODEL #1: PARLIAMENTARY-STYLE VOTING FOR ELECTION TO THE LOWER HOUSE: New bills are proposed all the time in the Parliament and votes are sought in order to make decisions on them and either passed forward or rejected. The polling is done with a “Yay” or “Nay” vote. This system is efficient and much more expressive:  It tells everyone the bottom line of whether or not enough votes were received to win.  It expresses what kind of support it had.  It expresses what kind of opposition it had.  It also expresses how close the vote was. This model can be used such that a voter could cast one vote as they do today but could cast it either in favour of OR against a candidate (you can only do one or the other). This simple change would result in the following advantages:  It doesn’t have the negative effect of devolving into a scenario where there are fewer political parties.  There is clearer indication to candidates from previous polling data on what the voter base is looking for.  It would result in more moderate mandates that appeal to larger voter bases as parties now have to worry about the supporter’s views as well as the dissenter’s.  It encourages new participants to come into the arena with new ideas.  It would lead to the formation of more stable governments and therefore stronger economies.  BY APPLYING UX DESIGN PRINCIPLES TO OUR VOTING METHODS, IT IS, IN FACT, POSSIBLE TO DEVELOP A SYSTEM THAT ALLOWS THE VOTER’S VOICE TO BE TRULY HEARD.  MODEL #2: RANKING OF CANDIDATES: This is a much more involved process but even more expressive than the first model. This model involves ranking all of the candidates in order of preference. Just as in today’s model of affirmative voting, this ranking model is only done in the affirmative. In addition to the advantages of the system above, the ranking also expresses the following:  There is no way to easily predict who the winners may be. And this is a good thing because then you can’t game the system.  It has the potential to clearly express not just the mandate that won, but also the specific points within it that actually caused the most affirmations. CONCLUSIONThere may well be other better-suited models of voting but by applying UX design principles to our voting methods, it is, in fact, possible to develop a system that allows the voter’s voice to be truly heard. It would not only reflect the actual democratic choice of the citizens, but also benefit our nation as a whole. As one of the few countries that has electronic voting, it would pave the way for India to be a more authentic democracy as well as the largest. "
    }, {
    "id": 37,
    "url": "http://localhost:4000/blog/design-should-reflect-values/",
    "title": "Why Your Design Should Reflect Your Values",
    "body": "2019/04/05 - User experience designers who are designing these experiences have their own world views that shape their designs. This is the right thing to do. INTRODUCTION: Everyday, we make countless decisions prompted by the design of systems, software and experiences that we engage with. More often than not, we barely give these decisions a second thought. But user experience designers who are designing these experiences have their own world views that shape their designs and users are only making choices within the subset of decisions provided to them by the designers. Design is about changing and managing perceptions and ideas about the world we live in. It’s powerful because when employed well, it works wonders as a way of wielding influence. This influence can broaden our horizons, make us aware of our hidden biases and even train good behaviour. Or, on the other hand, it can block progress and foster addictive and unhealthy behaviours such as providing positive reinforcement when we buy stuff we don’t need.  DESIGN IS ABOUT CHANGING AND MANAGING PERCEPTIONS AND IDEAS ABOUT THE WORLD WE LIVE IN. IT’S POWERFUL BECAUSE WHEN EMPLOYED WELL, IT WORKS WONDERS AS A WAY OF WIELDING INFLUENCE.  AN INNER VOICE: Design, regardless of the sphere it is employed in, can very rarely be objective. Yes, in a very basic sense, there is a choice to be made between an inefficient and an efficient set of user interactions, such as organising a login screen to require the least number of clicks in order to authenticate a user. But design isn’t like mathematics and there is usually more than one right solution to a problem. So while an inexperienced designer may be focussed on making choices between “efficiency” and “inefficiency”, a more mature designer may understand that fewer clicks isn’t the only way to evaluate a design. Instead, creating the right impression of “playfulness” is an important quality to convey as well and may actually design an experience that is less efficient but more memorable. Inevitably, the designer’s ethos, values and principles reflect in the creations and experiences s/he designs.  ”THE WAY WE THINK ABOUT DESIGN AND THE CHOICES THAT WE MAKE HAVE REAL-WORLD IMPLICATIONS.   Take, for example, the software Adobe Illustrator. It has a very methodical approach, going step by step, ensuring that the user is faced with no surprises. If you are trying to close the application, a prompt asks you to save your last set of changes to the project. Or, if you tried to apply an effect that requires a great deal of processing power, the application tells you that it is going to take some time to perform this task. In this manner, the user is aware of every step that s/he is in at each stage. For people who have met Sreedhar, the designer who was part of the team that designed the user experience for Illustrator, this methodical approach that the application takes is very much in keeping with his personality. Even when we take a careful look at a familiar building, we often know the thought that went into its structure and design. This is because it’s a physical manifestation of the philosophy of the architect. Whether it was Laurie Baker, the pioneering architect who believed in maximising space, ventilation and light or Charles Correa, known for his use of traditional methods and materials, the buildings they designed very much reflected their ethos. While many designers strive to achieve an objective design, it is probably worth stating that they should pursue a path that reflects what their view of the world is instead. That’s the only way to be honest in your work. The way we think about design and the choices that we make have real-world implications. These perceptions are also reflected in the manner in which user experience designers conceptualise and treat the user.  THE SERVANT OF TWO MASTERS: Apart from being driven by an inner voice, a designer also has to react to and make decisions about things that are placed in front of them by others. One main point of contention has to do with the fact that a designer is typically the servant of two masters. It is a field where the client is paying the designers to advocate for users and protect their needs and concerns. As a result, the designer is increasingly called upon to be aware of the dilemma of how far s/he is willing to listen to the client and where s/he would draw the line. For example, in the UX design of a mobile banking application, one of the ways of authenticating a transaction is to use Aadhaar data instead of other methods of authentication. A way to speed up the process, in case the user returned a second time to perform a transaction, is to store a copy of the biometric data on the local device. A designer concerned with privacy and security may recommend a certain workflow for the engineers to implement and a designer who prioritises speed and convenience may suggest another. Another example is of the choice of authentication mechanisms for logging into applications. Quite often face recognition has been touted as the solution to these problems, but will a designer account for women wearing a hijab, burqa or a saree to cover their faces? Will the designer’s political view of the world clash with that of the client’s and what choices will they make in that case? Also, a common point is the identification of gender in most registration forms. Will they have the option to pick “third gender”? Would the designer believe that this is an important enough point to be forceful about its inclusion in the registration process? Would they stand up to a client who may feel otherwise? Will they know the decision made by the Supreme Court in this regard? This level of sophistication may still be a distant dream since many applications out there still use “sex” and “gender” interchangeably without understanding the distinction between the two.  RESPONSIBILITY: I think it is important for designers to realise the influence they have on the world around them and the kind of impact they can have. I hope it fills them with the sense of responsibility they need to have when approaching their work. They’re no longer just designing a login form, or just creating an e-commerce website or just designing a service app. I hope they give it the respect their work deserves. The only way for India to become a hub for design is to have more debates about the right approaches and hear multiple perspectives. The best place to start is for designers to be honest about who they are and what they stand for. Whatever their view of the world, however limited or expansive it is, they should express it. One may be afraid of losing clients, but in fact, the opposite will happen as they start to attract clients that want their kind of work. They will also differentiate themselves in a crowded market where designers are trying to be everything to everyone.  ”THE BEST PLACE TO START IS FOR DESIGNERS TO BE HONEST ABOUT WHO THEY ARE AND WHAT THEY STAND FOR.   We are going through the biggest paradigm shift in the technology space since Web 1. 0 and the role the wallet is going to play in terms of providing access, protecting users and a whole lot more cannot be overstated. The dream of Web 1. 0, to help create a decentralised world had one fatal flaw — it didn’t allow commerce on it then. But we’re able to put the final piece of the puzzle together today through cryptocurrencies and DeFi. While the tech is here, the role of user experience design will be extremely important in helping to remove all the complexity and making it ready for mainstream adoption. There’s a very long road ahead, but it’s also filled with opportunities. I hope this article will help to generate ideas and hopefully inspire you to start working in the field of wallets or even something in Web3. "
    }, {
    "id": 38,
    "url": "http://localhost:4000/blog/4-ways-to-improve-patient-experience/",
    "title": "Four Ways to Improve Patient Experience with UX Design Principles",
    "body": "2019/02/21 - Post my experience in designing an interface for a birthing hospital the importance of UX in this space was highlighted. At 37, Anu is having her first pregnancy. She’s nervous. She relies on her hospital for timely support and information. But she has to wait three hours for an appointment and doesn’t get notifications. She plans to renege. Modern medical care needs to go beyond helping Anu deliver her baby, and improve her overall patient experience. With rampant competition and an aware, digitally savvy customer base, patient experience — timely appointments, easy access to information and good communication with doctors — can increase patient loyalty besides eliminating waste and reducing costs. An effective, intuitive way for hospitals to improve patient experience is to embrace technology and UX design principles. HOW DO UX DESIGN PRINCIPLES HELP IN DELIVERING BETTER PATIENT EXPERIENCE?: It involves using technology to reorganise services according to how patients behave as opposed to how the hospital’s default system runs.  From our research, we’ve identified four UX drivers that can improve patient experience:  ”AN EFFECTIVE, INTUITIVE WAY FOR HOSPITALS TO IMPROVE PATIENT EXPERIENCE IS TO EMBRACE TECHNOLOGY AND UX DESIGN PRINCIPLES.   #1 ELASTICITY: This refers to how “elastic” or flexible the hospital’s communication is. For example, customers during registration are asked for unnecessary information. This creates delay and distress. Instead, a quick online registration process through a bot in an app can ensure only Anu’s critical information is requested on priority. Another pain point for Anu is having to go to multiple places for information. Consultation cards on the same app can have their status updated to let Anu know what she needs to do next, depending on where she is in her pregnancy journey. For example, if her doctor gives complex post-consultation instructions, then cards appearing after the consultation can break them down into easy steps for Anu.  #2 EASE: This deals with how the hospital helps the patient save time. Research shows the more touch points a patient has to go through, the greater their dissatisfaction. Through an online experience, Anu’s entire user journey can be completed on the same app — from check-in, to seeing her spot in the queue, to getting updated on doctor status, etc. Another way of creating ease is time slots instead of exact times. Research shows failure to comply with exact times causes patients to become anxious. Instead, a flexible time slot manages Anu’s expectations and, if she is 15 minutes late, she doesn’t create a domino effect on other patients’ wait time. Anu also shouldn’t be wasting time searching for medical records before every consultation. By digitising everything on the app, she or even her spouse gets easy access. A chat facility is another great time-saver; she can just connect with her doctor instantly in case of a query.  #3 EMPATHY: Good UX is about increasing empathy for Anu’s journey. In addition to many of the above tactics, there are more overt ways to do this. For example, the app can collapse Anu’s complex pregnancy journey into easily accessible milestones on a timeline. So, on any given day, she can take comfort in looking at her journey. Moreover, she can book lab appointments and RSVP for events from this view. Giving Anu access to a community is another example. A lot of first-time parents are anxious. Accessing a community through the app can open up invaluable peer-group support.  #4 EFFICIENCY: Introducing technology with UX design principles can streamline processes and remove inefficiencies. This increases productivity and brings down costs. That’s not all; the platform becomes a one-stop shop for all of the hospital’s packages. This creates simple, effective communication around each package which, in turn, can result in better conversions. ConclusionIn conclusion, sensitivity, relevance and sociability guiding all UX decisions make for a vastly improved patient experience. Also, let’s not forget integrating tech and UX paves the way for machine learning and AI which can unlock a whole new level of efficiency and patient satisfaction! "
    }, {
    "id": 39,
    "url": "http://localhost:4000/blog/the-five-promises-of-technology/",
    "title": "The Five Promises of Technology",
    "body": "2019/01/10 - Having a framework to evaluate the use of technology is useful in evaluating how it can be employed IntroductionIn this era of technology, everything from sleek gadgets and AI to smart user interfaces promise to help businesses streamline processes, increase the number of happy clients and retain customers. However, the million dollar question is — are these technologies fulfilling their intended purpose? Fads also exist in the technology space. There are poorly designed implementations of technology as well. And it is extremely hard sometimes to differentiate between the two. For example, chatbots were all the rage over the last couple of years and while they provided real value for some, many e-commerce websites implemented them with unimpressive results. If it takes users fifteen interactions to accomplish a task with a chatbot that could otherwise be completed with just three, the chatbot is definitely an obstacle to the users in their journey. The bot might even be losing customers instead of helping you gain them. Now is the chat technology useful, or not? When technologies and tools are implemented without being properly designed, resources are wasted and revenues take a hit. Most importantly, this has a significant effect on the user’s experience with the business. These effects are obvious and inarguable but companies across the world end up making this mistake quite often. So why do so many go so wrong while evaluating which technology brings them the most value? It’s got to do with their framework for evaluation. An effective method would be to go back to the first principles and see if it delivers on the “five promises” of technology i. e. speed, scale, spread, smarts, and asynchrony.  ”AN EFFECTIVE EVALUATION OF TECHNOLOGY WOULD BE TO GO BACK TO THE FIRST PRINCIPLES AND SEE IF IT DELIVERS ON THE “FIVE PROMISES” OF TECHNOLOGY I. E. SPEED, SCALE, SPREAD, SMARTS, AND ASYNCHRONY.  BENEFIT #1: SPEED: Take the example of a loan management system in a financial services company. The usual customer journey would involve meeting the first line of customer service who helps fill out a form about the loan that s/he needs. Next, the credit of the prospective client is checked to determine loan viability. The finance team, which includes risk assessment, might eventually flag the application if the customer does not have enough collateral for the loan amount sought. If this real-world process is simply replicated as a web-based application, it will create a bottleneck because the number of people applying on it would overwhelm the system very quickly. However, a more befitting way to design it would be to implement machine learning to manage the stage-by-stage progress of the loan application through the system and to use human effort only to manage the exceptions that the system throws up. The actions performed by this human should also be used to reinforce the learning and make the system better over time. The person is then best imagined not just as a user of the system, but as a trainer who is making the system smarter. Such a system will achieve true speed for the organisation.  BENEFIT #2: SCALE: Technology-centered thinking would direct new businesses to use the technology to scale up their businesses. For example, an e-commerce-first approach would help a business scale without the obstacles faced by offline stores that are typically capital intensive. Take the example of Urban Ladder, the online furniture retailer that began with a user-friendly website with a focused approach of 35 categories of furniture catering to three cities in the first year. The results of this approach are there for all to see. Potential customers wouldn’t have scaled up to thousands and lakhs from a few hundred if the business hadn’t chosen to take the e-commerce route first.  BENEFIT #3: SPREAD: Technology instantly helps spread businesses from one location to multiple ones. Besides geography, language reaches through technology can help tap into potential customer bases that would otherwise be impossible to reach. Voice-based technologies developed by companies like Slang Labs, for instance, help businesses tap into the market of regional language users by offering a multilingual voice-based assistant platform that can be integrated into apps. This can help level up your business exponentially.  BENEFIT #4: SMARTS: With the proliferation of AI and it being made more widely applicable in regular businesses through companies like Prowler. io, technology has the ability to bring machine learning and artificial intelligence to every business out there. It can help refine and optimise processes within organisations and even predict what users would do next. With this kind of intelligence at your disposal, you can deliver superlative customer experiences, optimise your inventory so you never run out of stock or maintain any excess and even expand your business at a fraction of the cost and time it would have normally taken.  BENEFIT #5: ASYNCHRONY: One of the great advantages of technology is that it brings asynchrony in our communication and decision making. Any system that doesn’t employ asynchrony at its core is likely to be slower than others. Common examples of asynchronous technologies are email and WhatsApp. These allow people living in different time zones to discuss a subject and make a decision without requiring all of them to be available at the same time. This has brought incredible efficiency to communication and reduced the time spent in making decisions drastically in any system that relies on these types of asynchronous technologies. CONCLUSION: When technology is to be integrated into your business, the manner in which it is done must fulfil a minimum of three of these five promises for it to have any significant impact on revenue. If designed well, however, all five promises of technology can be taken advantage of and be a game changer for any organisation. "
    }, {
    "id": 40,
    "url": "http://localhost:4000/blog/lenskart/",
    "title": "Lenskart",
    "body": "2018/06/01 - ClientIndustryYearDeliverablesLenskartPrescription GlassesSunglassesContact Lenses2018Website designCommunicationsDESCRIPTIONThe ofﬂine stores, the desktop website and the mobile applications that Lenskart transacted with customers over were doing very well. But the mobile website was converting the least number of visitors into customers as compared with their other platforms. The client had consequently used that touchpoint to direct customers to download their mobile apps as a stop-gap solution instead until they had a chance to dedicate the resources required to overhaul the website completely. Our challenge was to design a mobile e-commerce site that would help in better conversion and work seamlessly with Lenskart’s offline stores and processes. The client had also worked with other UX agencies before working with us and had not been able to achieve the goals that they had set out to achieve. They had, therefore, proposed some key performance indicators (KPI’s) as goals for us to achieve and required us to guarantee them. We examined their performance data for the past few months and also conducted a study of their existing site to understand whether the numbers proposed could be achieved. After this, we felt confident enough to take on the challenge. THE OUTCOME: The client has implemented the design we created for them on their mobile website and also applied it to their Android and iOS apps. All key performance indicators are looking up.  8 Clicks to finish a purchase – 25% reduction 3 eyewear in a screen – 100% increase 80% of users found new design engaging 90% of users found new design clearer 8 personas addresses Offline store integrationTHE APPROACH: Before beginning work on the design for the new website, we discussed what our approach would be and ascertained the following guidelines:  There was extensive market research done by the client so that information would be provided to us. It established eyewear as a fashion statement in addition to providing pure utility.  We had complete freedom to create the design we needed without restricting ourselves to what was already designed and delivered on the desktop website or the mobile applications.  We set a goal for ourselves to create a seamless experience between the mobile website and the offline stores.  Wherever we disagreed with the client, the client agreed to performing A/B testing to determine the right approach. THE PROCESS: IDENTIFYING PROBLEMS: We worked very closely with the Lenskart team to identify the problems and recognise the user’s needs. This meant studying their research documents and examining their website analytics very closely. We then designed user journeys that didn’t repeat these problems while simultaneously addressing the needs of each type of user. THE RIGHT METAPHOR: We wanted the mobile web experience to reflect a person’s experience of walking into the store as closely as possible. We observed that customers that purchased glasses were trying on more than 30 frames per session and wanted to bring that learning to the web. We designed the interactions such that they allowed customers to easily view a lot of different frames per session, thus increasing the chances of conversion greatly.  NARROW OR WIDE: For a lot of people, eyewear is an integral part of their life. It’s the ﬁrst thing you wear as soon as you wake up and start the day. But over the last few years, it’s become more than that, it has occupied a space outside of utility and become a style statement. We wanted to take advantage of this positioning and treat the website more as a fashion brand as opposed to a utilitarian one. We therefore needed to design the site that not only helped narrow choices for a user with each subsequent step but also created paths for them to discover more products and styles to increase the chances of conversion. UNIVERSAL COMMERCE: While talking to people at the client’s stores and asking why they shopped at the store instead of shopping online, we understood their reasons for doing so. This made it clear to us that attempting to convert users to shopping online only would not address all their needs. We therefore took a “universal commerce” approach where we kept in mind the ofﬂine features that were important to some of these users. So customers could purchase the product online and get it delivered either to a store near them or to their home, but perform a return or exchange at the store/home; or even place the order online, try it on at the store/home and complete the purchase there.  PROVING OUR CASE: We tested the prototypes we designed on 10 users and recorded the user’s brain activity using an EEG headset while performing various everyday tasks. This way, we could understand what the user was feeling without the need to ask them questions about what they were thinking. They could just stay focussed on the task that we had asked them to perform. We understood the successes of the system we had designed and identified a few optimisations that we could make based on this test. We then made these rectifications before finalising the design.  "
    }, {
    "id": 41,
    "url": "http://localhost:4000/blog/cloudnine/",
    "title": "Cloudnine Hospitals",
    "body": "2018/03/01 - ClientIndustryYearDeliverablesCloudnine HospitalsSpecialty Chain of Birthing Hospitals2018-20193 Apps DesignedService DesignTHE CHALLENGEWhen patients go to hospitals, much of their satisfaction depends upon the people they interact with, the time they spend there and the ease of the experience. Healthcare in India has not been as highly invested in as it is in other countries but it is starting to see some investment in technology. Especially in a densely populated country like India where the daily traffic in hospitals is high, a hassle-free hospital experience can only be delivered through the use of technology. THE OUTCOME 3 hour wait-time reduced to 1 hour 8 touch points reduced to 3 An app suite that brought everyone at the hospitals brought onto one platform Reduced number of steps in registration Addition of doctor app that talks with the customer appTHE APPROACHFIELD RESEARCH: Our goal was to understand and map the user journey through the hospital. From the moment a patient arrives at the hospital until the moment they leave, we wanted to see what was happening on the hospital floor. We focussed on three points:  What are the various touch points in the hospital? Who is the patient speaking to, other than her consultant? How long do patients wait for their consultation on an average?We mapped the touch points using an architect’s map of the hospital floor supplied by Cloudnine. Here’s what we found.  Patients usually go through 8 touch points between arriving at the hospital and actually seeing their consultant. A majority of that time is spent feeling nervous or irritated.  On an average, patients speak with up to 7 people, including a customer relations executive, a receptionist, the consultant’s personal assistant, nurses, a senior consultant, pharmacists and lab technicians.  The total time it takes from the moment they walk into the hospital to the moment they enter their consultant’s office can be up to 5 hours. EMPATHY MAPPING: We then mapped the emotional experience of the patients based on the touch points we identified. Asking maternity patients to go back and forth from a customer relations executive in the waiting area, to an admin at a hospital reception, to the consultant’s personal assistant outside the doctor’s office causes unnecessary stress. But this mapping also enabled us to understand which elements were stressors during the visit, which ones were important and which could be avoided. USER INTERVIEWS: 1. PATIENT INTERVIEWS: We interviewed 15 patients about their experience at the hospital. This is what they had to say about the areas of improvements:  8 people said that the wait time for appointments was 2-3 hours on an average.  6 people said that they came to the hospital because they were referred to a great doctor, but that their experience with the rest of the hospital staff could be better.  5 people said that they were not told that their doctor would be delayed due to an emergency prior to arriving at the hospital.  4 first-time fathers wished that they had a community where they could connect with other fathers in the same situation as them.  1 person said that they had to drive 45 minutes to a different branch of the hospital to avail services for the package they had bought there even though it was from the same hospital franchise. 2. DOCTOR INTERVIEWS: We also interviewed 4 doctors about their experience working in the hospital. This is what we collected:  4 of them said that they relied on their assistants to compile all the hospital records of a patient prior to their consultation.  3 of them said that patients had almost as many follow-up questions after the consultation as they had during it.  3 of them shared their personal phone number with patients as a means of contacting them but patients often times took advantage of it and didn’t respect the doctor’s privacy.  3 of them said that patients were asked to come back to the hospital just to pick up a report when it was ready. 3. STAFF INTERVIEWS: We interviewed several hospital staff and learnt that:  Their knowledge about procedures and processes varied quite a bit, quite possibly influenced by the staff changing quite often.  There were a few redundant procedures where some of the CRM staff got in between the doctor and the patient and became a cause for irritation for the patient. KEY LEARNINGSFROM FIELD RESEARCH:  The most frequent points of concern for patients were around the wait-times and the unpredictability of the doctor’s appointments. This was a key problem that needed to be solved.  Choosing a doctor to be in charge of your baby’s birth is a more involved process than just viewing the key stats of the doctor. A better doctor-patient matchmaking system needed to be devised.  A lot of the questions being asked by the patients were repetitive for the doctors and while there were other sources of information available to users, they had to hear it from their doctor.  The hospital needed to standardise the operations across the various centres and provide patients a seamless experience no matter which centre they visited. This was going to be a bigger problem to solve.  The patient’s understanding of the services offered by the hospital was not clear. This wasn’t helped by the staff’s understanding of the situation either. FROM MARKET RESEARCH: Before trying our hand at our own solutions for the above problems, our first step was to download and use top health and medical apps in the market to see how they tackled the issues we identified as key user needs. Some useful and relevant features we found in our research were:  Chat with your doctor View medical records Order medication Find a doctor Book appointments Curated content for users on how to be healthierMost apps offered segmented parts of the hospital experience, creating a disjointed experience. There wasn’t one that addressed the patient’s experience throughout her pregnancy. DESIGN PRINCIPLESIn order to design the application, we created this new architect’s map to outline the ideal hospital experience we would be able to design. A majority of the time, the patient is likely to be happy and calm because the physical touch points would be taken care of using our app, including valet, check-in, being updated of their status in the queue, their doctor’s status and ordering medication. We offered ways for non-smartphone users to interact with the hospital as well but made a design choice of removing such touch points and reduced the wait-time from up to 5 hours to just 2 hours. The following five guidelines formed the foundation of our approach, which would eventually become the basis of the solution we designed: 1. BE SENSITIVE:  Women are giving birth later in life now than in previous generations.  They are opting to do so rather than approaching it as an automatic expectation from their lives, making this already special event even more important.  The older the person is, the higher the risks of complications during birth and many are aware of this fact, making them more anxious through the entire process.  Being sensitive to all of the things that they are going through at various stages is important in being able to design and deliver an experience that they would appreciate. 2. BE RELEVANT:  There’s a lot of information that surrounds the birthing process. There’s so much that one needs to know about conceiving, the changes their body will go through, the types of nutrition that are good for a baby growing in the womb, the kind of care one needs, etc.  Showing all of the information at the same time will not only serve to overwhelm, but will also prove useless. Showing relevant information at the right times is key. 3. BE A LIFELINE TO ALL:  One hopes for there to be no complications during birth, but life can take another course altogether. This weighs heavily on mothers and even more so on first-time mothers when their inexperience leaves them more worried than they should be.  While there are levels of alarm, the only course of remedy so far is to call a doctor. Some expecting parents call too often, others who are worried about being bothersome may end up calling too late. The app can recognise the different levels of alarm and provide the various remedies. 4. BE SOCIAL:  There are more nuclear families in India now than at any other point in its history before. Couples travel to cities where they find work and no longer have unlimited access to the family structures that would be around to help in the birthing process.  While the best hospitals take good care of the physical aspects of the birthing process, there’s still an unaddressed need in terms of the emotional.  This could be done by bringing in the social nature of the application and enabling expecting mothers to meet each other and form their own support groups. 5. BE A PART OF THE CULTURE:  We are a very social culture in India but most apps out there that aid in the process of birthing are designed for more individualistic cultures.  Families are involved whether in the same city or not. Technology can play a crucial role in this and can not only address their concerns, but also provide ways to be more involved.  This can play a vital role in making the mother-to-be feel more comforted and cared for.  It can also help first-time husbands understand the changes their partners are going through so they respond appropriately. FINAL OUTPUTWe focussed on two main points in our solution, which aimed to decrease the time patients spent in the hospital and to help them stay organised by giving them easy access to all the essential information. 1. REGISTERING WITH A BOT: The goal for us during the registration process was to bring the user into the application in as few steps and as easily as possible. So we focussed on figuring out the set of information that we simply couldn’t do without and allow the patient to come back and fill in any additional details at a later point. To do this, we adopted a conversational structure to make the patient feel comfortable and the app more approachable. The downside, however, was the amount that the user needs to type. We simplified this by providing ”input helpers” that are essentially guesses based on the most frequently provided answers from patients. This saves a lot of typing and also provides guidance to the patients as to what kind of answer was being requested. We took the bot (named Bump) further into the system, allowing Bump to become another way to interact with the entire app. For example, when the patient decides she wants to schedule an appointment, Bump comes back to collect the remaining details that are required to complete the registration and book her appointment. Bringing up details in context and only when they are really required also helps justify the level of detail and time it takes to complete the form.  2. USER FLOWS AS A TABLE: There were a lot of use cases during registration that needed to be addressed. Instead of using the traditional flow chart method, which became haphazard and disorganised with too many conditionals and branches, we used a table as shown below. It was successful in checking if we were missing any use case and easy to go through with the client.  3. APPOINTMENT TIME-SLOTS: Our research showed that patients were currently waiting up to 2-3 hours for their appointments. It was taking 6 minutes to book an appointment via the current system of calling customer service. We streamlined the appointment-booking process on the app to an average of 1-2 minutes and in some cases, even less. When a patient books an appointment, the system designates an exact time. The problem is, if a patient confirms their appointment and shows up even 10-15 minutes late, all the following patient appointments are affected and pushed back. In our system, when a patient books an appointment, she gets to choose from half-hour time slots and is added to the waiting queue depending upon her arrival time at the hospital. A half-hour slot guarantees that she expects to be seen within the half-hour period. She is told to check in 15 minutes prior to her appointment and is told her spot in the queue when she gets to the hospital. The time-slot system works on a first-come, first-served basis and thereby, is not influenced by other people’s arrival times. If another patient books an appointment in Slot B (9:30-10:00 a. m. ) and arrives at 9:30 a. m. , they are told that they are second in line. They are given the expectation that they are on priority in Slot B because they arrived early, so even if Slot A extends longer than 9:30 a. m. , they won’t mind since they are given a guarantee that they will be seen within a half-hour period. If they are given an exact time, their chances of frustration at not being seen at the promised time are high. Notice that Slot C has one vacancy and Slot D has two. This is to account for members of Slot A and B who don’t arrive within their check-in time. If they show up late, they are told that they have been moved to a different slot with a vacancy and that their wait-time will be up to an hour. Given the total time spent at the hospital currently can be up to 5 hours at times, an hour still isn’t much. Using the time-slot system, patients who arrive late for their slot will not start a domino effect and cause every consultation after them to be affected, especially the patients who actually checked in on time, and their wait time is still less than 2 hours. By replacing exact appointment times with a time-slot system, we have reduced waiting time considerably to a maximum of 45 minutes.  4. CONSULTATION STATUS CARDS: Our research revealed that too many touch points in the hospital increases user dissatisfaction. We focussed on creating an experience where the entire user journey through the hospital can be completed on the app – from check-in, to seeing their spot in the queue, to getting updated on their doctor’s status, to having the ability to cancel or reschedule an appointment, to viewing their next steps post consultation, etc. To do this, we created different states of the consultation card on the home screen, which constantly updates depending upon where the patient is in her pregnancy and hospital journey, as shown below. Secondary cards appear below the active consultation card that give suggestions on the next steps the patient can take. If there is an upcoming appointment in an hour, for example, the patient sees suggestions like booking a cab or calling a Cloudnine representative. On the active card, an overflow menu in the top right provides the option to cancel or reschedule an appointment, without leaving the home screen. We noticed that the list of instructions a doctor gives a patient can be tedious, so the cards appearing after a completed consultation break the steps down into easy to-do cards. Once tasks are completed, the respective card disappears.  5. TIMELINE: The pregnancy journey is a long one filled with consultations, scans, labs, workshops and other events. We have laid out all the milestones in an easily accessible timeline view. On any given day in the journey, a patient can see her progress, her upcoming milestones and previously completed milestones. We find showing the user her milestones in a timeline and schedule view transforms the overwhelming journey into an easy step-by-step process. She can book consultations, scans/lab appointments and RSVP for events directly from this view.  6. MEDICAL RECORDS: In our research, we noticed that two copies of all documents are printed, one for the patients and one for the hospital. This paper trail causes doctors to rely heavily on the organisational skills of their assistants when handling patient documents. On the flip side, patients themselves have to keep their printed documents in a safe place. Having a feature in the app where users can store and view medical records all in one place is imperative. In the app, an account holder can add a partner to the account for shared usage and a user can handle multiple family accounts within it. A husband can support his wife, her mother can also support her and take care of booking appointments so she need not feel like she has to do it all on her own. If the patient books a lamaze workshop, the event will be added to both partner calendars. Anyone with partner access to the main account can take responsibility and help the account holder in her long journey. Documents are organised by consultation and a user can search consultations by doctor name, date, consultation type, scan name, lab name or medication name. When documents/reports are ready for viewing, a patient no longer needs to come to the hospital to collect the document. Instead, she gets the reports right on her phone. If a patient chooses to get a scan outside Cloudnine, she can upload the report right onto the app.  7. CONSULTATION PREPARATION: In our research, we learned that many doctors would tell their patients to put a sticky note on their folder holding medical documents and quickly jot down any questions as they come up between consultations. In the customer app, an “Add Questions” section is accessible from the upcoming consultation card on the home screen. A user can collect all her questions for the doctor in one place and the doctor gets access to these questions before the consultation on his mobile and desktop app. Even if the user doesn’t have their sticky note on hand, she can still add questions in one place on her phone, organised by consultation.  8. CHAT WITH THE DOCTOR: Doctors give patients their personal numbers to contact them but many patients tend to take advantage of the gesture by messaging and calling the doctor at all hours. Without a full background profile of the patient, the doctor sometimes has difficulty diagnosing her and needs to ask for more details. In the customer app, there is an option to chat with the doctor. On the doctor’s app, they can access the patient’s profile and properly diagnose the symptoms and resolve the issue in one go. By having a chat feature in their app, the doctor is able to have peace of mind that their business and personal life can be separate on their phone and that they can respond to any questions their patients may have quickly and effectively. 9. COMMUNITY: A great feature that some pregnancy apps have already implemented is a community. After speaking with patients, we noticed that first-time fathers, in particular, want to be more proactive in the pregnancy process but are, instead, clueless as to how to act and what to do. The benefits of building a community for first-time parents are endless – they can have peer group support, join their due-date club, talk to more experienced parents, get emotional support for post-mortem depression, the list goes on. Even for more experienced patients, they can find and attend events to speak about their own experiences. The app curates different content for mothers and fathers in the community.  10. ONE-STOP SHOP: Our research showed inconsistencies in the hospital experience from one hospital to another. A patient can avail different services from the same Cloudnine Membership Plan, depending on which branch they purchased the package from; however, a customer must be at the hospital where she buys the plan to avail the services she has signed up for. Users are given brochures while they are at the hospital that inform them about delivery packages that they can avail. We knew the importance of creating a space in the app where users can understand what coming to Cloudnine entails and what they’ll receive in terms of services, all in one place. By presenting users all of the Cloudnine offerings in a comprehensible format, we anticipate a much higher conversion rate for package purchases. The shop feature in the app standardises all delivery packages in an easy-to-understand manner. Package details can be shared easily with family members using the “Share” option. A membership plan can be bought directly from the app without any external assistance and the preferred location to avail the services can be changed with ease. Plus, all the products and services a patient needs from the beginning to the end of the journey are compiled in one place. The system will push notifications to a patient nearing the end of her pregnancy, for example, to buy diapers and newborn essentials.  "
    }, {
    "id": 42,
    "url": "http://localhost:4000/blog/fis/",
    "title": "FIS Mobile Banking",
    "body": "2017/06/01 - ClientIndustryYearDeliverablesFIS SolutionsCore banking application for rural bankers2017-2018Tablet App DesignMobile App DesignTHE CHALLENGEThe project involved the design of an application for mobile bankers that would use it on a tablet in rural parts of India in order to provide banking services to villagers. There were unique challenges that included things like intermittent internet connectivity, hurdles due to illiteracy of the client, managing trust in such a scenario, as well as being mindful of the usage of the tablet in outdoor settings. This was an incredibly fun project that lasted about a year in total. THE OUTCOME:  6 clicks to complete a transfer – a 40% reduction Get to your task faster Security of transactions done by audio announcementsTHE BANKING LANDSCAPE: India, not uniquely, has seen the banking industry face pressure from outside it through indirect competitors like PayTM, Freecharge, PhonePe and the like. These players offer banking-like services through the use of their electronic wallets and people have been taking to it really quickly. While the pressure making traditional banks modernise their digital interfaces may have been questionable before, the RBI providing PayTM, et al, quasi-bank status made this pressure real. There was no question that these interfaces needed to modernise after that point. While the big banks with their own teams of technologists were trying to respond to this change, FIS was in a unique position to be able to evolve their platform outside the constraints of their client bank’s internal political and technological structures. This enabled Redd to work with them to provide a design that made an evolutionary jump instead of just taking the next step forward.  THE INDIAN DEMOGRAPHIC: Banking has traditionally been considered an offline process in India. People still prefer personal interactions to get their work done but the changing demography of India where more people are travelling to different cities to work has seen the need for money transfers Mobile application and such arising. These people have appreciated the benefits provided by electronic transfers, ATM’s and netbanking facilities and their attitudes towards banking has also, consequently, been evolving. While the majority still perform only a few functions like withdrawals, deposits and transfers with their banking applications, they are still not aware of the different possible functions in a bank. The application, therefore, needed to allow for these frequently performed functions to be done easily, but also to allow the user to discover all other functions that are possible with a bank. Another important challenge was to accommodate a varied target audience. India is a vast and diversely populated country. Banking needs to be accessible to the entire population, not just certain types of people. This meant that the application’s design had to accommodate for as many different user types as possible to avoid exclusion.  THE APPROACH: Banking is a vast field with a huge number of features and functions. So to handle this complex subject, we took the following approach: CONDUCT MARKET RESEARCH: We conducted market research against other direct and indirect competing offerings from the perspective of design trends and user familiarity so we could retain well-understood interaction paradigms. BUILD AN INTERACTION MODEL THAT WORKS ACROSS FUNCTIONS: The second obstacle to overcome was to design an interaction model that would work across functions like money transfers, insurance renewals, loan requests, etc. PROPOSE A MODEL AND FIX AFTER ANALYSIS: As the field of banking is so very extensive and each of the modules quite complicated, especially when you take into consideration the various changes that each client bank would want to bring in, one could not expect to ask all the questions ahead of time and arrive at a business analysis document and then take it forward. We took the approach of proposing a model based on initial research and then change and make the fixes after focussed discussions with regard to that module. We expected a higher number of revisions because of this approach, but there would be no work-around. DEVELOP A PROTOTYPE AND ACQUIRE FEEDBACK: To test the usability of the application, we built the prototypes and tested it against actual users to acquire feedback and make the fixes before taking it forward to implementation.  THE PROCESS: INPUT METHODS: Banking processes normally involve a lot of input from the users. People have to fill up long forms and authenticate themselves to complete even a simple process. When this form is taken online, users tend to make a lot of errors or skip important fields because of the screen size and direct adaptation of the offline forms. Our goal was to reduce as many errors as possible. To achieve this, we came up with a new input mechanism which would allow the user to focus on only one field at a time. We also ensured that the user would not have to move her/his eye up and down to look for fields, the fields would all appear in the bottom part of the screen. This made sure that the mental load on the user was less, which would eventually lead to faster processes with least possible errors. BENEFICIARY OR CONTACT: In today’s transfer process, users have to create a beneficiary every time, wait for it to get authenticated by the bank and then transfer money to them. Also, multiple transfer modes like UPI, AEPS, IMPS, etc. , just add to this complexity. Imagine having to create multiple beneficiaries for one person and then having to remember all of them without any confusion. After a lot of brainstorming, we decided to treat beneficiaries like contacts from our contact book. Users can create a parent beneficiary and then add different modes under each one. This allowed users to add multiple modes of payment under one beneficiary without having to enter the parent details all over again. TRANSFER PROCESS: Transferring money from one account to another is the most commonly used feature in any banking application. We wanted to design a process that would speed up the process without increasing the cognitive load on the user. Currently, the process of transferring money changes from mode to mode. Our first step was to combine all of these processes without affecting the dependencies. This would ensure that the user did not have to learn multiple steps and complete the task of transferring money easily.  WHITE-LABELLED APPLICATION: One of the biggest challenges with this application was to build it in a way that would allow multiple banks to use it by adding their brand colours and identity to it. Our visual design thus prescribed that the application be conceived on one primary colour and a primary gradient. This ensured that the design of the application would not be compromised by changing the colours. We also realised that the application needed to be constructed in a modular way to allow banks to add and remove features without affecting the user experience.  "
    }, {
    "id": 43,
    "url": "http://localhost:4000/blog/take-off/",
    "title": "Seven Lessons from the Aircraft Industry for UX Designers",
    "body": "2017/04/04 - There are a lot of things that have happened in the aircraft industry that apply in the user experience design field IntroductionThese past few months has seen me following shows about air crash investigations on YouTube that probably aired on American television at some point in the past. It’s not the macabre fascination for death and destruction that keeps me glued but the seemingly minute design problems that lead to these catastrophic events, sometimes insanely complicated and sometimes as plain as day. What was more interesting were the parallels I saw between the design of aircraft and that of the user experience (UX) design of software. So here’s a list of the top-five lessons that I believe a UX designer should know.  Lesson 1: Success is when nothing happens: This is probably the most important lesson that I took away from watching these videos. No one complains when a bomb does not go off on an aircraft. No one talks about flights that land at their destinations without incident. And absolutely no one mentions a flight that arrives on time. In the UX design too, most people don’t usually remark when things work well. They are just happy using it and focus on getting their work done. Moreover, the superior experience quickly becomes the baseline expectation from the software. When designing systems in airline industries and also in user experience, the lack of a positive response from customers cannot be deemed as failure. Instead we must use other measures for evaluating success. Better measurements of success are repeated engagements, frequency of use, high numbers of referrals or number of conversions.  Lesson 2: Things are made better over multiple iterations: An aircraft is a very delicate balance of a lot of different systems that have been perfected after their interaction and dependencies on other systems were learnt over time. Take for instance, the airspeed indicator on an airplane. Early models carried a single gauge. When people recognised that the gauge is a simple mechanical device that can fail, they added another indicator for the sake of redundancy. Then in one incident, one of the gauges wouldn’t work properly and showed an incorrect reading. This made pilots of one aircraft spend an inordinate amount of time trying to figure out which of the two gauges was showing the correct reading and this resulted in the plane crashing. After that incident, the human behaviour of pilots was taken into consideration and a third gauge was added so that pilots could look at all three gauges if required and decide quickly. It is nearly impossible for any human being to design an aircraft that took all of the factors of failure into consideration right from the beginning. In fact the primary objective of the National Transportation and Safety Board’s (NTSB) and their counterparts across the globe, is to identify such design flaws and communicate it to the airline industry as a whole so that good solutions could be adopted by all right away. In UX design too, an iterative approach is the best way forward. It is sometimes possible to anticipate some problems ahead of time based on the experience of the designer. But often, it is best to put the product in front of real-users and examine the behaviours and carefully optimise it over iterations. In the digital space it is especially easy to do and one can release multiple versions modifying and fixing things over time. Sometimes inexperienced designers (and inexperienced clients) make the leap and create what should be the third version of a piece of software in the first attempt. This is a huge waste of time because no matter how carefully we design the application in the lab, we learn the truths of our designs only when we get it into the hands of users because we may have made false assumptions based on bad user-testing in a laboratory setting, or we may find that customers are actually willing to pay for something we didn’t anticipate. It is therefore best to break up the design task into smaller chunks and find the fastest paths to get that chunk released. The best designed software out there which has to include Google Maps among them followed this very approach.  Lesson 3: Experienced professionals make all the difference: While I argued that it is best to release things over multiple iterations, there is a lot to be said for experience. A seasoned aircraft designer will understand amongst other things, the implications of placing an electrical line over a fuel supply line, the need to place the cock-pit voice recorder far away from the data recorder or that the primary driver of the aircraft systems design isn’t cost reduction but the safety of passengers. An experienced UX designer would be able to identify features that are critical to the business proposition, the dependencies of design decisions on the customer service teams or how future modules can be added on top of existing ones with the least amount of code revision by a development team and so on. The more experienced the design team is the more likely they will be able to anticipate such interdependencies between the various modules of the application. Furthermore, any design team that works across multiple industries will tend to evolve faster than a design team that only works in a single vertical simply because they would have seen solutions that may apply to one while working with another. For instance, we worked on the design of a breast cancer scan app that interfaced with a handheld scanner over bluetooth. The app needed a review feature that would allow a user to easily go through all the scans she had done previously to identify growth of red spots. We adapted a reviewing method that is similar to scrubbing through videos in movie players as the method that would help identify growths in multiple scans. While this is just one example, it occurs all the time.  Lesson 4: Be very discerning about why you need the user’s attention: On Delta Air Lines Flight 1141, that flew on August 31, the airplane was equipped with a Take-off Warning System (TOWS), an alarm that indicated the incorrect configuration of the aircraft for take-offs whenever the plane began to move. While it had good intentions, the alarm was designed to sound as soon as the airplane began to back away from the terminal gate and would sound all the way until the airplane achieved enough velocity to take off. At busy airports, it is not uncommon to have many aircrafts ahead queuing to take off which meant that the alarm would be sounding for much longer. To circumvent this, pilots frequently popped the circuit-breaker that would shut off the incessant alarm. This led to the aircraft crashing as pilots attempted to take off while the aircraft was in fact not at a speed that allowed it to climb. After the disaster, the National Transportation Safety Board (NTSB) issued directions to the aircraft manufacturers to fix the threshold for the alarm so that it would only sound an alarm when a bonafide low-speed take-off was attempted. In UX design too, it is important to exercise restraint when showing error notifications lest we desensitise our users to the notifications. For example, we see apps that display an error stating that a valid email address is required as soon as the user focuses on such field on a form. This is a bad pattern as the user is yet to make the mistake that the error is warning him or her about. A better time to show this error would be when the focus shifts away from the field or if that’s not possible for any reason, apply any algorithm that accurately identifies that the user actually made such an error before warning them. Otherwise they will get desensitised to the error notifications and can end up making mistakes multiple times and not realising it. This will lead to frustration on the user’s end and it must be avoided at all costs.  Lesson 5: Points of Inspection: It is almost impossible to examine every aspect of a complex system on a routine basis. But inspections are necessary before every flight to make sure passengers can fly safely. To deal with this, pilots are taught to do pre-flight checks which include walking around the aircraft looking and feeling for any cracks or fatigue marks on wings, the points at which they attach to the main fuselage, oil and fuel for contamination and proper levels, the lights and finally the wings for ice formation. These pre-flight checks in-fact cover the points in which a failure could indicate failure of sub-systems. While this is never as good as a complete and thorough examination of an aircraft, they are good points of inspection which can indicate the proper functioning of an aircraft. The idea of having points of inspection is critical in UX design as well. There are specific points of failure for every application that should be examined on a frequent basis as they indicate healthy functioning of systems. These points of inspection may include the number of customer service requests, number of returns or exchanges, amount of time spent within an app, amount of time spent to perform a function, etc. and will differ depending on the nature of the application in question. Experienced designers can spot these points during the design stage itself and specify it as a point whose usage needs to be tracked so that they will know what the data indicates once the application has been put into the hands of users. They may then take necessary steps to fix the problem or extend the feature as necessary.  Lesson 6: Averages can be misleading: On January 8, 2003, a US Airways Express Flight 5481 crashed to the ground after only 37 seconds of flight time. On it perished 21 passengers. The investigation revealed that the plane was in fact overweight by a total of 264 Kgs more than the maximum allowed Federal Aviation Authority’s (FAA) standards. The cause of this overloading was in fact the miscalculation that arose from working with the average weight to be considered per passenger based on the FAA guidelines set based on the average weights of people set in 1936. Recommendations were made by the NTSB to load airplanes based on actual weight of passengers rather than an estimated average. In UX design too there is the notion of personas which are essentially a typified set of the users. While this makes it simpler for us to design systems to serve these types of users, it must be kept in mind that they are not substitutes for actual users. Persona’s are useful when designing the first version of a heretofore non-existent system, but we must stop relying on them as soon as we have real data from real users because they are far more indicative of the reality than what we may have imagined in labs while designing the systems.  Lesson 7: Designing better workflows: In one of the most famous air-crash investigations, US Airways Flight 1549 flown by Captain Sully, the airplane landed in the Hudson river. All lives were saved in this crash but an investigation was conducted by the NTSB as the dual-engine failure was unheard of before that incident and it suspected pilot error to be one of the contributing factors for the crash. While the pilots were acquitted for any wrong-doing, they were commended for having the presence of mind to turn on the auxiliary power unit (APU) as soon as they lost power instead of following the quick-reference-checklist for handling bird-strikes put that step much further down the list of tasks for the pilots to complete. Amongst other recommendations, the NTSB also made recommendations for the redesign of the QR checklists to make APU engagement among the earlier steps rather than late ones. In other incidents, the QR checklists were very long and spanned multiple pages. The checklists didn’t take into consideration the state of mind of the users or the possibility of them making mistakes and having to repeat the steps in the checklists all over again. An examination conducted by the MIT revealed these problems with the checklists and made recommendations to keep them as a collection of short tasks rather than a long process. In UX design too, its useful learning as we are tempted too often to build workflows that combine a whole lot of steps together. Even the creation of “wizards” for achieving a number of tasks together should be reconsidered if usability is ever a matter of concern. Chunking them into smaller steps will make using them much easier to handle and create a sense of completion and satisfaction in the user’s minds. "
    }, {
    "id": 44,
    "url": "http://localhost:4000/blog/design-must-humanise-technology/",
    "title": "Design Must Humanise Technology",
    "body": "2016/12/05 - Technology must function within the world of regular people To humanise technology is to make technology function within the framework defined by the capabilities and limitations of regular people. For a long period of history technology concerned itself with the development of tools that made things faster, better or cheaper. As a result, we began communicating with more people, exposing ourselves to and processing more information, increased our area of influence and in general became more productive. We began to achieve things in seconds that would otherwise take us hours or days before. Take for example a farmer in the 18th century needing to learn about the best times to sow and harvest a crop, he would have to ask around, find someone who knew of anyone who grew that crop, physically walk the miles to meet the person and then learn about it. It would normally have been more than a day’s task. It’s not necessary to mention that a farmer today with the same problem can solve all of this in a matter of minutes by looking things up on the net or sending a message over email. His days have suddenly opened up and he can do a lot more.  Technology kept getting better and enabling us to do more. But today, one can argue that we’ve filled the cup of human capabilities to the brim. We are inundated with messages, notifications, emails, news feeds, phone calls and so much more on a daily basis. We are expected to be more productive, make more decisions and provide our attention to a lot more things than we ever used to. And it all has happened in a rather short period of time and our bodies and minds haven’t had the time in an evolutionary scale to adapt to it. Consequently, we are seeing greater number of cases of attention deficit disorders, of depression, of stress resulting in greater strains on inter-personal relationships. We as a species are just not able to keep up with the speed and quantum that technology can produce today. To understand this better, consider the sequence of events when you receive an email. A red badge pops up over the application icon attracting your attention to it, a notification on your desktop may pop-up offering you a quick preview of what the message says and if you’re like many people today, you probably have your phone also hooked up to the mail service and you get the same notifications on that device too. If you’re using a smartwatch, then you add one more device that’s attracting your attention to the same email. Your mind suddenly registers a sense of urgency given that all so many of these things are telling you about this mail. Even if you are aware consciously that it’s just an email, it nevertheless succeeds at least in creating a nagging sensation in your mind until you deal with it — even if it is a discount coupon for some new offer on a shopping site that you couldn’t care less about.  This feeling you may have experienced is by no means a trivial one. It is so common that there have been several articles talking about methods to achieve the “zero inbox”, a supposed ideal state where you have no emails left unanswered in your inbox. There have been CEO’s writing about the tricks they’ve used and there have also been applications that claim to help you achieve that ideal. A lot of people in companies also associate their sense of how productive they’ve been based on the achievement of this goal. The goal seems to be to find a stable stance in front of the door while ignoring the fact that there is a full-size battle tank on the other side! We don’t have a fighting chance. To humanise email technology would be to design the emailing process with the goal of accommodating email into the users life without disrupting it. What if we kept in mind the following questions when designing the email system: What does the user go through when an email is received? How much is he or she actually capable of doing? How much rest does the person require between tasks? Is now the best time to notify the user of a new email? Does the user really need to be notified of this email? Can the application provide assistance by presenting it in a form that is easy for the human to make decisions on, like presenting them with the possible responses included? Instead of acting like a petulant child that is begging for attention all the time, can we fashion the email system like a well-mannered adult that sought your attention only when it knew you’re free? Given the arc on which technology is progressing into the future, it is imperative that we as designers find ways to make technology more palatable to human beings and accommodate it into their lives instead of the other way around. And that’s precisely our goal here at Redd. "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});